[{"categories":["Python"],"content":" 翻译：A deep dive into the official Docker image for Python\nDocker的官方Python镜像非常流行，实际上，我建议将其变体之一作为基础镜像。但是许多人不太了解它的作用，这可能导致混乱和破裂。\n因此，在这篇文章中，我将介绍它的构造方式，为什么有用，如何正确使用它以及它的局限性。特别是，我将通读截至2020年8月19日的python:3.8-slim-buster变体，并在进行过程中对其进行解释。\n 阅读 Dockerfile 基础镜像 我们从基础镜像开始：\n1  FROMdebian:buster-slim  也就是说，基础镜像是Debian GNU / Linux 10，这是Debian发行版的当前稳定发行版，也称为Buster。\n Debian 的所有发行版均以 Toy Story 中的角色命名。如果您想知道，Buster是Andy的爱犬。\n 因此，首先，这是一个Linux发行版，可确保长期稳定，同时提供错误修复。该slim变体安装的软件包较少，因此没有提供编译器。\n环境变量 接下来设置环境变量。首先确保/usr/local/bin在 $PATH 中：\n1 2  # ensure local python is preferred over distribution pythonENV PATH /usr/local/bin:$PATH  基本上，Python 镜像是将 Python 安装到/usr/local中，因此可以确保所安装的 Python 可执行文件是默认使用的。\n接下来，设置区域设置：\n1 2 3  # http://bugs.python.org/issue19846# \u003e At the moment, setting \"LANG=C\" on a Linux system *fundamentally breaks Python 3*, and that's not OK.ENV LANG C.UTF-8  据我所知，即使不这样做，现代Python 3仍将默认为UTF-8，因此我不确定目前是否有必要。\n还有一个环境变量可以告诉您当前的Python版本：\n1  ENV PYTHON_VERSION 3.8.5  还有一个带有GPG密钥的环境变量，用于在下载Python时验证其源代码。\n运行时依赖 运行 Python 需要一些其他软件包：\n1 2 3 4  RUN apt-get update \u0026\u0026 apt-get install -y --no-install-recommends \\ \tca-certificates \\ \tnetbase \\ \t\u0026\u0026 rm -rf /var/lib/apt/lists/*    ca-certificates是标准证书颁发机构的证书列表，与您的浏览器用来验证https://URLs 的证书相当。这使Python，wget和其他工具可以验证服务器提供的证书。\n  netbase安装了一些文件到/etc。这些文件在将某些名称映射到相应的端口或协议时所需。例如，在这种情况下，/etc/services将服务名称映射https到相应的端口号443/tcp。\n  安装Python 接下来，安装编译器工具链，下载Python源代码，编译Python，然后卸载不需要的Debian软件包：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  RUN set -ex \\ \t\\ \t\u0026\u0026 savedAptMark=\"$(apt-mark showmanual)\" \\ \t\u0026\u0026 apt-get update \u0026\u0026 apt-get install -y --no-install-recommends \\ \tdpkg-dev \\ \tgcc \\ \tlibbluetooth-dev \\ \tlibbz2-dev \\ \tlibc6-dev \\ \tlibexpat1-dev \\ \tlibffi-dev \\ \tlibgdbm-dev \\ \tliblzma-dev \\ \tlibncursesw5-dev \\ \tlibreadline-dev \\ \tlibsqlite3-dev \\ \tlibssl-dev \\ \tmake \\ \ttk-dev \\ \tuuid-dev \\ \twget \\ \txz-utils \\ \tzlib1g-dev \\ # as of Stretch, \"gpg\" is no longer included by default\t$(command -v gpg \u003e /dev/null || echo 'gnupg dirmngr') \\ \t\\ \t\u0026\u0026 wget -O python.tar.xz \"https://www.python.org/ftp/python/${PYTHON_VERSION%%[a-z]*}/Python-$PYTHON_VERSION.tar.xz\" \\ \t\u0026\u0026 wget -O python.tar.xz.asc \"https://www.python.org/ftp/python/${PYTHON_VERSION%%[a-z]*}/Python-$PYTHON_VERSION.tar.xz.asc\" \\ \t\u0026\u0026 export GNUPGHOME=\"$(mktemp -d)\" \\ \t\u0026\u0026 gpg --batch --keyserver ha.pool.sks-keyservers.net --recv-keys \"$GPG_KEY\" \\ \t\u0026\u0026 gpg --batch --verify python.tar.xz.asc python.tar.xz \\ \t\u0026\u0026 { command -v gpgconf \u003e /dev/null \u0026\u0026 gpgconf --kill all || :; } \\ \t\u0026\u0026 rm -rf \"$GNUPGHOME\" python.tar.xz.asc \\ \t\u0026\u0026 mkdir -p /usr/src/python \\ \t\u0026\u0026 tar -xJC /usr/src/python --strip-components=1 -f python.tar.xz \\ \t\u0026\u0026 rm python.tar.xz \\ \t\\ \t\u0026\u0026 cd /usr/src/python \\ \t\u0026\u0026 gnuArch=\"$(dpkg-architecture --query DEB_BUILD_GNU_TYPE)\" \\ \t\u0026\u0026 ./configure \\ \t--build=\"$gnuArch\" \\ \t--enable-loadable-sqlite-extensions \\ \t--enable-optimizations \\ \t--enable-option-checking=fatal \\ \t--enable-shared \\ \t--with-system-expat \\ \t--with-system-ffi \\ \t--without-ensurepip \\ \t\u0026\u0026 make -j \"$(nproc)\" \\ \tLDFLAGS=\"-Wl,--strip-all\" \\ \t\u0026\u0026 make install \\ \t\u0026\u0026 rm -rf /usr/src/python \\ \t\\ \t\u0026\u0026 find /usr/local -depth \\ \t\\( \\ \t\\( -type d -a \\( -name test -o -name tests -o -name idle_test \\) \\) \\ \t-o \\( -type f -a \\( -name '*.pyc' -o -name '*.pyo' -o -name '*.a' \\) \\) \\ \t-o \\( -type f -a -name 'wininst-*.exe' \\) \\ \t\\) -exec rm -rf '{}' + \\ \t\\ \t\u0026\u0026 ldconfig \\ \t\\ \t\u0026\u0026 apt-mark auto '.*' \u003e /dev/null \\ \t\u0026\u0026 apt-mark manual $savedAptMark \\ \t\u0026\u0026 find /usr/local -type f -executable -not \\( -name '*tkinter*' \\) -exec ldd '{}' ';' \\ \t| awk '/=\u003e/ { print $(NF-1) }' \\ \t| sort -u \\ \t| xargs -r dpkg-query --search \\ \t| cut -d: -f1 \\ \t| sort -u \\ \t| xargs -r apt-mark manual \\ \t\u0026\u0026 apt-get purge -y --auto-remove -o APT::AutoRemove::RecommendsImportant=false \\ \t\u0026\u0026 rm -rf /var/lib/apt/lists/* \\ \t\\ \t\u0026\u0026 python3 --version  里面有很多东西，但是基本结果是：\n Python已安装到中/usr/local。 所有.pyc文件被删除。 gcc一旦不再需要编译Python所需的程序包等，便将其删除。  由于所有这些操作均在单个RUN命令中发生，因此镜像最终不会将编译器存储在其任何层中，从而使镜像变得更小。\n您可能会注意到的一件事是Python需要libbluetooth-dev进行编译。这令人惊讶，所以我追根究底，很明显，Python可以创建蓝牙套接字，但前提是必须在安装了此软件包的情况下进行编译的。\n设置别名 接下来，/usr/local/bin/python3获取一个别名/usr/local/bin/python，两种方式都可调用到：\n1 2 3 4 5 6  # make some useful symlinks that are expected to existRUN cd /usr/local/bin \\ \t\u0026\u0026 ln -s idle3 idle \\ \t\u0026\u0026 ln -s pydoc3 pydoc \\ \t\u0026\u0026 ln -s python3 python \\ \t\u0026\u0026 ln -s python3-config python-config  安装 pip 该pip包下载工具都有其自己的发布时间表，与Python的不同。例如，这Dockerfile将安装2020年7月发布的Python3.8.5。 pip20.2.2已于8月发布，但要Dockerfile确保包含较新的版本pip：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  # if this is called \"PIP_VERSION\", pip explodes with \"ValueError: invalid truth value '\u003cVERSION\u003e'\"ENV PYTHON_PIP_VERSION 20.2.2# https://github.com/pypa/get-pipENV PYTHON_GET_PIP_URL https://github.com/pypa/get-pip/raw/5578af97f8b2b466f4cdbebe18a3ba2d48ad1434/get-pip.pyENV PYTHON_GET_PIP_SHA256 d4d62a0850fe0c2e6325b2cc20d818c580563de5a2038f917e3cb0e25280b4d1RUN set -ex; \\ \t\\ \tsavedAptMark=\"$(apt-mark showmanual)\"; \\ \tapt-get update; \\ \tapt-get install -y --no-install-recommends wget; \\ \t\\ \twget -O get-pip.py \"$PYTHON_GET_PIP_URL\"; \\ \techo \"$PYTHON_GET_PIP_SHA256*get-pip.py\" | sha256sum --check --strict -; \\ \t\\ \tapt-mark auto '.*' \u003e /dev/null; \\ \t[ -z \"$savedAptMark\" ] || apt-mark manual $savedAptMark; \\ \tapt-get purge -y --auto-remove -o APT::AutoRemove::RecommendsImportant=false; \\ \trm -rf /var/lib/apt/lists/*; \\ \t\\ \tpython get-pip.py \\ \t--disable-pip-version-check \\ \t--no-cache-dir \\ \t\"pip==$PYTHON_PIP_VERSION\" \\ \t; \\ \tpip --version; \\ \t\\ \tfind /usr/local -depth \\ \t\\( \\ \t\\( -type d -a \\( -name test -o -name tests -o -name idle_test \\) \\) \\ \t-o \\ \t\\( -type f -a \\( -name '*.pyc' -o -name '*.pyo' \\) \\) \\ \t\\) -exec rm -rf '{}' +; \\ \trm -f get-pip.py  同样，所有.pyc文件均被删除。\nEntrypoint 最后，Dockerfile具体说明 Entrypoint：\n1  CMD [\"python3\"]  使用CMD不加 ENTRYPOINT，python默认情况下会在运行镜像时进入 REPL：\n1 2 3 4 5  $ docker run -it python:3.8-slim-buster Python 3.8.5 (default, Aug 4 2020, 16:24:08) [GCC 8.3.0] on linux Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. \u003e\u003e\u003e   但是，您还可以根据需要指定其他可执行文件：\n1 2  $ docker run -it python:3.8-slim-buster bash root@280c9b73e8f9:/#   我们学到了什么？ 对slim-buster变体，这里有一些要点。\n该python官方镜像如何包含的Python 尽管这一点似乎很明显，但值得注意的是它是如何包含的：它是自定义安装Python到/usr/local。\n常见错误是通过使用Debian的Python版本再次安装Python：\n1 2 3 4  FROMpython:3.8-slim-buster# THIS IS NOT NECESSARY:RUN apt-get update \u0026\u0026 apt-get install python3-dev  这会在/usr中而不是在/usr/local中安装额外的Python，并且通常会是其他版本的Python。您可不希望同一镜像中有两个不同版本的Python。大多数情况下，这只会导致混乱。\n如果您确实要使用Debian版本的Python，请debian:buster-slim改为使用基本镜像。\npython官方镜像包括了最新的pip 例如，Python 3.5的最新版本是在2019年11月，但是python:3.5-slim-buster包含的Docker镜像是pip从2020年8月开始的。（通常）这是一件好事，这意味着您可以获得最新的错误修复，性能改进以及对较新版本的支持。\npython官方镜像删除所有.pyc文件 如果要稍微加快启动速度，则可能希望.pyc使用compileall将标准库源代码编译到自己的镜像中。\npython官方镜像不安装Debian安全更新 尽管经常会重新生成debian:buster-slim和python镜像，但是在某些窗口中已发布了新的Debian安全修复程序，但是尚未重新生成镜像。您应该将安全更新安装到基础Linux发行版。\n","description":"","tags":["python","docker"],"title":"深入了解Python的官方Docker镜像","uri":"/blog/posts/official-docker-python-image/"},{"categories":null,"content":" Jenkins 天然程序和数据分离的属性，使得它能够容易的迁移与升级。\n这次想把通过在 Host 上运行的 Jenkins 迁移到 docker 容器内。\n 备份 通过脚本打包 最简单的方式是将 Jenkins 的工作目录打包。一般为 /var/jenkins_home，或者 /var/lib/jenkins。如果你的数据量相当小，请直接用 tar 打包。再直接迁移到需要重新部署的 Jenkins 工作目录即可。\n 本文中宿主机的 Jenkins 在 /var/lib/jenkins 目录\n 然而由于当前的 jenkins_home里面存放了一些临时文件，以及 jobs, workspace 目录数据量已经相当大，所以我们打包的时候需要排除一些文件。\nbackup.sh\n1 2 3 4 5 6 7 8  #!/bin/bash  current_date=`date \"+%Y%m%d%H%M\"` jenkins_backup_path='/home/jks-master/jenkins/backups/backup_'$current_date'.tar' jenkins_home='/var/lib/jenkins' #echo $jenkins_backup_path tar -zcvf $jenkins_backup_path --exclude-from=exclude.txt $jenkins_home   exclude.txt\n1 2 3 4 5 6 7 8 9 10  /var/lib/jenkins/jobs /var/lib/jenkins/workspace /var/lib/jenkins/backups /var/lib/jenkins/inbox /var/lib/jenkins/Anaconda3 /var/lib/jenkins/anaconda3 /var/lib/jenkins/caches /var/lib/jenkins/.cache /var/lib/jenkins/Pipeline_*   通过插件备份 目前 Jenkins 中比较成熟的插件是 ThinBackup。里面提供了相对丰富的配置项\n得到的压缩文件为下一步迁移作准备。\n迁移 选择使用的 docker 镜像是 jenkins/jenkins:lts。\n假定将备份文件解压到/var/jenkins_home目录，若之前打包文件包含了 jobs/, workspace/文件夹，那么只需将文件解压出来再挂载到 docker 容器内即可。\n由于文中的实验环境没有将以上两个目录打包进来，所以在启动容器时会挂载多个目录。\nstart_docker_jenkins.sh\n1 2 3 4 5 6 7 8 9 10  #!/bin/bash  docker run -d \\ -u 1000:1000 \\ -v /var/jenkins_home:/var/jenkins_home \\ -v /var/lib/jenkins/jobs:/var/jenkins_home/jobs \\ -v /var/lib/jenkins/workspace:/var/jenkins_home/workspace \\ -p 8081:8080 \\ -p 50001:50000 \\ jenkins/jenkins:lts   启动后，获取到容器的 id，使用 docker logs [ID] 查看是否有错误。\n异常情况   jenkins.model.InvalidBuildsDir: ${ITEM_ROOTDIR}/builds does not exist and probably cannot be created\n这个错误的原因是权限问题。需要检查启动 docker 的用户所挂载的目录是否有权限读写。如果没有的话可更改目录的持有者：\nchown -R [USER] [DIR] \n 关于 docker容器的权限问题可以见参考一节前两篇文章\n   参考 docker挂载volume的用户权限问题,理解docker容器的uid\n理解 docker 容器中的 uid 和 gid\n","description":"","tags":["jenkins"],"title":"迁移 Jenkins 到 Docker","uri":"/blog/posts/migrate-jenkins-on-docker/"},{"categories":null,"content":" Jenkins 是强大的自动化工具。\n本文介绍如果通过 jcli（Jenkins Client）来管理 Jenkins 站点\n 环境  启动 Jenkins Service  安装 Linux 下的用户，可通过一下命令安装 jcli\n1 2 3 4  curl -L https://github.com/jenkins-zh/jenkins-cli/releases/latest/download/jcli-linux-amd64.tar.gz|tar xzv # 将 jcli 后添加进环境变量 echo export PATH=~:$PATH \u003e\u003e ~/.bashrc \u0026\u0026 source ~/.bashrc   ##使用\n在使用 jcli 工具之前，需要先生成一份配置文件。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  jcli config gen -i=false \u003e ~/.jenkins-cli.yaml cat .jenkins-cli.yaml jenkins_servers: - name: yourServer url: http://localhost:8080/jenkins username: admin token: admin proxy: \"\" proxyAuth: \"\" insecureSkipVerify: true description: \"\" preHooks: [] postHooks: [] pluginSuites: [] mirrors: - name: default url: http://mirrors.jenkins.io/ - name: tsinghua url: https://mirrors.tuna.tsinghua.edu.cn/jenkins/ - name: huawei url: https://mirrors.huaweicloud.com/jenkins/ - name: tencent url: https://mirrors.cloud.tencent.com/jenkins/   可以登录到 jenkins 页面上去 User -\u003e Configure -\u003e API Token 生成一个 token 填入到上面对应字段。\njcli -h\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  Jenkins CLI written by golang which could help you with your multiple Jenkins, We'd love to hear your feedback at https://github.com/jenkins-zh/jenkins-cli/issues Usage: jcli [command] Available Commands: casc Configuration as Code center Manage your update center completion Generate shell completion scripts computer Manage the computers of your Jenkins config Manage the config of jcli credential Manage the credentials of your Jenkins crumb Print crumbIssuer of Jenkins cwp Custom Jenkins WAR packager for Jenkins doc Generate document for all jcl commands help Help about any command job Manage the job of your Jenkins open Open your Jenkins with a browser plugin Manage the plugins of Jenkins queue Manage the queue of your Jenkins restart Restart your Jenkins runner The wrapper of jenkinsfile runner shell Create a sub shell so that changes to a specific Jenkins remain local to the shell. shutdown Puts Jenkins into the quiet mode, wait for existing builds to be completed, and then shut down Jenkins user Print the user of your Jenkins version Print the version of Jenkins CLI Flags: --config-load If load a default config file (default true) --configFile string An alternative config file --debug Print the output into debug.html --doctor Run the diagnose for current command -h, --help help for jcli --insecureSkipVerify If skip insecure skip verify (default true) -j, --jenkins string Select a Jenkins server for this time --logger-level string Logger level which could be: debug, info, warn, error (default \"warn\") --proxy string The proxy of connection to Jenkins --proxy-auth string The auth of proxy of connection to Jenkins --proxy-disable Disable proxy setting --token string The token of Jenkins --url string The URL of Jenkins --username string The username of Jenkins Use \"jcli [command] --help\" for more information about a command.   可以看出 jcli 里面涵盖了许多子命令，为了方便查询，jcli 提供了生成命令文档的功能\njcli doc [PATH]\n在导出目录下：\n里面的内容为：\n常用命令 由于命令繁多，这里列出一些比较常用的命令，更多的功能请参阅上面生成的文档。\nCenter  jcli center download\t- Download jenkins.war jcli center identity\t- Print the identity of current Jenkins jcli center mirror\t- Set the update center to a mirror address jcli center start\t- Start Jenkins server from a cache directory jcli center upgrade\t- Upgrade your Jenkins jcli center watch\t- Watch your update center status  Config  jcli config add\t- Add a Jenkins config item jcli config clean\t- Clean up some unavailable config items jcli config edit\t- Edit a Jenkins config jcli config generate\t- Generate a sample config file for you jcli config list\t- List all Jenkins config items jcli config plugin\t- Manage plugins for jcli jcli config plugin\t- Manage plugins for jcli jcli config remove\t- Remove a Jenkins config jcli config select\t- Select one config as current Jenkins  Credential  jcli credential create\t- Create a credential from Jenkins jcli credential delete\t- Delete a credential from Jenkins jcli credential list\t- List all credentials of Jenkins  Job  jcli job artifact\t- Print the artifact list of target job jcli job build\t- Build the job of your Jenkins jcli job create\t- Create a job in your Jenkins jcli job delete\t- Delete a job in your Jenkins jcli job disable\t- Disable a job in your Jenkins jcli job edit\t- Edit the job of your Jenkins jcli job enable\t- Enable a job in your Jenkins jcli job history\t- Print the history of job in your Jenkins jcli job input\t- Input a job in your Jenkins jcli job log\t- Print the job's log of your Jenkins jcli job param\t- Get parameters of the job of your Jenkins jcli job search\t- Print the job of your Jenkins jcli job stop\t- Stop a job build in your Jenkins jcli job type\t- Print the types of job which in your Jenkins  Plugin  jcli plugin build\t- Build the Jenkins plugin project jcli plugin check\t- Check update center server jcli plugin create\t- Create a plugin project from the archetypes jcli plugin download\t- Download the plugins jcli plugin install\t- Install the plugins jcli plugin list\t- Print all the plugins which are installed jcli plugin open\t- Open update center server in browser jcli plugin release\t- Release current plugin project jcli plugin search\t- Print the plugins of your Jenkins jcli plugin trend\t- Show the trend of the plugin jcli plugin uninstall\t- Uninstall the plugins jcli plugin upgrade\t- Upgrade the specific plugin jcli plugin upload\t- Upload a plugin to your Jenkins  User  jcli user create\t- Create a user for your Jenkins jcli user delete\t- Delete a user for your Jenkins jcli user edit\t- Edit the user of your Jenkins jcli user token\t- Token the user of your Jenkins  Jenkins  jcli restart - Restart your Jenkins jcli shutdown - Puts Jenkins into the quiet mode, wait for existing builds to be completed, and then shut down Jenkins jcli runner - The wrapper of jenkinsfile runner Get more about jenkinsfile runner from https://github.com/jenkinsci/jenkinsfile-runner jcli shell - Create a sub shell so that changes to a specific Jenkins remain local to the shell.  参考 Jenkins CLI Tutorial\nJenkins CLI 文档\n","description":"","tags":["jenkins"],"title":"通过 jcli 管理 Jenkins","uri":"/blog/posts/manage-jenkins-by-using-jcli/"},{"categories":["Algorithm"],"content":"线性表相关 #Array\nLeetCode-p1 Two Sum Description:\nGiven an array of integers, return indices of the two numbers such that they add up to a specific target.\nYou may assume that each input would have exactly one solution, and you may not use the same element twice.\nAnalysis:\n Brute-force HashMap  Implements:\n Cpp  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  // Brute-force Solution class Solution { public: vector\u003cint\u003e twoSum(vector\u003cint\u003e\u0026 nums, int target) { vector\u003cint\u003e res; for(int i = 0; i \u003c nums.size(); ++i) { for(int j = i + 1; j \u003c nums.size(); ++j) { if(nums[j] == target - nums[i]) { res.push_back(i); res.push_back(j); return res; } } } return res; } };    Java  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  // Brute-force Solution class Solution { public int[] twoSum(int[] nums, int target) { for(int i = 0; i \u003c nums.length; i++){ for(int j = i + 1; j \u003c nums.length; j++){ if(nums[j] == target - nums[i]) return new int[]{i,j}; } } throw new IllegalArgumentException(\"No solution\"); } } // HashMap Solution class Solution { public int[] twoSum(int[] nums, int target) { int[] res = new int[2]; Map\u003cInteger, Integer\u003e map = new HashMap\u003cInteger, Integer\u003e(); for (int i = 0; i \u003c nums.length; ++i) { if (map.containsKey(target - nums[i])) { res[0] = i; res[1] = map.get(target - nums[i]); } map.put(nums[i], i); } return res; } }   Related Problem\n  3Sum\n  4Sum\n  Two Sum II - Input array is sorted\n  Two Sum III - Data structure design\n  Subarray Sum Equals K\n  Two Sum IV - Input is a BST\n  LeetCode-P4 Median of Two Sorted Arrays Description:\nThere are two sorted arrays nums1 and nums2 of size m and n respectively.\nFind the median of the two sorted arrays. The overall run time complexity should be O(log (m+n)).\nYou may assume nums1 and nums2 cannot be both empty.\nAnalysis:\n Merge Sort Solution find K-th position  Implements:\n Java  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  class Solution { public double findMedianSortedArrays(int[] nums1, int[] nums2) { int[] sorted = mergeSort(nums1, nums2); if (sorted.length % 2 == 1) { return sorted[sorted.length/2] / 1.0; } else { return (sorted[(sorted.length-1)/2] + sorted[sorted.length/2]) / 2.0; } } public int[] mergeSort(int[] nums1, int[] nums2) { int m = nums1.length, n = nums2.length; int total = m + n; int[] res = new int[total]; int i = 0, j = 0, k = 0; while (i \u003c m \u0026\u0026 j \u003c n) { res[k++] = (nums1[i] \u003c nums2[j]) ? nums1[i++] : nums2[j++]; } for (; i \u003c m; ++i) { res[k++] = nums1[i]; } for (; j \u003c n; ++j) { res[k++] = nums2[j]; } return res; } }   LeetCode-P11 Container With Most Water Description:\nGiven n non-negative integers a1, a2, ..., an , where each represents a point at coordinate (i, ai). n vertical lines are drawn such that the two endpoints of line i is at (i, ai) and (i, 0). Find two lines, which together with x-axis forms a container, such that the container contains the most water.\nNote: You may not slant the container and n is at least 2.\nAnalysis:\n Two Pointers  Implements:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  class Solution { public int maxArea(int[] height) { int n = height.length; int left = 0, right = n - 1, maxArea = 0; while (left \u003c right) { int w = right - left; int h = Math.min(height[left], height[right]); maxArea = Math.max(maxArea, w * h); // 高度较小的一侧决定maxArea  if (height[left] \u003e= height[right]) { right--; } else { left++; } } return maxArea; } } class Solution { public int maxArea(int[] height) { int maxArea = 0; for(int left = 0, right = height.length - 1; left \u003c right; ){ int h = (height[left] \u003c height[right]) ? height[left++] : height[right--]; maxArea = Math.max(maxArea, (right-left+1) * h); } return maxArea; } }   LeetCode-P15 3Sum Description:\nGiven an array nums of n integers, are there elements a, b, c in nums such that a + b + c = 0? Find all unique triplets in the array which gives the sum of zero.\nNote:\nThe solution set must not contain duplicate triplets.\nAnalysis:\n Two Pointer  Implements:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  public List\u003cList\u003cInteger\u003e\u003e threeSum(int[] num) { Arrays.sort(num); List\u003cList\u003cInteger\u003e\u003e res = new LinkedList\u003c\u003e(); for (int i = 0; i \u003c num.length-2; i++) { if (i == 0 || (i \u003e 0 \u0026\u0026 num[i] != num[i-1])) { int lo = i+1, hi = num.length-1, sum = 0 - num[i]; while (lo \u003c hi) { if (num[lo] + num[hi] == sum) { res.add(Arrays.asList(num[i], num[lo], num[hi])); do lo++; while (lo \u003c hi \u0026\u0026 num[lo] == num[lo-1]); do hi--; while (lo \u003c hi \u0026\u0026 num[hi] == num[hi+1]); } else if (num[lo] + num[hi] \u003c sum) lo++; else hi--; } } } return res; }   Related Problem:\n LeetCode-P16 3Sum Closest  LeetCode-P16 3Sum Closest Description:\nGiven an array nums of n integers and an integer target, find three integers in nums such that the sum is closest to target. Return the sum of the three integers. You may assume that each input would have exactly one solution.\nAnalyse:\n Brute-Force Two Pointers  Implements:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  // Brute-Force class Solution { public int threeSumClosest(int[] nums, int target) { int min = Integer.MAX_VALUE, n = nums.length; int res = 0; for (int i = 0; i \u003c n - 2; ++i) { for (int j = i + 1; j \u003c n - 1; ++j) { for (int k = j + 1; k \u003c n; ++k) { int sum = nums[i] + nums[j] + nums[k]; if (Math.abs(target - sum) \u003c min) { min = Math.abs(target - sum); res = sum; } } } } return res; } } // Two-Pointers class Solution { public int threeSumClosest(int[] nums, int target) { Arrays.sort(nums); int res = nums[0] + nums[1] + nums[nums.length - 1]; for (int i = 0; i \u003c nums.length - 2; ++i) { if (i == 0 || (i \u003e 0 \u0026\u0026 nums[i] != nums[i-1])) { int lo = i + 1, hi = nums.length - 1; while (lo \u003c hi) { int sum = nums[i] + nums[lo] + nums[hi]; if (sum \u003c target) do lo++; while (lo \u003c hi \u0026\u0026 nums[lo] == nums[lo-1]); else if (sum \u003e target) do hi--; while (lo \u003c hi \u0026\u0026 nums[hi] == nums[hi+1]); else return sum; res = (Math.abs(target-sum) \u003c Math.abs(target-res)) ? sum : res; } } } return res; } }   Related Problem:\n LeetCode-P15 3Sum  ###LeetCode-P18 4Sum\nDescription:\nGiven an array nums of n integers and an integer target, are there elements a, b, c, and d in nums such that a + b + c + d = target? Find all unique quadruplets in the array which gives the sum of target.\nNote:\nThe solution set must not contain duplicate quadruplets.\nAnalysis:\n Two Pointers  Implements:\nRelated Problems:\nLeetCode-P26 Remove Duplicates from Sorted Array Description:\nGiven a sorted array, remove the duplicates in place such that each element appear only once and return the new length. Do not allocate extra space for another array, you must do this in place with constant memory. For example, Given input array A = [1,1,2], Your function should return length = 2, and A is now [1,2].\nAnalysis:\nNone\nImplements:\n1 2 3 4 5 6 7 8 9 10 11 12 13  // Time complexity: O(n) , Space complexity: O(1) class Solution { public: int removeDuplicates(vector\u003cint\u003e\u0026 nums) { if (nums.empty()) return 0; int index = 0; for (int i = 1; i \u003c nums.size(); i++) { if (nums[index] != nums[i]) nums[++index] = nums[i]; } return index + 1; } };   Related Problems\n   单链表 ","description":"","tags":["algorithm","linear-list","array"],"title":"LeetCode 线性表相关题目与解决","uri":"/blog/posts/algorithm/leetcode-linear-table-related-problems-and-solutions/"},{"categories":["Java"],"content":"《Java核心技术》卷一 ：Chap14 并发   解释：多任务(Multitasking)，多线程(Multithreaded)\n  多进程和多线程区别？\n  线程执行一个任务的过程？\n  如何定义一个线程？\n警告：\n  如何中断线程？\n  线程有哪些状态？\n  线程有哪些属性？\n  为什么存在线程同步？\n因为存在竞争条件(race condition)。竞争条件是指两个或两个以上线程需要共享对同一数据的存取所导致的讹误。之所以会出现是因为执行存取动作并不是原子操作(动作在执行中被中断)。\n  如何同步存取？\n添加锁对象。\n  ","description":"","tags":["java"],"title":"《Java核心技术》卷一 ：Chap14 并发","uri":"/blog/posts/java/corejava-chap14-concurrency/"},{"categories":["Linux"],"content":"APUE: File and Directory 文件类型  普通文件（regular file) 目录文件 块特殊文件 字符特殊文件 FIFO Socket 符号链接  用户 ID、组 ID  一般uid，gid 获取自登录项，并在登录会话期间不会改变。但超级用户进程可以改变它们 有效用户 ID，有效组 ID以及附属组 ID 决定了文件访问权限 每个文件有一个所有者和组所有者  文件访问权限  每个文件有 9 个访问权限位 // table 进程打开、创建或删除文件时，内核会进行文件访问权限测试。 // 测试流程  新文件和目录所有权  新文件的用户 ID 设置为有效用户ID 新文件组 ID 可以是进程的有效组 ID，或者所在目录的组 ID  文件长度  stat 结构成员 st_size 表示以字节为单位的文件的长度，只对普通文件、目录文件和符号链接有意义 文件空洞？  文件截断  在文件尾端截去一部分数据缩短文件  文件系统  待定  符号链接  硬链接通常要求链接和文件位于同一文件系统 只有超级用户才能创建只想目录的硬链接  设备特殊文件  每个文件系统所在的存储设备都由其主、次设备号表示。  主设备好标识设备驱动程序 次设备号标识特定子设备   系统中与每个文件名关联的 st_dev 值是文件系统的设备号 只有字符特殊文件和块特殊文件才有 st_rdev 值，此值包含书籍设备的设备号  ","description":"","tags":["apue"],"title":"《APUE》文件与目录","uri":"/blog/posts/linux/apue-file-and-directory/"},{"categories":["Linux"],"content":"APUE: STANDARD IO 流和 FILE 对象  标准 I/O 库操作围绕流（Stream ）进行。  标准输入、标准输出和标准错误 缓冲   STDIO 提供缓冲的目的是尽可能减少 read 和 write 调用次数，对每个 IO 流自动进行缓冲管理。\n  提供以下类型的缓冲：\n 全缓冲：填满缓冲区后再进行 IO 操作 行缓冲：输入和输出中遇到换行符执行 IO 操作 无缓冲：立即执行    ISO C 要求缓冲特征：\n  当且仅当标准输入和标准输出不指向交互式设备时，才是全缓冲的（指向终端设备的溜航缓冲，否则为全缓冲）\n  标准错误一定不是全缓冲（很多系统默认使用不带缓冲的标准错误）\n    流的操作 打开流 相关函数\n读写流 ","description":"","tags":["apue","io"],"title":"《APUE》标准输入输出","uri":"/blog/posts/linux/apue-stdio/"},{"categories":["Linux"],"content":"配置完全命令行环境指南 获取帮助信息  man  man ascii man unicode|utf-8|latin1    help  ##文件与目录\n bat：更好的 cat cloc：计算代码行数，比 wc 更强大 file: 文件类型查看 find：强大的查找工具 head/tail：查看文件首部/尾部，查看/etc 下的配置文件的利器 locate：文件查找，基于内置数据库 less：更强大的 more lsd：更好看的 ls ranger：终端可视化文件管理 rename/repren：批量重命名文件 rsync：通过 ssh 或本地文件系统同步文件和文件夹 z：快速跳转目录工具，可替代 autojump  管道与正则   |, \u003e, \u003c, \u003e\u003e, \u003c\u003c\n  ack\n  awk\n  grep/egrep\n  sed\n  sort\n  uniq\n  系统信息  dmesg：引导及系统错误信息 sysctl： 在内核运行时动态地查看和修改内核的运行参数 hdparm：SATA/ATA 磁盘更改及性能分析 lsblk：列出块设备信息：以树形展示你的磁盘以及磁盘分区信息 lshw，lscpu，lspci，lsusb 和 dmidecode：查看硬件信息，包括 CPU、BIOS、RAID、显卡、USB设备等 lsmod 和 modinfo：列出内核模块，并显示其细节 iostat：硬盘使用状态 mpstat： CPU 使用状态 vmstat： 内存使用状态 lsof：列出当前系统打开文件的工具以及查看端口信息 dstat：系统状态查看 glances：高层次的多子系统总览 htop：top 的加强版  任务管理  nohup disown cron  网络管理  ip/ifconfig dig netstat ss：套接字数据 host 和 dig：DNS 查找 lsof -i: mtr：更好的网络调试跟踪工具 wireshark 和 tshark：抓包和网络调试工具 ngrep：网络层的 grep  版本控制  git  冷门但有用  expr：计算表达式或正则匹配 m4：简单的宏处理器 yes：多次打印字符串 cal：漂亮的日历 env：执行一个命令（脚本文件中很有用） printenv：打印环境变量（调试时或在写脚本文件时很有用） look：查找以特定字符串开头的单词或行 cut，paste 和 join：数据修改 fmt：格式化文本段落 pr：将文本格式化成页／列形式 fold：包裹文本中的几行 column：将文本格式化成多个对齐、定宽的列或表格 expand 和 unexpand：制表符与空格之间转换 nl：添加行号 seq：打印数字 bc：计算器 factor：分解因数 gpg：加密并签名文件 toe：terminfo 入口列表 nc：网络调试及数据传输 socat：套接字代理，与 netcat 类似 slurm：网络流量可视化 dd：文件或设备间传输数据 file：确定文件类型 tree：以树的形式显示路径和文件，类似于递归的 ls stat：文件信息 time：执行命令，并计算执行时间 timeout：在指定时长范围内执行命令，并在规定时间结束后停止进程 lockfile：使文件只能通过 rm -f 移除 logrotate： 切换、压缩以及发送日志文件 watch：重复运行同一个命令，展示结果并／或高亮有更改的部分 when-changed：当检测到文件更改时执行指定命令。参阅 inotifywait 和 entr。 tac：反向输出文件 shuf：文件中随机选取几行 comm：一行一行的比较排序过的文件 strings：从二进制文件中抽取文本 tr：转换字母 iconv 或 uconv：文本编码转换 split 和 csplit：分割文件 sponge：在写入前读取所有输入，在读取文件后再向同一文件写入时比较有用，例如 grep -v something some-file | sponge some-file units：将一种计量单位转换为另一种等效的计量单位（参阅 /usr/share/units/definitions.units） apg：随机生成密码 xz：高比例的文件压缩 ldd：动态库信息 nm：提取 obj 文件中的符号 ab 或 wrk：web 服务器性能分析 strace：调试系统调用 cssh：可视化的并发 shell last：登入记录 w：查看处于登录状态的用户 id：用户/组 ID 信息 sar：系统历史数据 iftop 或 nethogs：套接字及进程的网络利用情况 fortune，ddate 和 sl：额，这主要取决于你是否认为蒸汽火车和莫名其妙的名人名言是否“有用”  ","description":"","tags":["cmdline-tool","terminal"],"title":"配置完全命令行环境指南","uri":"/blog/posts/linux/summary-of-command-line-tools-under-linuxlinux/"},{"categories":["Web"],"content":"Django 项目的容器化实践  Python web 的部署环境，往往需要多种服务配合搭建，这种非常适合使用 Docker 来进行部署，现在我们来看一个利用 Dockerfile 和 docker-compose 所部署的 Django 项目\n 项目结构 ","description":"","tags":["django","docker"],"title":"Django 项目的容器化实践","uri":"/blog/posts/web/django-project-containerization-practice/"},{"categories":null,"content":"Jenkins Testlink Plugin 源码笔记 需求 Testlink 的 testcase 可以通过 Jenkins 去执行，当 Jenkins job 执行完之后，可以将执行结果保存到 Testlink 中。\njenkins 中 testlink plugin 仅仅可以在 freestyle 项目类型中使用，但目前大多数的 job 已经转移到 pipeline 类型，所以 testlink plugin 支持 pipeline 是一个自然的需要。\n思路 首先查到官方 Testlink-plugin 的 repo https://github.com/jenkinsci/testlink-plugin\npull 到本地查看一下项目结构\n1 2 3 4 5 6 7 8 9 10  ├── pom.xml ├── src\t│ ├── main │ │ ├── java │ │ ├── resources │ │ └── webapp │ └── test │ ├── java │ └── resources   其中主要代码存放在 src/main/hudson/plugins/testlink 下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  ├── AbstractTestLinkBuilder.java ├── AbstractTestLinkProjectAction.java ├── GraphHelper.java ├── Report.java ├── TestLinkBuildAction.java ├── TestLinkBuilder.java ├── TestLinkBuilderDescriptor.java ├── TestLinkInstallation.java ├── TestLinkJunitWrapper.java ├── TestLinkProjectAction.java ├── TestLinkResult.java ├── TestLinkSite.java ├── result │ ├── AbstractJUnitResultSeeker.java │ ├── AbstractTAPFileNameResultSeeker.java │ ├── AbstractTestNGResultSeeker.java │ ├── JUnitCaseClassNameResultSeeker.java │ ├── JUnitCaseNameResultSeeker.java │ ├── JUnitMethodNameResultSeeker.java │ ├── JUnitSuiteNameResultSeeker.java │ ├── ResultSeeker.java │ ├── ResultSeekerDescriptor.java │ ├── ResultSeekerException.java │ ├── TAPFileNameMultiTestPointsResultSeeker.java │ ├── TAPFileNameResultSeeker.java │ ├── TestCaseWrapper.java │ ├── TestNGClassNameResultSeeker.java │ ├── TestNGMethodNameDataProviderNameResultSeeker.java │ ├── TestNGMethodNameResultSeeker.java │ └── TestNGSuiteNameResultSeeker.java └── util ├── ExecutionOrderComparator.java └── TestLinkHelper.java   现在可以来对代码进行分析了，首先我们寻找到调用的入口 TestlinkBuilder.java\n定位到 perfrom() 函数\n1 2 3  public boolean perform(AbstractBuild\u003c?, ?\u003e build, Launcher launcher, BuildListener listener) throws InterruptedException, IOException { // function body\t}   可以看到入参列表：\nAbstractBuild\u003c?, ?\u003e build\nLauncher\nBuildListener \n接下来看函数体内容：\n1 2 3 4 5 6 7 8  // TestLink installation listener.getLogger().println(Messages.TestLinkBuilder_PreparingTLAPI()); final TestLinkInstallation installation = DESCRIPTOR .getInstallationByTestLinkName(this.testLinkName); if (installation == null) { throw new AbortException(Messages.TestLinkBuilder_InvalidTLAPI()); }   TestlinkInstallation 保存 configuration 里面对 Testlink 的配置信息:\n包括 name, url, devKey, testlinkJavaAPIPr\toperties\n接下来是初始化其他的东西\n1 2 3 4 5 6 7 8 9 10  TestLinkHelper.setTestLinkJavaAPIProperties(installation.getTestLinkJavaAPIProperties(), listener); final TestLinkSite testLinkSite; final TestCaseWrapper[] automatedTestCases; final String testLinkUrl = installation.getUrl(); final String testLinkDevKey = installation.getDevKey(); TestPlan testPlan; listener.getLogger().println(Messages.TestLinkBuilder_UsedTLURL(testLinkUrl)); ... testLinkSite = this.getTestLinkSite(testLinkUrl, testLinkDevKey, testProjectName, testPlanName, platformName, buildName, buildCustomFields, buildNotes);   TestlinkSite 成员里有 TestlinkAPI, 可以通过传入 configuration 里面所设置的参数对 Testlink 进行操作。\n1 2 3 4 5 6 7 8 9 10  final String[] testCaseCustomFieldsNames = TestLinkHelper.createArrayOfCustomFieldsNames(build.getBuildVariableResolver(), build.getEnvironment(listener), this.getCustomFields()); // Array of automated test cases TestCase[] testCases = testLinkSite.getAutomatedTestCases(testCaseCustomFieldsNames); // Retrieve custom fields in test plan final String[] testPlanCustomFieldsNames = TestLinkHelper.createArrayOfCustomFieldsNames(build.getBuildVariableResolver(), build.getEnvironment(listener), this.getTestPlanCustomFields()); testPlan = testLinkSite.getTestPlanWithCustomFields(testPlanCustomFieldsNames); // Transforms test cases into test case wrappers automatedTestCases = this.transform(testCases);   获取 CustomFields ， 通过TestlinkSite 拿到对应的 (List)Testcase，转换为(List)TestlinkWrapper , 针对其进行了一层封装，具体细节看 result/TestcaseWrapper.java.\n1 2 3 4 5 6  for(TestCaseWrapper tcw : automatedTestCases) { testLinkSite.getReport().addTestCase(tcw); if(LOGGER.isLoggable(Level.FINE)) { LOGGER.log(Level.FINE, \"TestLink automated test case ID [\" + tcw.getId() + \"], name [\" +tcw.getName()+ \"]\"); } }   TestSite中有成员 Report，用来存储基本的 Testcase，以及 TestStatus 这些信息\n1 2 3 4 5 6  if(getResultSeekers() != null) { for (ResultSeeker resultSeeker : getResultSeekers()) { LOGGER.log(Level.INFO, \"Seeking test results. Using: \" + resultSeeker.getDescriptor().getDisplayName()); resultSeeker.seek(automatedTestCases, build, build.getWorkspace(), launcher, listener, testLinkSite); } }   ResultSeeker 通过执行测试用例得到的 *report.xml 文件解析得到相应 Testcase 的执行结果。\n1 2 3 4 5 6  final Report report = testLinkSite.getReport(); report.tally(); ... final TestLinkResult result = new TestLinkResult(report); final TestLinkBuildAction buildAction = new TestLinkBuildAction(result); build.addAction(buildAction);   最后一步，生成 TestlinkReport，这里的对应的是 Jenkins 显示的report，而不是 TestlinkAPI 的 report。\n执行逻辑结束。\n后记 在完成这篇文章之前，我对于能否清晰的表达出我的分析有很大的怀疑。我之前也曾阅读过源码，是关于数据结构的。针对大的，互相有依赖的，以一定代码规模的，我不曾分析过。\n在阅读源码的时候，获得了以下几个小的知识点\n 从入口到各个模块的调用，是阅读源码的脉络 不要一开始纠结于细节。大致了解各个功能模块的作用就行 良好的抽象能力是关键技能  ","description":"","tags":null,"title":"Jenkins Testlink Plugin 源码笔记","uri":"/blog/posts/jenkins-testlink-plugin-source-notes/"},{"categories":null,"content":"Jenkins 服务无法启动排错指北 问题定位 start service:\nservice jenkins start \nthen check service status:\nservice jenkins status \nfor detail log info:\njournalctl -xe -u jenkins.service\n常见原因   端口争用\n如果 jenkins 服务端口在 8080，可以查看 8080 端口是否被其他服务所占用\nsudo lsof -i:8080\n假设是被一个叫 http-alt 的服务占用了，接下来把 8080 端口的服务 kill 掉\nsudo htop\n 这里加 sudo 是为了为 htop 里面 kill 赋予 root 权限\n /http-alt 查找到服务，可能有多行，摁下 F5 sort 下，找到父进程\n再摁下 F9 发送 kill 信号\n最后摁下 9\n相当于执行 kill PID -9\n  Have fun\n","description":"","tags":null,"title":"Jenkins 服务无法启动排错指北","uri":"/blog/posts/jenkins-service-cannot-be-started/"},{"categories":null,"content":"k8s 环境搭建 Intro 关于组织主题，活动相关介绍\n前期准备 硬件要求\n master节点 内存2核3G(最小2G) node节点 内存2核2G  其中可以\n搭建过程 配置 etc/host\n1 2 3  172.19.0.21 debian-21 172.19.0.22 debian-22 172.19.0.23 debian-23   配置 ssh\napt install openssh-server vim /etc/ssh/sshd_config PermitRootLogin yes\n开启 ipv4 的 forward机制\n1 2 3  vim /etc/sysctl.conf net.ipv4.ip_forward=1 sysctl --system   关闭 swap\nswapoff -a\n安装 runtime （每个节点都需要安装）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  apt install \\  apt-transport-https \\  ca-certificates \\  curl \\  gnupg-agent \\  software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add - add-apt-repository \\  \"deb [arch=amd64] https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/debian \\ $(lsb_release -cs)\\ stable\" apt update apt install docker-ce docker-ce-cli containerd.io   配置 docker\n修改docker配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  vim /etc/docker/daemon.json { \"registry-mirrors\": [ \"https://dockerhub.azk8s.cn\", \"https://reg-mirror.qiniu.com\" ], \"exec-opts\": [\"native.cgroupdriver=systemd\"], \"log-driver\": \"json-file\", \"log-opts\": { \"max-size\": \"100m\" }, \"insecure-registries\": [\"0.0.0.0/0\"], \"storage-driver\": \"overlay2\" }   Kubernates 组件\nMaster 组件\n   Protocol Direction Port Range Purpose Used By     TCP InBound 6443* Kubernetes API server All   TCP InBound 2379-2380 etcd server client API kube-apiserver, etcd   TCP InBound 10250 Kubelet API Self, Control plane   TCP InBound 10251 kube-scheduler Self   TCP InBound 10252 kube-controller-manager Self    Nodes 组件\n   Protocol Direction Port Range Purpose Used By     TCP InBound 10250 Kubelet API Self, Control plane   TCP InBound 30000-32767 NodePort Services All    安装 kebulet kubeadm kubectl （master、node节点都需要安装）\n1 2 3 4 5 6 7 8  apt-get update \u0026\u0026 apt-get install -y apt-transport-https curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - cat \u003c\u003cEOF \u003e/etc/apt/sources.list.d/kubernetes.list deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main EOF apt-get update apt-get install -y kubelet kubeadm kubectl   在 master 节点\n1  kubeadm init --apiserver-advertise-address 172.19.0.21 --pod-network-cidr 10.10.0.0/16 --service-cidr 10.11.0.0/16 --kubernetes-version=v1.15.3 --dry-run   k8s中要注意一下几个网络:\n 机器的网络 pod的网络 集群的网络  ","description":"","tags":null,"title":"k8s 环境搭建","uri":"/blog/posts/k8s-environment-construction/"},{"categories":null,"content":"关于 Jenkins 与 Python Unittest 集成的实践 问题场景 unittest 在 python 中得到了很好的支持， Jenkins 作为自动化工具，可以根据 DSL 写出的 job 自动进行调度与执行。\n这里将把两者结合起来，自动执行单元测试。\n环境搭建  install jenkins by docker make jenkins node have python python lib: xmlrunnser jenkins plugins  构建过程 Pipeline\nPython TestCasae\n测试结果与报告 ","description":"","tags":["jenkins","unittest","python"],"title":"关于 Jenkins 与 Python Unittest 集成的实践","uri":"/blog/posts/practice-on-the-integration-of-jenkins-and-python-unittest/"},{"categories":["Python"],"content":"阅读 Python 源码：collections.abc ABC(Abstract Base Class) 抽象基类。\n要了解为什么 Python 要设计这个，需要先了解到几个概念。\n 鸭子类型 接口协议 继承  与 collections.abc 相关的有两个文件：\n  abc.py\n  _collections_abc.py\n  其中 abc.py 定义了 ABCMeta 和 ABC 类，和一些装饰器：\n函数装饰器：abstractmethod\n装饰器类：abstractclassmethod，abstractstaticmethod，abstractproperty\nABCMeta 类是元类，用来描述和生成 ABC 类。\n代码不长，去除 debug 的一些方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  class ABCMeta(type): \"\"\"Metaclass for defining Abstract Base Classes (ABCs). 定义 ABC 的元类 用此元类创建 ABC，抽象基类能被直接用作子类，行为像 mix-in。以及可以 Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). \"\"\" def __new__(mcls, name, bases, namespace, **kwargs): cls = super().__new__(mcls, name, bases, namespace, **kwargs) _abc_init(cls) return cls def register(cls, subclass): \"\"\"Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. \"\"\" return _abc_register(cls, subclass) def __instancecheck__(cls, instance): \"\"\"Override for isinstance(instance, cls).\"\"\" return _abc_instancecheck(cls, instance) def __subclasscheck__(cls, subclass): \"\"\"Override for issubclass(subclass, cls).\"\"\" return _abc_subclasscheck(cls, subclass) class ABC(metaclass=ABCMeta): \"\"\"Helper class that provides a standard way to create an ABC using inheritance. \"\"\" __slots__ = ()   ABCMeta 生成 ABC 类是通过 _abc_init(cls)，在创建实例的过程中，改变了生成类的属性。\nABCMeata 重写了两个方法，可以被注册为虚拟子类，这就是抽象基类的全部作用。\n","description":"","tags":null,"title":"阅读 Python 源码：collections.abc","uri":"/blog/posts/python/pythonpython-source-code-collectionsabc/"},{"categories":["Python"],"content":"用 Python 实现 LAN 扫描工具  树莓派没装 GUI，插上网线后找不到 IP\n 当然有很多种方法可以解决这个场景\n arp -a 可以查看所在局域网里所有的设备 IP 与 MAC nmap  如果在 Mac 情况下，可以通过 APPStore 下载 LANScan\n这里写一个简单的 python 脚本来达到相似的效果。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64  #!/usr/bin/env python3 # -*- coding: UTF-8 -*- \"\"\" 扫描网关所在子网 Host 信息 \"\"\" import os import sys import netifaces import nmap from collections import namedtuple from prettytable import PrettyTable def switch_root(): \"\"\" 提升到root权限 \"\"\" if os.geteuid(): args = [sys.executable] + sys.argv # 下面两种写法，一种使用su，一种使用sudo，都可以 # os.execlp('su', 'su', '-c', ' '.join(args)) os.execlp('sudo', 'sudo', *args) # 从此处开始是正常的程序逻辑 print('Running at root privilege.') def get_gateway(): \"\"\" 获取默认网关 \"\"\" return netifaces.gateways()['default'][netifaces.AF_INET][0] def lan_scan(gateway): nm = nmap.PortScanner() infos = [] lan_net = gateway + '/24' scan_rst = nm.scan(lan_net, arguments='-sn') scanstats = scan_rst['nmap']['scanstats'] for host in sorted(nm.all_hosts(), key=lambda x: int(x.split('.')[-1])): addr = scan_rst['scan'][host]['addresses']['ipv4'] mac = scan_rst['scan'][host]['addresses'].get('mac', 'None') hostname = scan_rst['scan'][host]['hostnames'][0]['name'] vendor = scan_rst['scan'][host]['vendor'].get(mac, 'None') info = [addr, mac, hostname, vendor] infos.append(info) return infos def print_table(ips_info): table = PrettyTable(['index', 'addr', 'mac', 'hostname', 'vendor']) table.board = True for i, info in enumerate(ips_info): table.add_row([i] + info) print(table) def main(): switch_root() print_table(lan_scan(get_gateway())) if __name__ == \"__main__\": main()   如果想要生成涵盖更多信息的表格，需要调整 nm.scan() 里的 arguments 参数内容。\n","description":"","tags":["network"],"title":"用 Python 实现 LAN 扫描工具","uri":"/blog/posts/python/use-python-to-implement-lan-scanning-tool/"},{"categories":["Python"],"content":"本次 share 介绍如何写出更 pythonic 的 python 代码。\n从两个方面切入:\n第一个方面是介绍 python 的代码风格规范，以目前实践中事实规范 pep8 为标准。\n第二个方面是介绍 python 的一些语言特性，如何利用这些特写编写更优雅的 python 代码\n[toc]\n1. PEP 8: Style Guide for Python Code 以下所有内容包含在官方 PEP(Python Enhancement Proposals) 链接为 [pep8][https://www.python.org/dev/peps/pep-0008/]\n简要版本\n  代码编排\n  缩进。4个空格的缩进（编辑器都可以完成此功能），不使用Tap，更不能混合使用Tap和空格\n 针对不同编辑器兼容性，对 tab 可能有不同的标准，导致样式不统一。\n   每行最大长度79，换行可以使用反斜杠，最好使用圆括号。换行点要在操作符的后边敲回车。\n 早期 unix 主机终端只能显示 80 个字符。\n通过限制所需的编辑器窗口宽度，可以并排打开多个文件，并且在使用在相邻列中显示两个版本的代码查看工具时，效果很好。\n   类和top-level函数定义之间空两行；\n类中的方法定义之间空一行；\n函数内逻辑无关段落之间空一行；\n其他地方尽量不要再空行。\n    文档编排\n  模块内容的顺序：\n模块说明和docstring\nimport\nglobals\u0026constants\n其他定义。\n其中import部分，又按标准、三方和自己编写顺序依次排放，之间空一行。\n  不要在一句import中多个库，比如import os, sys不推荐。 如果采用from XX import XX引用库，可以省略‘module.’，都是可能出现命名冲突，这时就要采用import XX。\n如果有命名冲突。可以使用 from X import Y as Z\n    空格的使用 总体原则，避免不必要的空格。\n 各种右括号前不要加空格。 逗号、冒号、分号前不要加空格。 函数的左括号前不要加空格。如Func(1)。 序列的左括号前不要加空格。如list[2]。 操作符左右各加一个空格，不要为了对齐增加空格。 函数默认参数使用的赋值符左右省略空格。 不要将多句语句写在同一行，尽管使用‘；’允许。 if/for/while语句中，即使执行语句只有一句，也必须另起一行。    命名规范 总体原则，新编代码必须按下面命名风格进行，现有库的编码尽量保持风格。\n 尽量单独使用小写字母‘l’，大写字母‘O’等容易混淆的字母。 模块命名尽量短小，使用全部小写的方式，可以使用下划线。 包命名尽量短小，使用全部小写的方式，不可以使用下划线。 类的命名使用CapWords的方式，模块内部使用的类采用_CapWords的方式。_ 异常命名使用CapWords+Error后缀的方式。 全局变量尽量只在模块内有效，类似C语言中的static。实现方法有两种，一是__all__机制;二是前缀一个下划线 函数命名使用全部小写的方式，可以使用下划线。 常量命名使用全部大写的方式，可以使用下划线。 类的属性（方法和变量）命名使用全部小写的方式，可以使用下划线。 类的属性有3种作用域public、non-public和subclass API，可以理解成C++中的public、private、protected，non-public属性前，前缀一条下划线。 类的属性若与关键字名字冲突，后缀一下划线，尽量不要使用缩略等其他方式。 为避免与子类属性命名冲突，在类的一些属性前，前缀两条下划线。比如：类Foo中声明__a,访问时，只能通过Foo._Foo__a，避免歧义。如果子类也叫Foo，那就无能为力了。 类的方法第一个参数必须是self，而静态方法第一个参数必须是cls。    注释 总体原则，错误的注释不如没有注释。所以当一段代码发生变化时，第一件事就是要修改注释！ 注释必须使用英文，最好是完整的句子，首字母大写，句后要有结束符，结束符后跟两个空格，开始下一句。如果是短语，可以省略结束符。\n 块注释，在一段代码前增加的注释。在‘#’后加一空格。段落之间以只有‘#’的行间隔。比如：  # Description : Module config. # # Input : None # # Output : None  行注释，在一句代码后加注释。比如：x = x + 1 # Increment x 但是这种方式尽量少使用。可以在 Magic Number 时使用。 避免无谓的注释。    文档描述 1 为所有的共有模块、函数、类、方法写docstrings；非共有的没有必要，但是可以写注释（在def的下一行）。 2 如果docstring要换行，参考如下例子,详见PEP 257\n1 2 3 4 5  \"\"\"Return a foobang Optional plotz says to frobnicate the bizbaz first. \"\"\"     编码建议\n  编码中考虑到其他python实现的效率等问题，比如运算符‘+’在CPython（Python）中效率很高，都是Jython中却非常低，所以应该采用.join()的方式。 2 尽可能使用i\n  s is not取代==，比如if x is not None 要优于if x。 3 使用基于类的异常，每个模块或包都有自己的异常类，此异常类继承自Exception。 4 异常中不要使用裸露的except，except后跟具体的exceptions。 5 异常中try的代码尽可能少。比如：\ntry: value = collection[key] except KeyError: return key_not_found(key) else: return handle_value(value) 要优于 try: # Too broad! return handle_value(collection[key]) except KeyError: # Will also catch KeyError raised by handle_value() return key_not_found(key)   使用startswith() and endswith()代替切片进行序列前缀或后缀的检查。比如\nYes: if foo.startswith(‘bar’):优于 No: if foo[:3] == ‘bar’: - 使用isinstance()比较对象的类型。比如 Yes: if isinstance(obj, int): 优于 No: if type(obj) is type(1):   判断序列空或不空，有如下规则\nYes: if not seq: if seq: 优于 No: if len(seq) if not len(seq)   字符串不要以空格收尾。\n  二进制数据判断使用 if boolvalue的方式。\n    2.Effictive python 在第一部分介绍了 Python Codestyle 接受度最广泛的 pep8 后，要想能够写出 pythonic 的代码仍然是不够的。Python 语言有着丰富的语法特性，能让 Python 代码十分优雅。\n接下来介绍的这部分的内容来源于 「 Effective Python 」。\n本次只会介绍一部分有用的特性，结合实际的例子来完成。\n内置序列类型概览  容器序列\nlist、tuple 和 collections.deque 这些序列能存放不同类型的数据。 扁平序列\nstr、bytes、bytearray、memoryview 和 array.array，这类序列只能容纳一种类型。  容器序列存放的是它们所包含的任意类型的对象的引用，而扁平序列里存放的是值而不是引用。换句话说，扁平序列其实是一段连续的内存空间。由此可见扁平序列其实更加紧凑，但是它里面只能存放诸如字符、字节和数值这种基础类型。\n序列类型还能按照能否被修改来分类。\n 可变序列\nlist、bytearray、array.array、collections.deque 和 memoryview。 不可变序列\ntuple、str 和 bytes  列表推导和生成器表达式 列表推导和可读性 列表推导是构建列表(list)的快捷方式，生成器表达式用来穿件其他任何类型的序列。\n1 2 3 4 5 6 7 8 9 10  # 比较两段代码 symbols = 'abcde' codes = [] for symbol in symbols: codes.append(ord(symbol)) print(codes) codes = [ord(symbol) for symbol in symbols] print(codes)   列表推导能够提升可读性。 只用列表推导来创建新的列表，并尽量保持简短（不要超过一行）\n列表推导同 filter 和 map 的比较 1 2 3 4 5 6 7  symbols = 'abcde' beyond_ascii = [ord(s) for s in symbols if ord(s) \u003e 100] print(beyond_ascii) beyond_ascii = list(filter(lambda c: c \u003e 100, map(ord, symbols))) print(beyond_ascii)   [101] [101]  笛卡尔积 1 2 3 4 5 6 7 8 9 10 11  colors = ['black', 'white'] sizes = ['S', 'M', 'L'] tshirts = [(color, size) for color in colors for size in sizes] print(tshirts) tshirts = [(color, size) for size in sizes for color in colors] print(tshirts) # 注意顺序是依照 for-loop 嵌套关系   [('black', 'S'), ('black', 'M'), ('black', 'L'), ('white', 'S'), ('white', 'M'), ('white', 'L')] [('black', 'S'), ('white', 'S'), ('black', 'M'), ('white', 'M'), ('black', 'L'), ('white', 'L')]  生成器表达式 列表推导与生成器表达式的区别：\n 生成器表达式遵守实现了迭代器接口，可以逐个地产出元素。 列表推导是先建立一个完整的列表，再将这个列表传递到构造函数里。 语法上近似，方括号换成圆括号  1 2 3 4 5  # symbols = 'abcde' print(tuple(ord(symbol) for symbol in symbols)) import array print(array.array('I', (ord(symbol) for symbol in symbols)))    如果生成器表达式是一个函数调用过程中的唯一参数，则不需要额外括号 生成器会在 for-loop 运行时才生成一个组合。逐个产出元素  1 2 3 4 5  colors = ['black', 'white'] sizes = ['S', 'M', 'L'] for tshirt in ('%s%s' %(c, s) for c in colors for s in sizes): print(tshirt)   black S black M black L white S white M white L  元祖不仅仅是不可变的列表 元祖与记录  元祖是对数据的记录 元祖的位置信息为数据赋予了意义。对元祖内元素排序，位置信息将丢失  1 2 3 4 5 6 7 8 9 10 11 12 13  # LA 国际机场经纬度 lax_coordinates = (33.9425, -118.408056) # 城市，年份，人口（单位：百万），人口变化（单位：百分比），面积 city, year, pop, chg, area = ('Tokyo', 2003, 32450, 0.66, 8014) # country_code, passport number traveler_ids = [('USA', '31195855'), ('BBA', 'CE342567'), ('ESP', 'XDA205856')] for passport in sorted(traveler_ids): print('%s%s' % passport) # 拆包（unpacking） for country, _ in traveler_ids: print(country)   BBACE342567 ESPXDA205856 USA31195855 USA BBA ESP  元祖拆包  平行赋值  1 2 3 4 5  lax_coordinates = (33.9425, -118.408056) # 元祖拆包 latitude, longtitude = lax_coordinates print(latitude) print(longtitude)   33.9425 -118.408056   交换变量值，不使用中间变量  1 2 3 4 5  a = 3 b = 4 b, a = a, b print(a) print(b)   4 3   * 运算符，把一个可迭代对象拆开作为函数参数  1 2 3 4 5 6 7 8  divmod(20, 8) t = (20, 8) divmod(*t) quotient, remainder = divmod(*t) print(quotient) print(remainder)   2 4   函数用元祖形式返回多个值   _ 用作占位符，可以用来处理不需要的数据\n 1 2 3 4  import os _, filename = os.path.split('/home/xiao/.ssh/id_rsa.pub') print(filename)   id_rsa.pub   用* 处理省下的元素  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  a, b, *rest = range(5) print(a, b, rest) a, b, *rest = range(3) print(a, b, rest) a, b, *rest = range(2) print(a, b, rest) # * 前缀只能用在一个变量前，该变量可出现在赋值表达式中任意位置 a, *body, c, d = range(5) print(a, body, c, d) *head, b, c, d = range(5) print(head, b, c, d)   0 1 [2, 3, 4] 0 1 [2] 0 1 [] 0 [1, 2] 3 4 [0, 1] 2 3 4  嵌套元祖拆包 1 2 3 4 5 6 7 8 9 10 11 12 13  metro_areas = [ ('Tokyo', 'JP', 36.933, (35.689722, 139.691667)), # \u003c1\u003e ('Delhi NCR', 'IN', 21.935, (28.613889, 77.208889)), ('Mexico City', 'MX', 20.142, (19.433333, -99.133333)), ('New York-Newark', 'US', 20.104, (40.808611, -74.020386)), ('Sao Paulo', 'BR', 19.649, (-23.547778, -46.635833)), ] print('{:15} | {:^9} | {:^9}'.format('', 'lat.', 'long.')) fmt = '{:15} | {:9.4f} | {:9.4f}' for name, cc, pop, (latitude, longitude) in metro_areas: # \u003c2\u003e if longitude \u003c= 0: # \u003c3\u003e print(fmt.format(name, latitude, longitude))    | lat. | long. Mexico City | 19.4333 | -99.1333 New York-Newark | 40.8086 | -74.0204 Sao Paulo | -23.5478 | -46.6358  将元祖作为记录仍缺少一个功能：字段命名\n具名元祖(numedtuple) collections.namedtuple 是一个工厂函数，用来构建带字段名的元祖和一个有名字的\n namedtuple 构建的类的实例所消耗的内存和元祖是一样的，因为字段名都存在对应的类里。 实例和普通的对象实例小一点，因为 Python 不会用 __dict__ 存放实例的属性\n 1 2 3 4 5 6 7 8  from collections import namedtuple # 需要两个参数，类名和类各个字段的名字 City = namedtuple('City', 'name country population coordinates') tokyo = City('Tokyo', 'JP', 36.933, (35.689722, 129.691667)) print(tokyo) print(tokyo.population) print(tokyo.coordinates)   City(name='Tokyo', country='JP', population=36.933, coordinates=(35.689722, 129.691667)) 36.933 (35.689722, 129.691667)  namedtuple 除了从普通元祖继承的属性外，还有一些专有属性。 常用的有：\n _fields 类属性 _make(iterable) 类方法 _asdict() 实例方法  1 2 3 4 5 6 7 8  print(City._fields) LatLong = namedtuple('LatLong', 'lat long') delhi_data = ('Delhi NCR', 'IN', 21.935, LatLong(28.613889, 77.208889)) delhi = City._make(delhi_data) print(delhi._asdict()) for key, value in delhi._asdict().items(): print(key + ':', value)   ('name', 'country', 'population', 'coordinates') OrderedDict([('name', 'Delhi NCR'), ('country', 'IN'), ('population', 21.935), ('coordinates', LatLong(lat=28.613889, long=77.208889))]) name: Delhi NCR country: IN population: 21.935 coordinates: LatLong(lat=28.613889, long=77.208889)  切片 在 Python 里, 列表（list），元祖（tuple）和字符串（str）这类序列类型都支持切片操作\n为什么切片的区间会忽略最后一个元素  Python 以0 作为起始下标 当只有后一个位置信息时，可以快速导出切片和区间的元素数量 当起止位置信息课件是，可以快速计算出切片和区间的长度 （stop - start） 可利用任意一个下标把序列分割成不重叠的两部分。my_list[:x] my_list[x:]  1 2 3  ### 对对象进行切片 - 可以通过 s[a🅱️c] 的形式对 s 在 a 和 b 区间以 c 为间隔取值   1 2 3 4  s = 'bicycle' print(s[::3]) print(s[::-1]) print(s[::-2])   bye elcycib eccb  多维切片和省略 [] 运算符可以使用以逗号分开的多个索引或切片。\n如 a[i, j]，a[m:n, k:1]得到二维切片\n要正确处理[] 运算符，对象的特殊方法 __getitem__，__setitem__ 需要以元祖的形式来接受 a[i, j]的索引。\n给切片赋值 切片放在赋值语句左边，或作为 del 操作对象，可以对序列进行嫁接、切除或就地修改\n1 2 3 4 5 6 7 8 9 10 11 12 13  l = list(range(10)) print(l) l[2:5] = [20, 30] print(l) del l[5:7] print(l) l[3::2] = [11, 22] print(l) # l[2:5] = 100 WRONG   [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0, 1, 20, 30, 5, 6, 7, 8, 9] [0, 1, 20, 30, 5, 8, 9] [0, 1, 20, 11, 5, 22, 9]  对序列使用 + 和 *  + 和 * 不修改原有的操作对象，而是构建一个新的序列  1 2 3 4  l = [1, 2, 3] print(l * 5) print(5 * 'abcd')   [1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3] abcdabcdabcdabcdabcd  建立由列表组成的列表  a * n，如果在序列 a 中存在对其他可变变量的引用的话，得到的序列中包含的是 n 个对指向同一地址的引用\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  board = [['_'] * 3 for i in range(3)] # 换一种形式 # board = [] # for i in range(3): # row = ['_'] * 3 # board.append(row) print(board) board[1][2] = 'X' print(board) # weird_board = [['_'] * 3] * 3 # 换一种形式 weird_board = [] row = ['_'] * 3 for i in range(3): weird_board.append(row) weird_board[1][2] = 'O' # 会发现 3 个指向同一列表的引用 print(weird_board)   [['_', '_', '_'], ['_', '_', '_'], ['_', '_', '_']] [['_', '_', '_'], ['_', '_', 'X'], ['_', '_', '_']] [['_', '_', 'O'], ['_', '_', 'O'], ['_', '_', 'O']]  序列的增量赋值 +=、*=  += 背后的特殊方法是 __iadd__ 方法，没有则退一步调用 __add__ 同理 *= 的特殊方法是 __imul__  1 2 3 4 5 6 7 8 9 10 11 12 13 14  l = [1, 2, 3] print(id(l)) l *= 2 print(l) # 列表ID 无改变 print(id(l)) t = (1, 2, 3) print(id(t)) t *= 2 print(t) # 新元祖被创建 print(id(t))   4534358344 [1, 2, 3, 1, 2, 3] 4534358344 4536971408 (1, 2, 3, 1, 2, 3) 4546754024  list.sort方法和内置函数sorted  list.sort 会就地排序列表，方法返回值为 None sorted 会新建一个列表作为返回值 两个方法都有 reverse 和 key 作为可选的关键字参数 reserve 为 True 时，降序输出。默认为 false key 只有一个参数的函数，将被用在序列的每一个元素上，其结果作为排序算法依赖的对比关键字  用bisect管理已排序的序列 bisect 模块有两个主要函数：\n bisect insort 都利用二分查找法来在有序序列中查找或插入人元素  用 bisect 来搜索 bisect(haystack, needle) 默认为升序，haystack 需要保持有序。 使用方法： bisect(index, needle) 查找位置 index，再使用 haystack.insert(index, needle) 插入新值\n也可以用 insort 来一步到位，且后者速度更快\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  # BEGIN BISECT_DEMO import bisect import sys HAYSTACK = [1, 4, 5, 6, 8, 12, 15, 20, 21, 23, 23, 26, 29, 30] NEEDLES = [0, 1, 2, 5, 8, 10, 22, 23, 29, 30, 31] ROW_FMT = '{0:2d} @ {1:2d} {2}{0:\u003c2d}' def demo(bisect_fn): for needle in reversed(NEEDLES): position = bisect_fn(HAYSTACK, needle) # \u003c1\u003e offset = position * ' |' # \u003c2\u003e print(ROW_FMT.format(needle, position, offset)) # \u003c3\u003e if __name__ == '__main__': if sys.argv[-1] == 'left': # \u003c4\u003e bisect_fn = bisect.bisect_left else: bisect_fn = bisect.bisect print('DEMO:', bisect_fn.__name__) # \u003c5\u003e print('haystack -\u003e', ' '.join('%2d' % n for n in HAYSTACK)) demo(bisect_fn) # END BISECT_DEMO   DEMO: bisect_right haystack -\u003e 1 4 5 6 8 12 15 20 21 23 23 26 29 30 31 @ 14 | | | | | | | | | | | | | |31 30 @ 14 | | | | | | | | | | | | | |30 29 @ 13 | | | | | | | | | | | | |29 23 @ 11 | | | | | | | | | | |23 22 @ 9 | | | | | | | | |22 10 @ 5 | | | | |10 8 @ 5 | | | | |8 5 @ 3 | | |5 2 @ 1 |2 1 @ 1 |1 0 @ 0 0  Array  虽然列表既灵活又简单，但面对各类需求时，我们可能会有更好的选择。比如，要存放 1000 万个浮点数的话，数组（array）的效率要高得多，因为数组在背后存的并不是 float 对象，而是数字的机器翻译，也就是字节表述。这一点就跟 C 语言中的数组一样。再比如说，如果需要频繁对序列做先进先出的操作，deque（双端队列）的速度应该会更快。\n array.tofile 和 fromfile 可以将数组以二进制格式写入文件，速度要比写入文本文件快很多，文件的体积也小。\n 另外一个快速序列化数字类型的方法是使用 pickle（https://docs.python.org/3/library/pickle.html）模块。pickle.dump 处理浮点数组的速度几乎跟array.tofile 一样快。不过前者可以处理几乎所有的内置数字类型，包含复数、嵌套集合，甚至用户自定义的类。前提是这些类没有什么特别复杂的实现。\n array 具有 type code 来表示数组类型：具体可见 array 文档.\nmemoryview  memoryview.cast 的概念跟数组模块类似，能用不同的方式读写同一块内存数据，而且内容字节不会随意移动。\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  import array arr = array.array('h', [1, 2, 3]) memv_arr = memoryview(arr) # 把 signed short 的内存使用 char 来呈现 memv_char = memv_arr.cast('B') print('Short', memv_arr.tolist()) print('Char', memv_char.tolist()) memv_char[1] = 2 # 更改 array 第一个数的高位字节 # 0x1000000001 print(memv_arr.tolist(), arr) print('-' * 10) bytestr = b'123' # bytes 是不允许更改的 try: bytestr[1] = '3' except TypeError as e: print(repr(e)) memv_byte = memoryview(bytestr) print('Memv_byte', memv_byte.tolist()) # 同样这块内存也是只读的 try: memv_byte[1] = 1 except TypeError as e: print(repr(e))   Deque collections.deque 是比 list 效率更高，且线程安全的双向队列实现。\n除了 collections 以外，以下 Python 标准库也有对队列的实现：\n queue.Queue (可用于线程间通信) multiprocessing.Queue (可用于进程间通信) asyncio.Queue heapq  ","description":"","tags":["python","codestyle"],"title":"如何让你的代码更 Pythonic","uri":"/blog/posts/python/make-your-code-more-pythonic/"},{"categories":["Python"],"content":"使用 Unittest 组织 TestCase 的工程结构 单文件的 TestCase 很容易被执行，只需用执行命令 python test_xxx.py。\n随着 TestCase 的增多，我们可能面对这样的情况：\n 执行多个 TestCase 作为一组被执行 指定某一些 TestCase 执行  此时我们需要把 TestCase 按照一定层次结构组织。\n环境  Python 3+  TestLoader 在 import unittest 时，会自动导入 TestLoader 类，在类中封装了 5 中组织 TestCase 的方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  class TestLoader(object): \"\"\" 该类负责根据各种标准加载测试并将它们包装在TestSuite中 \"\"\" def loadTestsFromTestCase(self, testCaseClass): \"\"\" 返回testCaseClass中包含的所有测试用例的套件 \"\"\" def loadTestsFromModule(self, module, *args, pattern=None, **kws): \"\"\" 返回给定模块中包含的所有测试用例的套件 \"\"\" def loadTestsFromName(self, name, module=None): \"\"\" 返回给定用例名的测试用例的套件 \"\"\" def loadTestsFromNames(self, names, module=None): \"\"\" 返回给定的一组用例名的测试用例的套件 \"\"\" def discover(self, start_dir, pattern='test*.py', top_level_dir=None): \"\"\" 查找并返回指定的起始目录中的所有测试模块，递归到子目录中以查找它们并返回在其 中找到的所有测试。仅加载与模式匹配的测试文件。 必须可以从项目的顶层导入测试模块。如果起始目录不是顶级目录，则必须单独指定顶级目录。 \"\"\" defaultTestLoader = TestLoader() \"\"\" defaultTestLoader是TestLoader()的实例对象 \"\"\"   Unittest 组织 TestCase 的方式 工程目录 1 2 3 4 5 6 7 8 9 10  test ├── run_from_discover.py ├── run_from_test_case_class.py ├── run_from_test_case_moudle.py ├── run_from_test_case_name.py ├── run_from_test_case_names.py └── test_case ├── __init__.py ├── test_add.py └── test_sub.py    test_case 用来放置 TestCase 的实现 test_case 需要组织为包（包含 __init__.py） run_from_*.py 为测试执行入口  1. 加载测试类中的用例 1  loadTestsFromTestCase(self, testCaseClass)    使用loadTestsFromTestCase这个方法，需传入unittest测试类的类名 以项目为例子，传入 testCaseClass ：AddCase  run_from_test_case_class.py\n1 2 3 4 5 6 7 8  # encoding:utf8 import unittest from test_case.test_add import AddCase cases = unittest.TestLoader().loadTestsFromTestCase(AddCase) runner = unittest.TextTestRunner(verbosity=2) runner.run(cases)   运行\n1 2 3 4 5  python run_from_test_case_class.py test_add_1 (test_case.test_add.AddCase) 加法冒烟测试 ... ok test_add_2 (test_case.test_add.AddCase) ... FAIL   2、加载模块中的测试用例 1  loadTestsFromModule(self, module, *args, pattern=None, **kws)    使用loadTestsFromModule这个方法，需传入被测试模块 以项目为例子，传入参数 module ：test_add  run_from_test_case_moudle.py\n1 2 3 4 5 6 7 8  # encoding:utf8 import unittest from test_case import test_add cases = unittest.TestLoader().loadTestsFromModule(test_add) runner = unittest.TextTestRunner(verbosity=2) runner.run(cases)   运行 run_from_test_case_moudle.py\n1  python run_from_test_case_moudle.py   运行结果\n1 2 3  test_add_1 (test_case.test_add.AddCase) 加法冒烟测试 ... ok test_add_2 (test_case.test_add.AddCase) ... FAIL   3、加载指定的单个测试用例 1  loadTestsFromName(self, name, module=None)    使用loadTestsFromName这个方法，需传入测试用例的方法名 传入测试用例的方法名格式：moudleName.testCaseClassName.testCaseName 以项目为例子，我想测试test_add.py 里面的用例 test_add_1 我需要传入的参数 name：test_add.AddCase.test_add_1 loadTestsFromName这个方法是在 sys.path 里面的路径去寻找测试模块test_add.py,然后再寻找测试类AddCase 最后再寻找测试用例test_add_1  run_from_case_name.py\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  # encoding:utf8 import unittest import os import sys # 获取 \"how_to_run_test_case\" 的绝对路径 dir_run_test_case = os.path.dirname(os.path.abspath(__file__)) # 获取 \"test_case\" 的绝对路径 dir_test_case = dir_run_test_case + '/test_case' # 把 \"test_case\" 的绝对路径 加入 sys.path sys.path.insert(0,dir_test_case) case= unittest.TestLoader().loadTestsFromName('test_add.AddCase.test_add_1') runner = unittest.TextTestRunner(verbosity=2) runner.run(cases)   运行 run_from_case_name.py\n1  python run_from_case_name.py   运行结果\n1 2  test_add_1 (test_add.AddCase) 加法冒烟测试 ... ok   4、加载指定的多个测试用例 1  loadTestsFromNames(self, names, module=None)    使用loadTestsFromNames这个方法,需要传入一个数组 数组里面里面的元素必须是字符串 数组元素可以是模块、类、方法 数组元素 - 传入格式1：moudleName 数组元素 - 传入格式2：moudleName.testCaseClassName 数组元素 - 传入格式3：moudleName.testCaseClassName.testCaseName 以项目为例，我想测试test_add.py 里面的用例 test_add_1 ，以及test_sub.py 里面的用例 test_sub_1 我需要传入的参数 names：['test_sub.SubCase.test_sub_2','test_add.AddCase.test_add_1'] loadTestsFromNames这个方法是在 sys.path 里面的路径去寻找匹配的测试用例 执行用例是根据数组元素的的顺序执行  run_from_case_names.py\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  # encoding:utf8 import unittest import sys import os # 获取 \"how_to_run_test_case\" 的绝对路径 dir_run_test_case = os.path.dirname(os.path.abspath(__file__)) # 获取 \"test_case\" 的绝对路径 dir_test_case = dir_run_test_case + '/test_case' # 把 \"test_case\" 的绝对路径 加入 sys.path sys.path.insert(0,dir_test_case) cases = ['test_sub.SubCase.test_sub_1','test_add.AddCase.test_add_1'] suite = unittest.TestLoader().loadTestsFromNames(cases) runner = unittest.TextTestRunner(verbosity=2) runner.run(suite)   运行 run_from_case_names.py\n1  python run_from_case_names.py   运行结果\n1 2 3 4  test_sub_1 (test_sub.SubCase) 减法冒烟测试 ... ok test_add_1 (test_add.AddCase) 加法冒烟测试 ... ok   5、加载指定目录下所有的测试用例 1  discover(self, start_dir, pattern='test*.py', top_level_dir=None)    start_dir ： 查找用例的起始目录 pattern='test*py' : 查找模块名为test开头的python文件 top_level_dir=None ：测试模块顶级目录  run_from_discover.py\n1 2 3 4 5 6 7 8 9 10 11  # encoding:utf8 import unittest import os dir_how_to_run_test_case = os.path.dirname(os.path.abspath(__file__)) dir_test_case = dir_how_to_run_test_case + '/test_case' cases = unittest.defaultTestLoader.discover(dir_test_case) runner = unittest.TextTestRunner(verbosity=2) runner.run(cases)   运行 run_from_discover.py\n1  python run_from_discover.py   运行结果\n1 2 3 4 5 6  test_add_1 (test_add.AddCase) 加法冒烟测试 ... ok test_add_2 (test_add.AddCase) ... FAIL test_sub_1 (test_sub.SubCase) 减法冒烟测试 ... ok test_sub_2 (test_sub.SubCase) ... FAIL   ","description":"","tags":["unitest"],"title":"使用 Unittest 组织 TestCase 的工程结构","uri":"/blog/posts/python/organize-the-project-structure-of-testcase-in-unittest/"},{"categories":null,"content":"使用 Bash严格模式  原文链接：Use Bash Strict Mode (Unless You Love Debugging)\n翻译：YueChuan\n在 Unix/Linux 环境很难避免与 Bash 脚本打交道，一份高质量，可靠且可维护的 Bash 脚本应该怎么写？\n本文将提供一些技巧帮助你解决这些问题...\n 让我们开门见山，直接上 PUNCHLINE。\n如果你的 Bash 脚本以这段代码开始，它们将变得更加健壮，可靠和可维护：\n1 2 3  #!/bin/bash set -euo pipefail IFS=$'\\n\\t'    [toc]\n我将此称为非官方的 bash严格模式 。\n这导致 bash 的执行过程中，许多种类的细微错误无法出现。您将花费更少的时间进行调试，并避免在生产环境中出现意想不到的复杂情况。\n这里有一个短期的弊端：这些设置使某些常见的 bash 习惯用法更难使用。大多数情况都有简单的解决方法，详细说明如下：跳至 Issues＆Solutions。\n但首先，让我们看一下这些晦涩难懂的行的实际上做了什么。\nset 语句 这些行故意导致脚本失败。等等，发生了什么？相信我，这是一件好事。使用这些设置，某些常见错误将导致脚本 立即 明确且显然地失败。否则，您将收获在生产环境中爆炸后才发现的隐藏错误。\nset -euo pipefail 的缩写：\n1 2 3  set -e set -u set -o pipefail   让我们分别看一下。\nset -e set -e 如果任何命令[1] 的退出状态为非零，则该选项指示 bash 立即退出。\n您不想为命令行shell设置它，但是在脚本中它很有帮助。在所有广泛使用的通用编程语言中，未处理的运行时错误（无论是Java中引发的异常，还是C中的分段错误，还是Python中的语法错误）都立即停止程序的执行；随后的行不执行。\n默认情况下，bash所做的没有做到这一点。如果您在命令行上使用bash，则此默认行为正是您想要的-您不希望输入错误将您注销！但是在脚本中，您真的想要相反。如果脚本中的一行失败，但最后一行成功，则整个脚本具有成功的退出代码。这样很容易错过该错误。\n同样，在将bash用作命令行shell并将其在脚本中使用时，您想要的与这里不一致。在脚本中容忍错误要好得多，这就是set -e给您带来的好处。\nset -u set -u  影响变量。\n设置后，对您之前未定义的任何变量的引用( $* 和 $@ 除外) 都会发生错误，并导致程序立即退出。出于各种缘由，Python，C，Java等语言都具有相同的行为方式。其中之一就是错别字没有意识到就不会创建新变量。例如：\n1 2 3 4  #!/bin/bash firstName=\"Aaron\" fullName=\"$firstnameMaxwell\" echo \"$fullName\"   花一点时间看看。看到错误了吗？\n第三行的右侧显示“ firstname”（全部小写），而不用驼峰式的“ firstName”。如果没有-u选项，这将是一个无提示错误。但是，使用-u选项，脚本将以退出代码1退出该行，并将消息“ firstname：unbound variable”输出到stderr。\n这就是您想要的：让它明确且立即失败，而不是创建可能为时已晚的细微错误。\nset -o pipefail 此设置可防止掩盖管道中的错误。如果管道中的任何命令失败，则该返回码将用作整个管道的返回码。默认情况下，管道的返回码是最后一个命令的返回码-即使成功。想象一下在文件中找到匹配行的排序列表：\n1 2 3 4  % grep some-string /non/existent/file | sort grep: /non/existent/file: No such file or directory echo $? 0    %是bash提示\n 在这里，grep的退出代码为2，将错误消息写入stderr，将空字符串写入stdout。然后，此空字符串通过sort传递，该字符串愉快地接受它作为有效输入，并返回状态代码0。这对于命令行很好，但对shell脚本则不利：您几乎肯定希望脚本立即退出具有非零的退出代码...就像这样：\n1 2 3 4 5  1. % set -o pipefail 2. % grep some-string /non/existent/file | sort 3. grep: /non/existent/file: No such file or directory 4. % echo $? 5. 2   设置IFS IFS(Internal Field Separator) 设置 Bash 的分隔符。\n当设置为字符串时，Bash会考虑字符串中的每个字符以分隔单词。这决定了bash如何遍历序列。例如，此脚本：\n1 2 3 4 5 6 7 8 9 10 11  1. #!/bin/bash 2. IFS=$' ' 3. items=\"a b c\" 4. for x in $items; do 5. echo \"$x\" 6. done 7. 8. IFS=$'\\n' 9. for y in $items; do 10. echo \"$y\" 11. done   ...将打印出以下内容：\n1 2 3 4  a b c a b c   在第一个for循环中，IFS设置为$' '。（ $'...'语法创建一个字符串，用反斜杠转义的字符替换为特殊字符-例如，“ \\ t”代表制表符，“ \\ n”代表换行符。）\n在for循环中，x和y设置为bash认为是“单词”的任何值”以原始顺序显示。对于第一个循环，IFS是一个空格，这意味着单词由空格字符分隔。对于第二个循环，“单词”由 换行符分隔，这意味着bash将“ items”的整个值视为一个单词。如果IFS超过一个字符，则将对这些字符中的任何一个进行拆分。\n知道了吗？下一个问题是，为什么我们将IFS设置为由制表符和换行符组成的字符串？因为在循环中迭代时，它为我们提供了更好的行为。“更好”的意思是“引起意外和令人困惑的错误的可能性要小得多”。这在使用bash数组时很明显：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  1. #!/bin/bash 2. names=( 3. \"Aaron Maxwell\" 4. \"Wayne Gretzky\" 5. \"David Beckham\" 6. \"Anderson da Silva\" 7. ) 8. 9. echo \"With default IFS value...\" 10. for name in ${names[@]}; do 11. echo \"$name\" 12. done 13. 14. echo \"\" 15. echo \"With strict-mode IFS value...\" 16. IFS=$'\\n\\t' 17. for name in ${names[@]}; do 18. echo \"$name\" 19. done   （是的，我把我的名字列在了不起的运动员名单上。放飞自我~）\n这是输出：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  With default IFS value... Aaron Maxwell Wayne Gretzky David Beckham Anderson da Silva With strict-mode IFS value... Aaron Maxwell Wayne Gretzky David Beckham Anderson da Silva   或者考虑一个以文件名作为命令行参数的脚本：\n1 2 3  1. for arg in $@; do 2. echo \"doing something with file: $arg\" 3. done   如果您将其调用为myscript.sh notes todo-list 'My Resume.doc'，则使用默认的IFS值，第三个参数将被误解析为两个单独的文件-名为“ My”和“ Resume.doc”。实际上，它是一个包含空格的文件，名为“ My Resume.doc”。\n哪种行为更普遍有用？当然，第二个-我们有能力不分割空格。如果我们有一个通常包含空格的字符串数组，通常我们希望逐项迭代它们，而不是将单个项拆分为多个。\n将IFS设置为$'\\n\\t'意味着仅在换行符和制表符上会发生单词拆分。这通常会产生有用的拆分行为。默认情况下，bash将此设置为$' \\n\\t'-空格，换行符，制表符-这太急了。[2]\n问题与解决方案 多年来，我一直在使用非官方的bash严格模式。在这一点上，它总是立即为我节省时间和调试麻烦。但是起初这是具有挑战性的，因为在这些情况下，我的许多惯常习惯和成语都不起作用。本文的其余部分列出了您可能遇到的一些问题，以及如何快速解决这些问题。\n（如果遇到问题，在这里看不到，请给我发电子邮件，我会尽力提供帮助。）\n 采购不合格的文件 位置参数 故意未定义的变量 您期望具有非零退出状态的命令 基本清理 短路注意事项 反馈/如果卡住  采购不合格的文件 有时，您的脚本需要获取无法在严格模式下使用的文件。然后怎样呢？\n1 2 3  source some/bad/file.env ＃您的严格模式脚本会立即退出此处， ＃出现致命错误。   解决方案是（a）暂时禁用严格模式的该方面；（b）出示文件；然后（c）在下一行重新启用。\n您最需要的时间是文档引用未定义的变量。暂时允许以下行为set +u：\n1 2 3  1. set +u 2. source some/bad/file.env 3. set -u    请记住，set +u 禁用此变量严格性并将其set -u 启用。这有点违反直觉，因此在这里要小心。\n 您过去在Python虚拟环境中需要这样做。如果您不熟悉Python：您可以设置一个自定义的隔离环境-称为virtualenv-存储在一个名为“ venv”的目录中。您通过在以下位置获取名为“ bin / activate”的文件来选择使用此文件：\n1 2 3 4 5 6 7  ＃这将更新PATH并将PYTHONPATH设置为 ＃使用预配置的虚拟环境。 source /path/to/venv/bin/activate ＃现在所需的Python版本就在您的路径中， ＃与您需要的一组特定库。 python my_program.py   在现代版本的Python中，这在bash严格模式下非常有效。但是，较旧的虚拟环境（还很年轻，您可能仍然会遇到它们）无法与-u选项一起正常使用：\n1 2 3 4 5 6  1. set -u 2. source /path/to/venv/bin/activate 3. _OLD_VIRTUAL_PYTHONHOME: unbound variable _OLD_VIRTUAL_PYTHONHOME：未绑定变量 ＃这会使您的严格模式脚本退出并出现错误。   没问题，您只需使用上面的模式：\n1 2 3  1. set +u 2. source /path/to/venv/bin/activate 3. set -u   以我的经验，原始文档很少需要 -e或被-o pipefail禁用。但是，如果遇到这种情况，您将以相同的方式处理它。\n位置参数 -u如果进行任何未定义的变量引用（$*或除外），则此设置将导致脚本立即退出 $@。但是，如果您的脚本采用位置参数- $1，$2等等-并且您想要验证是否提供了该怎么办？考虑以下脚本 sayhello.sh：\n如果您自己运行“ sayhello.sh”，则会发生以下情况：\n％./sayhello.sh ./sayhello.sh：第3行：$ 1：未绑定变量 最无用的错误消息。解决方案是使用参数默认值。这个想法是，如果在运行时引用了一个未定义的变量，则bash具有使用“：-”运算符声明默认值的语法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  ＃尚未设置变量 $foo，在严格模式下 ＃下一行触发错误。 bar=$foo # 如果未定义VARNAME，则＃$ {VARNAME：-DEFAULT_VALUE}等于DEFAULT_VALUE。 ＃ 因此，在这里，$ bar设置为“ alpha”： bar=${foo:-alpha} ＃现在我们显式设置foo： foo =“beta” ＃...，默认值将被忽略。这里$ bar设置为“ beta”： bar=${foo:-alpha} ＃要将默认值设置为空字符串，请使用$ {VARNAME：-} empty_string=${some_undefined_var:-}   在严格模式下，需要将其用于所有位置参数引用：\n1 2 3 4 5 6 7 8  1. #!/bin/bash 2. set -u 3. name=${1:-} 4. if [[ -z \"$name\" ]]; then 5. echo \"usage: $0NAME\" 6. exit 1 7. fi 8. echo \"Hello, $name\"   故意未定义的变量 在默认模式下，对未定义变量的引用将得出一个空字符串-有时会依赖此行为。在严格模式下，这不是一个选择，并且有两种方法可以解决它。我认为最好的方法是在脚本的任何位置对其进行引用之前，将变量明确设置为空字符串：\n1 2 3 4 5 6  someVar = “” ＃... ＃可能设置或未设置someVar的代码行 ＃... if [[ -z \"$someVar\" ]]; then ＃...   一种替代方法是使用${someVar:-}语法作为默认值，如Positional Parameters下所述。那里的问题是，有可能忘记而只是说 $someVar，而且输入更多。只需在脚本顶部显式设置默认值即可。那就没有办法咬你了。\n您期望具有非零退出状态的命令 当您想运行将失败的命令，或者您知道将拥有非零退出代码时，会发生什么？您不希望它停止脚本，因为这实际上是正确的行为。\n这里有两个选择。通常，您最想使用的最简单的方法是|| true在命令后附加“ ”：\n1 2 3 4 5 6 7 8 9 10 11 12 13  ＃“ grep -c”报告匹配的行数。如果数字是0， ＃然后grep的退出状态为1，但我们不在乎-我们只想 ＃知道匹配数目，即使该数目为零。 ＃在严格模式下，下一行因错误而中止： count=$(grep -c some-string some-file) ＃但是这一行为表现得更好： 1. count=$(grep -c some-string some-file || true) 2. 3. echo \"count: $count\"   布尔运算符的这种短路使内部表达式 $( ... )始终可以成功求值。\n您可能会发现这种技巧几乎总是可以解决您的问题。但是，如果您想知道命令的返回值，即使该返回值非零怎么办？然后，您可以暂时禁用立即退出选项：\n1 2 3 4 5 6 7 8 9 10 11  ＃我们以set -e开始此脚本。然后... 1. set +e 2. count=$(grep -c some-string some-file) 3. retval=$? 4. set -e ＃当一行或多行匹配时，grep的返回码为0； ＃1，如果没有行匹配；和2错误。这个图案 ＃让我们区分它们。 1. echo \"return value: $retval\" 2. echo \"count: $count\"   基本清理 假设您的脚本结构如下：\n 筹集一些昂贵的资源 用它做点什么 释放该资源，使其不会持续运行并产生巨额账单  对于“昂贵的资源”，这可能像EC2实例那样花费您的实际钱。或者，它可能是一些更小-就像一个临时目录-要创建脚本来使用，那么一定要删除一旦完成（所以它不会泄露存储等）的set -e选项，它错误可能会导致您的脚本在执行清理之前退出，这是不可接受的。\n解决方案：使用bash出口陷阱。链接的文章详细解释了这一重要模式，我强烈建议您精通此技术-在工具箱中使用它会显着提高脚本的健壮性和可靠性。简而言之，您将定义一个bash函数来执行清理或释放资源，然后注册要在退出时自动调用的函数。这是使用它来稳健清除暂存目录的方法：\n1 2 3 4 5 6 7 8 9  1. scratch=$(mktemp -d -t tmp.XXXXXXXXXX) 2. function finish { 3. rm -rf \"$scratch\" 4. } 5. trap finish EXIT 6. 7. # Now your script can write files in the directory \"$scratch\". 8. # It will automatically be deleted on exit, whether that's due 9. # to an error, or normal completion.   短路注意事项 严格模式的全部目的是将许多隐藏的，间歇的或微妙的错误转换为直接的，显而易见的错误。但是，严格模式会引起一些特殊的短路问题。“短路”是指用\u0026\u0026或||- 将多个命令链接在一起，例如：\n1 2  1. # Prints a message only if $somefile exists. 2. [[ -f \"$somefile\" ]] \u0026\u0026 echo \"Found file: $somefile\"   当连续链接三个或更多命令时，可能会出现第一个短路问题：\n1 2 3  1. first_task \u0026\u0026 second_task \u0026\u0026 third_task 2. # And more lines of code following: 3. next_task   潜在的问题：如果second_task失败， third_task将无法运行，并且next_task在本示例中，执行将继续到下一行代码- 。这可能正是您想要的行为。或者，您可能打算如果second_task失败，则脚本应立即以错误代码退出。在这种情况下，最好的选择是使用一个块-即花括号：\n1 2 3 4 5  1. first_task \u0026\u0026 { 2. second_task 3. third_task 4. } 5. next_task   因为我们正在使用该-e选项，所以如果 second_task失败，脚本将立即退出。\n第二个问题确实存在。使用以下常见用法时，它可能会潜行：\n1 2  1. # COND \u0026\u0026 COMMAND 2. [[ -f \"$somefile\" ]] \u0026\u0026 echo \"Found file: $somefile\"   人们写作时COND \u0026\u0026 COMMAND，通常的意思是“如果COND成功（或布尔值为true），则执行COMMAND。无论如何，请继续执行脚本的下一行。” 对于完整的“ if / then / fi”子句来说，这是非常方便的简写。但是，当这样的构造是文件的最后一行时，严格模式可以为脚本提供令人惊讶的退出代码：\n1. % cat short-circuit-last-line.sh 2. #!/bin/bash 3. set -euo pipefail 4. # omitting some lines of code... 5. 6. # Prints a message only if $somefile exists. 7. # Note structure: COND \u0026\u0026 COMMAND 8. [[ -f \"$somefile\" ]] \u0026\u0026 echo \"Found file: $somefile\" 9. 10. % ./short-circuit-last-line.sh 11. % echo $? 12. 1 当脚本到达最后一行时，$somefile实际上 并不存在。因此COND评估为假，并且COMMAND没有执行-这应该发生。但是该脚本以非零的退出代码退出，这是一个错误：该脚本实际上已正确执行，因此它实际上应该以0退出。实际上，如果最后一行代码是其他内容，那正是我们所得到的：\n1. % cat short-circuit-before-last-line.sh 2. #!/bin/bash 3. set -euo pipefail 4. # omitting some lines of code... 5. 6. # Prints a message only if $somefile exists. 7. # Structure: COND \u0026\u0026 COMMAND 8. # (When we run this, $somefile will again not exist, 9. # so COMMAND will not run.) 10. [[ -f \"$somefile\" ]] \u0026\u0026 echo \"Found file: $somefile\" 11. 12. echo \"Done.\" 13. 14. % ./short-circuit-before-last-line.sh 15. Done. 16. % echo $? 17. 0 这是怎么回事？事实证明，该-e选项在这样的短路表达式中有一个特殊的例外：如果COND 计算结果为false，COMMAND将不会运行，并且执行流程将进行到下一行。但是，整行的结果-整个短路表达式-将为非零，因为COND是。作为脚本的最后一行，它成为程序的退出代码。\n这是我们不希望遇到的错误，因为它可能是微妙的，不明显的并且难以复制。而且它主要很难处理，因为仅当它是文件的最后一个命令时才会显示。在任何其他行上，它的行为都很好，不会造成任何问题。在正常的日常开发中，很容易忘记这一点，并使其从裂缝中溜走。例如，如果您从头删除看起来无害的echo语句，使短路线现在最后，该怎么办？\n在上面的特定示例中，我们可以在完整的“ if”子句中扩展表达式。这是完美的行为：\n1 2 3 4 5 6 7 8 9 10 11 12  1. # Prints a message only if $somefile exists. 2. if [[ -f \"$somefile\" ]]; then 3. echo \"Found file: $somefile\" 4. fi 5. 6. # If COND is a command or program, it works the same. This: 7. first_task \u0026\u0026 second_task 8. 9. # ... becomes this: 10. if first_task; then 11. second_task 12. fi   最终的完整解决方案是什么？您可以决定信任自己和您的队友，以始终记住这一特殊情况。所有人都可以随意使用短路功能，但是对于实际部署的任何内容，都不允许短路表达式位于脚本的最后一行。对于您和您的团队来说，这可能100％可靠地起作用，但我认为对于我自己和许多其他开发人员而言并非如此。当然，某种类型的linter或commit钩子可能会有所帮助。\n也许更安全的选择是决定根本不使用短路，而始终使用完整的if语句。但是，这可能并不吸引人：短路很方便，人们出于某种原因喜欢这样做。目前，我仍在寻找更令人满意的解决方案。如果您有任何建议，请与我联系。\n反馈/如果卡住 如果您有任何反馈或改进建议，我很想听听。通过电子邮件与我（Aaron Maxwell）取得联系，网址为redsymbol dot net的最大值。\n相反，如果您发现严格模式会导致上述问题（我没有告诉您如何解决），我也想知道。给您发送电子邮件时，请在电子邮件正文（而不是附件）中包含一个最小的 bash脚本，以演示该问题。还要非常清楚地说明所需的输出或效果，以及您得到的错误或失败。如果您的脚本不是某个标识符很钝的巨型怪兽，那么我很有可能会得到响应，而我将不得不在整个下午进行解析。\n脚注  [1]具体来说，如果有管道；括号中的任何命令；或以大括号形式作为命令列表的一部分执行的命令以非零退出状态退出，脚本立即以相同状态退出。这还有其他一些细微之处。有关详细信息，请参见内置bash“ set”的文档。 [2]另一种方法：不更改IFS，而是从循环开始for arg in \"$@\"-用双引号覆盖迭代变量。这将改变循环语义以产生更好的行为，甚至更好地处理一些边缘情况。最大的问题是可维护性。即使是经验丰富的开发人员，也很容易忘记加双引号。即使原始作者已经成功地根深蒂固了这个习惯，但期望所有未来的维护者都会愚蠢。简而言之，依靠引号很可能会引入细微的定时炸弹错误。设置IFS使其不可能。  ","description":"","tags":["bash"],"title":"使用 Bash 严格模式","uri":"/blog/posts/use-bash-strict-mode/"},{"categories":null,"content":" 之前介绍过 Expect 作为处理程序交互工具的使用。\n结合串口命令以及 Expect 读取输入输出，针对一些具有固定流程而且能通过输出判断命令执行情况的测试用例，可以实现基于串口的测试自动化。\n 问题 在使用串口调试过程中，需要手动输入执行命令，交互性输入，以及等待执行结果。基本所有的信息都在 tty 中串行的进行显示。痛点有下面几个\n 重复命令手动输入执行 交互性输入 等待执行信息，不能自动保存到文件 串口调试环境本身edit 便利性  基于以上的问题，需要存在需求：\n 可以将执行命令存放脚本中，而且可以去调用执行 可处理交互性输入 对于执行命令输出可以保存到 log 文件  基本方案   基于 SecureCRT\nSecureCRT 脚本，使用 python 语言\n优点：\n GUI 界面，操作直观 python syntax 语法特性支持强大  缺点：\n SecureCRT 过重，本身安装麻烦 仍然需要基本交互，SecureCRT 内调用脚本 与 jenkins 的集成    基于 Terminal 环境\n首先要解决的是串口环境，这里使用 picocom 命令行工具，类似的有 minicom 等。\n其次，针对需要交互行输入，使用 Expect 处理，Expect 基于 TCL (Tool control language）\n最后，得到的 .expect 脚本可以通过 Jenkins pipeline 进行调用。\n优点：\n 轻量化，可通过命令行安装 所有过程都在 Terminal 操作 集成到 Jenkins，完全支持自动化流程  缺点：\n picocom 在功能性方面较弱    ##实际解决\n针对上面两种方案，如果是非重复性调试，使用前者上手更快。\n如果有需要多次重复性，或者自动化测试需求，选择后者。\n下面给出使用 Expect 的一个 demo：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76  #!/usr/bin/expect # -d: debug mode # expect config set timeout 30 log_file test-expect.log # picocom config set baudrate \"115200\" set device \"/dev/ttyUSB0\" set prompt \"=\u003e\" # function define set interval 5 set iter_cnt 10 proc start_xvr_debug { prompt } { send \"xvr_client_dbus\\r\" expect $prompt } proc test_switch_channel_display { iter_cnt interval prompt } { for { set i 1 } { $i \u003c $iter_cnt } { incr i 1 } { send \"switch_channel_display -cam 0 -ch 0 -onoff 1\\r\" expect $prompt exec sleep $interval send \"switch_channel_display -cam 0 -ch 0 -onoff 0\\r\" expect $prompt exec sleep $interval send \"switch_channel_display -cam 0 -ch 1 -onoff 1\\r\" expect $prompt exec sleep $interval send \"switch_channel_display -cam 0 -ch 1 -onoff 0\\r\" expect $prompt exec sleep $interval } } proc test_start_stop_pipeline { iter_cnt interval prompt } { for { set i 1 } { $i \u003c $iter_cnt } { incr i 1 } { send \"stop_pipeline /dev/xvr_pipeline-0\\r\" expect $prompt exec sleep $interval send \"stop_pipeline /dev/xvr_pipeline-1\\r\" expect $prompt exec sleep $interval send \"start_pipeline /dev/xvr_pipeline-0\\r\" expect $prompt exec sleep $interval send \"start_pipeline /dev/xvr_pipeline-1\\r\" expect $prompt exec sleep $interval } } spawn picocom -b $baudrate $device expect \"Terminal ready\\r\" send \"\\r\" # send \"xvr_client_dbus\\r\" # expect $prompt start_xvr_debug $prompt test_switch_channel_display $iter_cnt $interval $prompt # test_start_stop_pipeline $iter_cnt $interval $prompt expect eof # interact wait   在具体使用中遇到的有几个小坑:\n 集成到 jenkins 时，jenkins 用户无法获得 /dev/ttyUSB0 权限。 sudo  执行 Expect 脚本进程 kill  详情见尾注意小节。\n参考  SecureCRT-python-scripts SecureCRT Offical demo Expect manual Expect 使用教程 Expect interact \u0026 expect eof  注意   关于 jenkins 用户无法获取 /dev/ttyUSB0 权限\n在这里最好不要直接使用 sudo ，使用 root 权限执行的坏处在于，当你想要中断 expect 脚本时，也必须使用 root 权限。并且在集成到 Jenkins 时，jenkins 用户起了 root 权限的进程，在中断 job 的时候。expect 任然在 jenkins node 上继续执行。\n解决的方案是将 jenkins 用户加入拥有 dev 设备权限的用户组。\n1  sudo usermod aG dialout jenkins     sudo 执行的 expect 进程kill\nsudo killall -u USER expect \n  ","description":"","tags":["automation","serial","expect"],"title":"关于串口测试自动化的解决方案","uri":"/blog/posts/solutions-for-serial-port-test-automation/"},{"categories":["Linux"],"content":"Linux如何查找大文件或目录总结  转载自: https://www.cnblogs.com/kerrycode/p/4391859.html\n在Windows系统中，我们可以使用 TreeSize 工具查找一些大文件或文件夹，非常的方便高效.\n在Linux系统中，如何去搜索一些比较大的文件呢？下面我整理了一下在Linux系统中如何查找大文件或文件夹的方法。\n 如何查找大文件？ 其实很多时候，你需要了解当前系统下有哪些大文件，比如文件大小超过100M或1G（阀值视具体情况而定）。那么如何把这些大文件搜索出来呢？例如我要搜索当前目录下，超过800M大小的文件\n1  find . -type f -size +800M   如上命令所示，我们仅仅能看到超过800M大小的文件的文件名称，但是对文件的信息（例如，文件大小、文件属性）一无所知，那么能否更详细显示一些文件属性或信息呢，当然可以，如下所示\n1  find . -typf f -size +800M | xargs ls -al   当我们只需要查找超过800M大小文件，并显示查找出来文件的具体大小，可以使用下面命令\n1  find . -typf f -size +800M | xargs du -h   如果你还需要对查找结果按照文件大小做一个排序，那么可以使用下面命令\n1  find . -typf f -size +800M | xargs du -h | sort -nr # 从大到小排序   有时候排列的顺序并不完全是按大小一致，这个是因为du命令的参数h所致，你可以统一使用使用MB来显示，这样就能解决这个问题。到这里，这个在Linux系统查找大文件的命令已经非常完美了，当然如果你还有很多的需求，那么可以在这个命令上做修改、调整.\n\n2: 如何查找Linux下的大目录\n譬如有时候磁盘空间告警了，而你平时又疏于管理、监控文件的增长，那么我需要快速的了解哪些目录变得比较大，那么此时我们可以借助du命令来帮我们解决这个问题。\n[root@getlnx01 u03]# du -h --max-depth=1\n16K ./lost+found\n33G ./flash_recovery_area\n37G ./oradata\n70G .\n如果你想知道flash_recovery_area目录下面有哪些大文件夹，那么可以将参数max-depth=2 ，如果你想对搜索出来的结果进行排序，那么可以借助于sort命令。如下所示\n[root@getlnx01 u03]# du -h --max-depth=2 | sort -n\n3.5G ./flash_recovery_area/EPPS\n16K ./lost+found\n29G ./flash_recovery_area/backup\n33G ./flash_recovery_area\n37G ./oradata\n37G ./oradata/epps\n70G .\n[root@getlnx01 u03]# du -hm --max-depth=2 | sort -n\n1 ./lost+found\n3527 ./flash_recovery_area/EPPS\n29544 ./flash_recovery_area/backup\n33070 ./flash_recovery_area\n37705 ./oradata\n37705 ./oradata/epps\n70775 .\n\n[root@getlnx01 u03]# cd /\n[root@getlnx01 /]# du -hm --max-depth=2 | sort -n\n有时候搜索出来的结果太多了（譬如，我从根目录开始搜索），一直在刷屏，如果我只想查出最大的12个文件夹，怎么办呢？此时就要借助head命令来显示了\n[root@getlnx01 /]# du -hm --max-depth=2 | sort -nr | head -12\n407480 .\n167880 ./u04\n158685 ./u02/oradata\n158685 ./u02\n152118 ./u04/oradata\n70775 ./u03\n37705 ./u03/oradata\n33070 ./u03/flash_recovery_area\n5995 ./u01/app\n5995 ./u01\n3551 ./usr\n1558 ./usr/share\n[root@getlnx01 /]#\n\n参考资料：\nhttp://linuxandfriends.com/how-to-find-large-files-in-linux-using-command-line/\nhttp://www.docin.com/p-563963500.html\n","description":"","tags":["linux"],"title":"Linux如何查找大文件或目录总结","uri":"/blog/posts/linux/how-to-find-files-under-linux/"},{"categories":["Python"],"content":"通过 pySerial 连接串口  pySerial 是一个 Python 模块。该模块封装了对串行端口的访问。\n它提供了在Windows，OSX，Linux，BSD（可能是任何POSIX兼容系统）和IronPython上运行的Python的后端。名为 “serial” 的模块会自动选择适当的后端。\n简而言之，pySerial 提供了通过 Python 代码连接串口设备的功能。\n [toc]\n安装 1 2 3  python -m pip install pyserial # or pip install pyserial   基本使用 打开串口设备/dev/ttyUSB0，默认波特率 9600，不设置 Timeout\n1 2 3 4 5  \u003e\u003e\u003e import serial \u003e\u003e\u003e ser = serial.Serial('/dev/ttyUSB0') # open serial port \u003e\u003e\u003e print(ser.name) # check which port was really used \u003e\u003e\u003e ser.write(b'hello') # write a string \u003e\u003e\u003e ser.close() # close port   打开串口设备/dev/ttyS1, 波特率 19200，设置 Timeout 为 1 秒\n1 2 3 4  \u003e\u003e\u003e with serial.Serial('/dev/ttyS1', 19200, timeout=1) as ser: ... x = ser.read() # read one byte ... s = ser.read(10) # read up to ten bytes (timeout) ... line = ser.readline() # read a '\\n' terminated line   打开串口 COM3, 波特率 38400，不设 Timeout\n1 2 3 4  \u003e\u003e\u003e ser = serial.Serial('COM3', 38400, timeout=0, ... parity=serial.PARITY_EVEN, rtscts=1) \u003e\u003e\u003e s = ser.read(100) # read up to one hundred bytes ... # or as much is in the buffer   动态设置串口属性\n先创建 Serial 实例，再设置属性，通过 Serial.open() 连接串口\n1 2 3 4 5 6 7 8 9 10 11  \u003e\u003e\u003e ser = serial.Serial() \u003e\u003e\u003e ser.baudrate = 19200 \u003e\u003e\u003e ser.port = 'COM1' \u003e\u003e\u003e ser Serial\u003cid=0xa81c10, open=False\u003e(port='COM1', baudrate=19200, bytesize=8, parity='N', stopbits=1, timeout=None, xonxoff=0, rtscts=0) \u003e\u003e\u003e ser.open() \u003e\u003e\u003e ser.is_open True \u003e\u003e\u003e ser.close() \u003e\u003e\u003e ser.is_open False   支持 with 语法 context manager:\n1 2 3 4 5  with serial.Serial() as ser: ser.baudrate = 19200 ser.port = 'COM1' ser.open() ser.write(b'hello')   内置工具 pySerial 库中内置了两个工具\n list_ports miniterm  list_ports list_ports 能列出串口列表，在终端环境下输入 python -m serial.tool.list_ports -h\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  usage: list_ports.py [-h] [-v] [-q] [-n N] [-s] [regexp] Serial port enumeration positional arguments: regexp only show ports that match this regex optional arguments: -h, --help show this help message and exit -v, --verbose show more messages -q, --quiet suppress all messages -n N only output the N-th entry -s, --include-links include entries that are symlinks to real devices # 列出可用的串口端口 python -m serial.tools.list_ports -v /dev/ttyUSB0 desc: FT232R USB UART hwid: USB VID:PID=0403:6001 SER=A90807ZH LOCATION=1-10 /dev/ttyUSB1 desc: FT232R USB UART hwid: USB VID:PID=0403:6001 SER=AC01PSKO LOCATION=1-9 2 ports found   在 Python 代码里调用 serial.tools.list_ports.comports()\n1 2 3  \u003e\u003e\u003e from serial.tools import list_ports \u003e\u003e\u003e list_ports.comports() [\u003cserial.tools.list_ports_linux.SysFS object at 0x7fc2c3ec5460\u003e, \u003cserial.tools.list_ports_linux.SysFS object at 0x7fc2d0aad880\u003e]   miniterm miniterm 是对 pySerial 进行封装的串口终端，输入 python -m serial.tools.miniterm -h:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  usage: miniterm.py [-h] [--parity {N,E,O,S,M}] [--rtscts] [--xonxoff] [--rts RTS] [--dtr DTR] [-e] [--encoding CODEC] [-f NAME] [--eol {CR,LF,CRLF}] [--raw] [--exit-char NUM] [--menu-char NUM] [-q] [--develop] [port] [baudrate] Miniterm - A simple terminal program for the serial port. positional arguments: port serial port name baudrate set baud rate, default: 9600 optional arguments: -h, --help show this help message and exit port settings: --parity {N,E,O,S,M} set parity, one of {N E O S M}, default: N --rtscts enable RTS/CTS flow control (default off) --xonxoff enable software flow control (default off) --rts RTS set initial RTS line state (possible values: 0, 1) --dtr DTR set initial DTR line state (possible values: 0, 1) --ask ask again for port when open fails data handling: -e, --echo enable local echo (default off) --encoding CODEC set the encoding for the serial port (e.g. hexlify, Latin1, UTF-8), default: UTF-8 -f NAME, --filter NAME add text transformation --eol {CR,LF,CRLF} end of line mode --raw Do no apply any encodings/transformations hotkeys: --exit-char NUM Unicode of special character that is used to exit the application, default: 29 --menu-char NUM Unicode code of special character that is used to control miniterm (menu), default: 20 diagnostics: -q, --quiet suppress non-error messages --develop show Python traceback on error   用 miniterm.py 进入串口环境\n1 2 3 4 5 6  miniterm.py /dev/ttyUSB1 115200 --- Miniterm on /dev/ttyUSB1 115200,8,N,1 --- --- Quit: Ctrl+] | Menu: Ctrl+T | Help: Ctrl+T followed by Ctrl+H --- / #   案例：向串口写入以及读取 1 2 3 4 5 6 7 8  import serial device = serial.Serial('/dev/ttyUSB1', 115200) while True: str_in = input() device.write((str_in + '\\n').encode()) str_out = device.read_all().decode('utf-8') print(str_out)   这段代码从输入读取，通过串口向设备写入，再从串口中读取返回的值打印出来。\n","description":"","tags":["serial","python"],"title":"通过 pySerial 连接串口","uri":"/blog/posts/python/connect-serial-port-via-pyserial/"},{"categories":null,"content":"基于 Pexpect 在开发板执行 TestCase 问题场景 在大多数嵌入式工程环境下，我们通过串口或者网口连接开发板，进行测试或调试。\n带有固定步骤，且可通过输出判断执行结果的 TestCase，可以将其转为自动化测试。\n通过 ssh 连接开发板，测试用例可以是 Expect 脚本，或者为了方便生成测试报告，使用 Python Unittest 框架。可以通过 Pexpect （Expect 的 Python 实现）来达到目标。\n环境搭建  jenkins Python lib: pexpect  实现 ","description":"","tags":["python","expect","jenkins"],"title":"基于 Pexpect 在开发板执行 TestCase","uri":"/blog/posts/execute-testcase-on-the-development-board-based-pexpect/"},{"categories":["Python","Fluent-Python"],"content":" 当我在自己的程序中发现用到了模式，我觉得这就表明某个地方出错了。程序的形式应该仅仅反映它所要解决的问题。代码中其他任何外加的形式都是一个信号，（至少对我来说）表明我对问题的抽象还不够深——这通常意味着自己正在手动完成事情，本应该通过写代码来让宏的扩展自动实现。\n——Paul Graham, Lisp 黑客和风险投资人\n Python 内置了迭代器模式，用于进行惰性运算，按需求一次获取一个数据项，避免不必要的提前计算。\n迭代器在 Python 中并不是一个具体类型的对象，更多地使指一个具体协议。\n 所有的生成器都是迭代器。它们都实现了迭代器接口，区别于迭代器用于从集合中取出元素，生成器用来生成元素。  迭代器协议 Python 解释器在迭代一个对象时，会自动调用 iter(x)。\n内置的 iter 函数会做以下操作：\n 检查对象是否实现了 __iter__ 方法（abc.Iterable），若实现，且返回的结果是个迭代器（abc.Iterator），则调用它，获取迭代器并返回； 若没实现，但实现了 __getitem__ 方法（abc.Sequence），若实现则尝试从 0 开始按顺序获取元素并返回； 以上尝试失败，抛出 TypeError，表明对象不可迭代。  判断一个对象是否可迭代，最好的方法不是用 isinstance 来判断，而应该直接尝试调用 iter 函数。\n注：可迭代对象和迭代器不一样。从鸭子类型的角度看，可迭代对象 Iterable 要实现 __iter__，而迭代器 Iterator 要实现 __next__. 不过，迭代器上也实现了 __iter__，用于返回自身。\n迭代器的具体实现 《设计模式：可复用面向对象软件的基础》一书讲解迭代器设计模式时，在“适用性”一 节中说： 迭代器模式可用来：\n  访问一个聚合对象的内容而无需暴露它的内部表示\n  支持对聚合对象的多种遍历\n  为遍历不同的聚合结构提供一个统一的接口（即支持多态迭代）\n  为了“支持多种遍历”，必须能从同一个可迭代的实例中获取多个独立的迭代器，而且各个迭代器要能维护自身的内部状态，因此这一模式正确的实现方式是，每次调用 iter(my_iterable) 都新建一个独立的迭代器。\n序列可迭代的原因：iter函数 解释器需要迭代对象 x 时，会自动调用 iter(x):\n  检查对象是否实现了 __iter__ 方法并调用，获取到迭代器\n  如果没有实现__iter__, 检查是否有 __getitem__ 函数，尝试按顺序下标获取元素\n  如果上述状况都不符合， 抛出 \"C object is not iterable\" 异常\n  这就是为什么这个示例需要定义 SentenceIterator 类。所以，不应该把 Sentence 本身作为一个迭代器，否则每次调用 iter(sentence) 时返回的都是自身，就无法进行多次迭代了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  # 通过实现迭代器协议，让一个对象变得可迭代 import re from collections import abc class Sentence: def __init__(self, sentence): self.sentence = sentence self.words = re.findall(r'\\w+', sentence) def __iter__(self): \"\"\"返回 iter(self) 的结果\"\"\" return SentenceIterator(self.words) # 推荐的做法是对迭代器对象进行单独实现 class SentenceIterator(abc.Iterator): def __init__(self, words): self.words = words self._index = 0 def __next__(self): \"\"\"调用时返回下一个对象\"\"\" try: word = self.words[self._index] except IndexError: raise StopIteration() else: self._index += 1 return word sentence = Sentence('Return a list of all non-overlapping matches in the string.') assert isinstance(sentence, abc.Iterable) # 实现了 __iter__，就支持 Iterable 协议 assert isinstance(iter(sentence), abc.Iterator) for word in sentence: print(word, end='·')   Return·a·list·of·all·non·overlapping·matches·in·the·string·  上面的例子中，我们的 SentenceIterator 对象继承自 abc.Iterator 通过了迭代器测试。而且 Iterator 替我们实现了 __iter__ 方法。\n但是，如果我们不继承它，我们就需要同时实现 __next__ 抽象方法和实际迭代中并不会用到的 __iter__ 非抽象方法，才能通过 Iterator 测试。\n可迭代对象与迭代器的比较   可迭代对象\n使用 iter 内置函数可以获取迭代器的对象。\n  迭代器\n迭代器是一种对象：实现了 __next__ 方法，返回序列中的下一个元素，并在无元素可迭代时抛出 StopIteration 异常。\n  生成器函数 生成器函数的工作原理   只要函数的定义体中有 yield 关键字，该函数就是生成器函数。\n  调用生成器函数会返回生成器对象。\n  如果懒得自己写一个迭代器，可以直接用 Python 的生成器函数来在调用 __iter__ 时生成一个迭代器。\n注：在 Python 社区中，大家并没有对“生成器”和“迭代器”两个概念做太多区分，很多人是混着用的。不过无所谓啦。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  # 使用生成器函数来帮我们创建迭代器 import re class Sentence: def __init__(self, sentence): self.sentence = sentence self.words = re.findall(r'\\w+', sentence) def __iter__(self): for word in self.words: yield word return sentence = Sentence('Return a list of all non-overlapping matches in the string.') for word in sentence: print(word, end='·')   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  # 使用 re.finditer 来惰性生成值 # 使用生成器表达式（很久没用过了） import re class Sentence: def __init__(self, sentence): self.re_word = re.compile(r'\\w+') self.sentence = sentence def __iter__(self): return (match.group() for match in self.re_word.finditer(self.sentence)) sentence = Sentence('Return a list of all non-overlapping matches in the string.') for word in sentence: print(word, end='·')   案例：使用 itertools模块生成等差数列 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  # 实用模块 import itertools # takewhile \u0026 dropwhile print(list(itertools.takewhile(lambda x: x \u003c 3, [1, 5, 2, 4, 3]))) print(list(itertools.dropwhile(lambda x: x \u003c 3, [1, 5, 2, 4, 3]))) # zip print(list(zip(range(5), range(3)))) print(list(itertools.zip_longest(range(5), range(3)))) # itertools.groupby animals = ['rat', 'bear', 'duck', 'bat', 'eagle', 'shark', 'dolphin', 'lion'] # groupby 需要假定输入的可迭代对象已经按照分组标准进行排序（至少同组的元素要连在一起） print('----') for length, animal in itertools.groupby(animals, len): print(length, list(animal)) print('----') animals.sort(key=len) for length, animal in itertools.groupby(animals, len): print(length, list(animal)) print('---') # tee g1, g2 = itertools.tee('abc', 2) print(list(zip(g1, g2)))   1 2 3 4 5 6 7 8 9 10  # 使用 yield from 语句可以在生成器函数中直接迭代一个迭代器 from itertools import chain def my_itertools_chain(*iterators): for iterator in iterators: yield from iterator chain1 = my_itertools_chain([1, 2], [3, 4, 5]) chain2 = chain([1, 2, 3], [4, 5]) print(list(chain1), list(chain2))   [1, 2, 3, 4, 5] [1, 2, 3, 4, 5]  iter 函数还有一个鲜为人知的用法：传入两个参数，使用常规的函数或任何可调用的对象创建迭代器。这样使用时，第一个参数必须是可调用的对象，用于不断调用（没有参数），产出各个值；第二个值是哨符，这是个标记值，当可调用的对象返回这个值时，触发迭代器抛出 StopIteration 异常，而不产出哨符。\n1 2 3 4 5 6 7 8  # iter 的神奇用法 # iter(callable, sentinel) import random def rand(): return random.randint(1, 6) # 不停调用 rand(), 直到产出一个 5 print(list(iter(rand, 5)))   ","description":"","tags":["python"],"title":"《流畅的Python》可迭代的对象、迭代器和生成器","uri":"/blog/posts/python/fluent-python/fluent-python-iterable-objects-iterators-and-generators/"},{"categories":["Python"],"content":" 文章转载自：\nhttps://hanjianwei.com/2013/07/25/python-mro/\n 什么是MRO 对于支持继承的编程语言来说，其方法（属性）可能定义在当前类，也可能来自于基类，所以在方法调用时就需要对当前类和基类进行搜索以确定方法所在的位置。\n而搜索的顺序就是所谓的「方法解析顺序」（Method Resolution Order，或MRO）。对于只支持单继承的语言来说，MRO 一般比较简单；而对于 Python 这种支持多继承的语言来说，MRO 就复杂很多。\n先看一个「菱形继承」的例子：\n如果 x 是 D 的一个实例，那么 x.show() 到底会调用哪个 show 方法呢？\n如果按照 [D, B, A, C] 的搜索顺序，那么 x.show() 会调用 A.show()；\n如果按照 [D, B, C, A] 的搜索顺序，那么 x.show() 会调用 C.show()。\n由此可见，MRO 是把类的继承关系线性化的一个过程，而线性化方式决定了程序运行过程中具体会调用哪个方法。既然如此，那什么样的 MRO 才是最合理的？Python 中又是如何实现的呢？\nPython 至少有三种不同的 MRO：\n 经典类（classic class）的深度遍历。 Python 2.2 的新式类（new-style class）预计算。 Python 2.3 的新式类的C3 算法。它也是 Python 3 唯一支持的方式。  经典类的 MRO Python 有两种类：经典类（classic class）和新式类（new-style class）。两者的不同之处在于新式类继承自 object。\n在 Python 2.1 以前，经典类是唯一可用的形式；Python 2.2 引入了新式类，使得类和内置类型更加统一；在 Python 3 中，新式类是唯一支持的类。\n经典类采用了一种很简单的 MRO 方法：从左至右的深度优先遍历。以上述「菱形继承」为例，其查找顺序为 [D, B, A, C, A]，如果只保留重复类的第一个则结果为 [D, B, A, C]。我们可以用 inspect.getmro 来获取类的 MRO：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  \u003e\u003e\u003e import inspect \u003e\u003e\u003e class A: ... def show(self): ... print \"A.show()\" ... \u003e\u003e\u003e class B(A): pass \u003e\u003e\u003e class C(A): ... def show(self): ... print \"C.show()\" ... \u003e\u003e\u003e class D(B, C): pass \u003e\u003e\u003e inspect.getmro(D) (\u003cclass __main__.D at 0x105f0a6d0\u003e, \u003cclass __main__.B at 0x105f0a600\u003e, \u003cclass __main__.A at 0x105f0a668\u003e, \u003cclass __main__.C at 0x105f0a738\u003e) \u003e\u003e\u003e x = D() \u003e\u003e\u003e x.show() A.show()   这种深度优先遍历对于简单的情况还能处理的不错，但是对于上述「菱形继承」其结果却不尽如人意：虽然 C.show() 是 A.show() 的更具体化版本（显示了更多的信息），但我们的 x.show() 没有调用它，而是调用了 A.show()。这显然不是我们希望的结果。\n对于新式类而言，所有的类都继承自 object，所以「菱形继承」是非常普遍的现象，因此不可能采用这种 MRO 方式。\nPython 2.2 的新式类 MRO 为解决经典类 MRO 所存在的问题，Python 2.2 针对新式类提出了一种新的 MRO 计算方式：在定义类时就计算出该类的 MRO 并将其作为类的属性。因此新式类可以直接通过 __mro__ 属性获取类的 MRO。\nPython 2.2 的新式类 MRO 计算方式和经典类 MRO 的计算方式非常相似：它仍然采用从左至右的深度优先遍历，但是如果遍历中出现重复的类，只保留最后一个。重新考虑上面「菱形继承」的例子，由于新式类继承自 object 因此类图稍有改变：\n按照深度遍历，其顺序为 [D, B, A, object, C, A, object]，重复类只保留最后一个，因此变为 [D, B, C, A, object]。代码为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  \u003e\u003e\u003e class A(object): ... def show(self): ... print \"A.show()\" ... \u003e\u003e\u003e class B(A): pass \u003e\u003e\u003e class C(A): ... def show(self): ... print \"C.show()\" ... \u003e\u003e\u003e class D(B, C): pass \u003e\u003e\u003e D.__mro__ (\u003cclass '__main__.D'\u003e, \u003cclass '__main__.B'\u003e, \u003cclass '__main__.C'\u003e, \u003cclass '__main__.A'\u003e, \u003ctype 'object'\u003e) \u003e\u003e\u003e x = D() \u003e\u003e\u003e x.show() C.show()   这种 MRO 方式已经能够解决「菱形继承」问题，再让我们看个稍微复杂点的例子：\n1 2 3 4 5  \u003e\u003e\u003e class X(object): pass \u003e\u003e\u003e class Y(object): pass \u003e\u003e\u003e class A(X, Y): pass \u003e\u003e\u003e class B(Y, X): pass \u003e\u003e\u003e class C(A, B): pass   首先进行深度遍历，结果为 [C, A, X, object, Y, object, B, Y, object, X, object]；然后，只保留重复元素的最后一个，结果为 [C, A, B, Y, X, object]。Python 2.2 在实现该方法的时候进行了调整，使其更尊重基类中类出现的顺序，其实际结果为 [C, A, B, X, Y, object]。\n这样的结果是否合理呢？首先我们看下各个类中的方法解析顺序：对于 A 来说，其搜索顺序为 [A, X, Y, object]；对于 B，其搜索顺序为 [B, Y, X, object]；对于 C，其搜索顺序为 [C, A, B, X, Y, object]。我们会发现，B 和 C 中 X、Y 的搜索顺序是相反的！也就是说，当 B 被继承时，它本身的行为竟然也发生了改变，这很容易导致不易察觉的错误。此外，即使把 C 搜索顺序中 X 和 Y 互换仍然不能解决问题，这时候它又会和 A 中的搜索顺序相矛盾。\n事实上，不但上述特殊情况会出现问题，在其它情况下也可能出问题。其原因在于，上述继承关系违反了线性化的「 单调性原则 」。Michele Simionato对单调性的定义为：\n A MRO is monotonic when the following is true: if C1 precedes C2 in the linearization of C, then C1 precedes C2 in the linearization of any subclass of C. Otherwise, the innocuous operation of deriving a new class could change the resolution order of methods, potentially introducing very subtle bugs.\n 也就是说，子类不能改变基类的方法搜索顺序。在 Python 2.2 的 MRO 算法中并不能保证这种单调性，它不会阻止程序员写出上述具有二义性的继承关系，因此很可能成为错误的根源。\n除了单调性之外，Python 2.2 及 经典类的 MRO 也可能违反继承的「 局部优先级 」，具体例子可以参见官方文档。采用一种更好的 MRO 方式势在必行。\nC3 MRO 为解决 Python 2.2 中 MRO 所存在的问题，Python 2.3以后采用了C3 方法来确定方法解析顺序。你如果在 Python 2.3 以后版本里输入上述代码，就会产生一个异常，禁止创建具有二义性的继承关系：\n1 2 3 4 5 6 7  \u003e\u003e\u003e class C(A, B): pass Traceback (most recent call last): File \"\u003cipython-input-8-01bae83dc806\u003e\", line 1, in \u003cmodule\u003e class C(A, B): pass TypeError: Error when calling the metaclass bases Cannot create a consistent method resolution order (MRO) for bases X, Y   我们把类 C 的线性化（MRO）记为 L[C] = [C1, C2,…,CN]。其中 C1 称为 L[C] 的头，其余元素 [C2,…,CN] 称为尾。如果一个类 C 继承自基类 B1、B2、……、BN，那么我们可以根据以下两步计算出 L[C]：\n L[object] = [object] L[C(B1…BN)] = [C] + merge(L[B1]…L[BN], [B1]…[BN])  这里的关键在于 merge，其输入是一组列表，按照如下方式输出一个列表：\n 检查第一个列表的头元素（如 L[B1] 的头），记作 H。 若 H 未出现在其它列表的尾部，则将其输出，并将其从所有列表中删除，然后回到步骤1；否则，取出下一个列表的头部记作 H，继续该步骤。 重复上述步骤，直至列表为空或者不能再找出可以输出的元素。如果是前一种情况，则算法结束；如果是后一种情况，说明无法构建继承关系，Python 会抛出异常。  该方法有点类似于图的拓扑排序，但它同时还考虑了基类的出现顺序。我们用 C3 分析一下刚才的例子。\nobject，X，Y 的线性化结果比较简单：\n1 2 3  L[object] = [object] L[X] = [X, object] L[Y] = [Y, object]   A 的线性化计算如下：\n1 2 3 4 5  L[A] = [A] + merge(L[X], L[Y], [X], [Y]) = [A] + merge([X, object], [Y, object], [X], [Y]) = [A, X] + merge([object], [Y, object], [Y]) = [A, X, Y] + merge([object], [object]) = [A, X, Y, object]   注意第3步，merge([object], [Y, object], [Y]) 中首先输出的是 Y 而不是 object。这是因为 object 虽然是第一个列表的头，但是它出现在了第二个列表的尾部。所以我们会跳过第一个列表，去检查第二个列表的头部，也就是 Y。Y 没有出现在其它列表的尾部，所以将其输出。\n同理，B 的线性化结果为：\n1  L[B] = [B, Y, X, object]   最后，我们看看 C 的线性化结果：\n1 2 3 4  L[C] = [C] + merge(L[A], L[B], [A], [B]) = [C] + merge([A, X, Y, object], [B, Y, X, object], [A], [B]) = [C, A] + merge([X, Y, object], [B, Y, X, object], [B]) = [C, A, B] + merge([X, Y, object], [Y, X, object])   到了最后一步我们没有办法继续计算下去 了：X 虽然是第一个列表的头，但是它出现在了第二个列表的尾部；Y 虽然是第二个列表的头，但是它出现在了第一个列表的尾部。因此，我们无法构建一个没有二义性的继承关系，只能手工去解决（比如改变 B 基类中 X、Y 的顺序）。\n我们再看一个没有冲突的例子：\n计算过程如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  L[object] = [object] L[D] = [D, object] L[E] = [E, object] L[F] = [F, object] L[B] = [B, D, E, object] L[C] = [C, D, F, object] L[A] = [A] + merge(L[B], L[C], [B], [C]) = [A] + merge([B, D, E, object], [C, D, F, object], [B], [C]) = [A, B] + merge([D, E, object], [C, D, F, object], [C]) = [A, B, C] + merge([D, E, object], [D, F, object]) = [A, B, C, D] + merge([E, object], [F, object]) = [A, B, C, D, E] + merge([object], [F, object]) = [A, B, C, D, E, F] + merge([object], [object]) = [A, B, C, D, E, F, object]   当然，可以用代码验证类的 MRO，上面的例子可以写作：\n1 2 3 4 5 6 7 8  \u003e\u003e\u003e class D(object): pass \u003e\u003e\u003e class E(object): pass \u003e\u003e\u003e class F(object): pass \u003e\u003e\u003e class B(D, E): pass \u003e\u003e\u003e class C(D, F): pass \u003e\u003e\u003e class A(B, C): pass \u003e\u003e\u003e A.__mro__ (\u003cclass '__main__.A'\u003e, \u003cclass '__main__.B'\u003e, \u003cclass '__main__.C'\u003e, \u003cclass '__main__.D   ","description":"","tags":["python"],"title":"Python 中的方法解析顺序(MRO)","uri":"/blog/posts/python/method-resolution-order-mro-in-python/"},{"categories":["Linux"],"content":"用 Expect 处理命令行程序交互 shell 把程序交互的特性留给了用户，这意味着有些程序，不能脱离用户输入。比如 passwd 命令。\nexpect 能够调用其他 unix 程序，处理交互操作。\nExpect 脚本登录 SSH 先看一个通过 expect 脚本 SSH 到远程主机的示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  #!/usr/bin/expect  set host \"192.168.199.231\" set user \"xiao\" set password \"xiao\" spawn ssh '$user@$host' expect { \"*(yes/no)?\" { send \"yes\\r\" exp_continue } \"*password:\" { send \"$password\\r\" } timeout { puts \"timed out\",exit } } interact   这里注意到两个重要的关键字：spawn，expect\n下面对 expect 语法里的关键字作介绍\nKeyword spawn： 调用其他 unix 程序，生成新进程\nexpect: 处理其他程序的输出，对于匹配到的输出可以触发操作\nset: 全局变量赋值\nsend: 发送字符指令，支持特殊字符 \\r 回车, \\x03 Ctrl+c 等等\nputs: 发送字符到标准输出\ninteract: 交互控制权切换到用户\nFlowControl  for-loop  1 2 3 4 5 6 7 8 9 10 11 12 13  for {} {} {} { ... } // eg: for {set i 0} { i \u003c 10} {incr 1} { ... } // Endless loop for {} 1 {} { ... }    while-loop  1 2 3  while { EXPRESSION } { ... }    if-else  1 2 3 4 5  if { EXPRESSION } { ... } else { ... }   Match-Operation 1 2 3 4 5 6 7 8 9 10 11  expect { PATTERN1 { DO_SOMETHING } PATTERN2 { DO_SOMETHING_ELSE } timeout { exit } }   接收参数传入 1 2 3 4 5  # 命令行参数 # $argv，参数数组，使用[lindex $argv n]获取，$argv 0为脚本名字 # $argc，参数个数 set username [lindex $argv 1] # 获取第1个参数 set passwd [lindex $argv 2] # 获取第2个参数   Function 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  # params  set timeout 5 set now [clock seconds] set date [clock format $now -format {%Y%m%d-%H%M}] log_file -noappend exp/log/xvr_autotest_$date.log # picocom config set baudrate \"1000000\" set device [lindex $argv 0]; proc test_reboot { interval } { send \"reboot\\r\" sleep $interval } proc test_some_function {} { } proc main {} { set interval 5 test_reboot $interval test_some_function } spawn picocom -b $baudrate -f x $device expect \"Terminal ready\" { send \"\\r\" } main   以上，通过 expect 调用了 picocom (串口命令行工具) 连接到串口，去执行重启命令。\nReference  expect教程中文版 expect说明 [expect命令][https://man.linuxde.net/expect1]  ","description":"","tags":null,"title":"用 Expect 处理命令行程序交互","uri":"/blog/posts/linux/linuxuse-expect-to-handle-command-line-program-interaction/"},{"categories":["Python","Fluent-Python"],"content":" 抽象类表示接口。\n——Bjarne Stroustrup, C++ 之父\n 本章讨论的话题是接口：\n从鸭子类型的代表特征动态协议，到使接口更明确、能验证实现是否符合规定的抽象基类（Abstract Base Class, ABC）。\n 接口的定义：对象公开方法的子集，让对象在系统中扮演特定的角色。\n协议是接口，但不是正式的（只由文档和约定定义），因此协议不能像正式接口那样施加限制。\n允许一个类上只实现部分接口。\n 接口与协议   什么是接口\n对象公开方法的子集，让对象在系统中扮演特定的角色。\n  鸭子类型与动态协议\n  受保护的类型与私有类型不能在接口中\n  可以把公开的数据属性放在接口中\n  案例：通过实现 getitem 方法支持序列操作 1 2 3 4 5 6 7 8 9  class Foo: def __getitem__(self, pos): return range(0, 30, 10)[pos] f = Foo() print(f[1]) for i in f: print(i)   Foo 实现了序列协议的 __getitem__ 方法。因此可支持下标操作。\nFoo 实例是可迭代的对象，因此可以使用 in 操作符\n案例：在运行时实现协议——猴子补丁 FrenchDeck 类见前面章节。\nFrenchDeck 实例的行为像序列，那么其实可以用 random 的 shuffle 方法来代替在类中实现的方法。\n1 2 3 4 5 6  from random import shuffle from frenchdeck import FrenchDeck deck = FrenchDeck() shuffle(deck) # TypeError: 'FrenchDeck' object does not support item assigment   FrenchDeck 对象不支持元素赋值。这是因为它只实现了不可变的序列协议，可变的序列还必须提供 __setitem__ 方法。\n1 2 3 4 5 6 7  def set_card(deck, pos, card): deck._cards[pos] = card FrenchDeck.__setitem__ = set_card shuffle(deck) print(deck[:5]) print(deck[:5])   这种技术叫做猴子补丁：在运行是修改类或程序，而不改动源码。缺陷是补丁代码与要打补丁的程序耦合紧密。\n抽象基类（abc） 抽象基类是一个非常实用的功能，可以使用抽象基类来检测某个类是否实现了某种协议，而这个类并不需要继承自这个抽象类。\ncollections.abc 和 numbers 模块中提供了许多常用的抽象基类以用于这种检测。\n有了这个功能，我们在自己实现函数时，就不需要非常关心外面传进来的参数的具体类型（isinstance(param, list)），只需要关注这个参数是否支持我们需要的协议（isinstance(param, abc.Sequence）以保障正常使用就可以了。\n但是注意：从 Python 简洁性考虑，最好不要自己创建新的抽象基类，而应尽量考虑使用现有的抽象基类。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  # 抽象基类 from collections import abc class A: pass class B: def __len__(self): return 0 assert not isinstance(A(), abc.Sized) assert isinstance(B(), abc.Sized) assert abc.Sequence not in list.__bases__ # list 并不是 Sequence 的子类 assert isinstance([], abc.Sequence) # 但是 list 实例支持序列协议   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  # 在抽象基类上进行自己的实现 from collections import abc class FailedSized(abc.Sized): pass class NormalSized(abc.Sized): def __len__(self): return 0 n = NormalSized() print(len(n)) f = FailedSized() # 基类的抽象协议未实现，Python 会阻止对象实例化   有一点需要注意：抽象基类上的方法并不都是抽象方法。\n换句话说，想继承自抽象基类，只需要实现它上面所有的抽象方法即可，有些方法的实现是可选的。\n比如 Sequence.__contains__，Python 对此有自己的实现（使用 __iter__ 遍历自身，查找是否有相等的元素）。但如果你在 Sequence 之上实现的序列是有序的，则可以使用二分查找来覆盖 __contains__ 方法，从而提高查找效率。\n我们可以使用 __abstractmethods__ 属性来查看某个抽象基类上的抽象方法。这个抽象基类的子类必须实现这些方法，才可以被正常实例化。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  # 自己定义一个抽象基类 import abc # 使用元类的定义方式是 class SomeABC(metaclass=abc.ABCMeta) class SomeABC(abc.ABC): @abc.abstractmethod def some_method(self): raise NotImplementedError class IllegalClass(SomeABC): pass class LegalClass(SomeABC): def some_method(self): print('Legal class OK') l = LegalClass() l.some_method() il = IllegalClass() # Raises   虚拟子类 使用 register 接口可以将某个类注册为某个 ABC 的“虚拟子类”。支持 register 直接调用注册，以及使用 @register 装饰器方式注册（其实这俩是一回事）。\n注册后，使用 isinstance 以及实例化时，解释器将不会对虚拟子类做任何方法检查。\n注意：虚拟子类不是子类，所以虚拟子类不会继承抽象基类的任何方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  # 虚拟子类 import abc import traceback class SomeABC(abc.ABC): @abc.abstractmethod def some_method(self): raise NotImplementedError def another_method(self): print('Another') @classmethod def __subclasshook__(cls, subcls): \"\"\" 在 register 或者进行 isinstance 判断时进行子类检测 https://docs.python.org/3/library/abc.html#abc.ABCMeta.__subclasshook__ \"\"\" print('Subclass:', subcls) return True class IllegalClass: pass SomeABC.register(IllegalClass) # 注册 il = IllegalClass() assert isinstance(il, IllegalClass) assert SomeABC not in IllegalClass.__mro__ # isinstance 会返回 True，但 IllegalClass 并不是 SomeABC 的子类 try: il.some_method() # 虚拟子类不是子类，不会从抽象基类上继承任何方法 except Exception as e: traceback.print_exc() try: il.another_method() except Exception as e: traceback.print_exc()   ","description":"","tags":["python"],"title":"《流畅的Python》接口之从协议到抽象基类","uri":"/blog/posts/python/fluent-python/fluent-python-interface-from-protocol-to-abstract-base-class/"},{"categories":null,"content":"自学计算机科学  本文档是对TeachYourselfCS内容的中文翻译，原作者为Ozan Onay和Myles Byrne。如需了解翻译相关信息或帮助改进翻译，请参见本文档结尾。\nThis document is a Chinese translation of TeachYourselfCS, which is written by Ozan Onay and Myles Byrne. For more information about this translation, please refer to the end of this document.\n 如果你是一个自学成才的工程师，或者从编程培训班毕业，那么你很有必要学习计算机科学。幸运的是，不必为此花上数年光阴和不菲费用去攻读一个学位：仅仅依靠自己，你就可以获得世界一流水平的教育💸。\n互联网上，到处都有许多的学习资源，然而精华与糟粕并存。你所需要的，不是一个诸如“200+免费在线课程”的清单，而是以下问题的答案：\n 你应当学习哪些科目，为什么？ 对于这些科目，最好的书籍或者视频课程是什么？  在这份指引中，我们尝试对这些问题做出确定的回答。\n简而言之 大致按照列出的顺序，借助我们所建议的教材或者视频课程（但是最好二者兼用），学习如下的九门科目。目标是先花100到200个小时学习完每一个科目，然后在你职业生涯中，不时温习其中的精髓🚀。\n   科目 为何要学？ 最佳书籍 最佳视频     编程 不要做一个“永远没彻底搞懂”诸如递归等概念的程序员。 《计算机程序的构造和解释》 Brian Harvey’s Berkeley CS 61A   计算机架构 如果你对于计算机如何工作没有具体的概念，那么你所做出的所有高级抽象都是空中楼阁。 《深入理解计算机系统》 Berkeley CS 61C   算法与数据结构 如果你不懂得如何使用栈、队列、树、图等常见数据结构，遇到有难度的问题时，你将束手无策。 《算法设计手册》 Steven Skiena’s lectures   数学知识 计算机科学基本上是应用数学的一个“跑偏的”分支，因此学习数学将会给你带来竞争优势。 《计算机科学中的数学》 Tom Leighton’s MIT 6.042J   操作系统 你所写的代码，基本上都由操作系统来运行，因此你应当了解其运作的原理。 《操作系统导论》 Berkeley CS 162   计算机网络 互联网已然势不可挡：理解工作原理才能解锁全部潜力。 《计算机网络：自顶向下方法》 Stanford CS 144   数据库 对于多数重要程序，数据是其核心，然而很少人理解数据库系统的工作原理。 《Readings in Database Systems》 （暂无中译本） Joe Hellerstein’s Berkeley CS 186   编程语言与编译器 若你懂得编程语言和编译器如何工作，你就能写出更好的代码，更轻松地学习新的编程语言。 《Crafting Interpreters》 Alex Aiken’s course on Lagunita   分布式系统 如今，多数 系统都是分布式的。 《数据密集型应用系统设计》 MIT 6.824    还是太多？ 如果花几年时间自学 9 门科目让人望而却步，我们建议你只专注于两本书：《深入理解计算机系统》 和 《数据密集型应用系统设计》。根据我们的经验，投入到这两本书的时间可以获得极高的回报率，特别适合从事网络应用开发的自学工程师。这两本书也可以作为上面表格中其他科目的纲领。\n为什么要学习计算机科学？ 软件工程师分为两种：一种充分理解了计算机科学，从而有能力应对充满挑战的创造性工作；另一种仅仅凭着对一些高级工具的熟悉而勉强应付。\n这两种人都自称软件工程师，都能在职业生涯早期挣到差不多的工资。然而，随着时间流逝，第一种工程师不断成长，所做的事情将会越来越有意义且更为高薪，不论是有价值的商业工作、突破性的开源项目、技术上的领导力或者高质量的个人贡献。\n 全球短信系统每日收发约200亿条信息，而仅仅靠57名工程师，现在的 WhatsApp 每日收发420亿条。\n— Benedict Evans (@BenedictEvans) 2016年2月2日\n 第一种工程师总是寻求深入学习计算机科学的方法，或是通过传统的方法学习，或是在职业生涯中永无止息地学习；第二种工程师 通常浮于表面，只学习某些特定的工具和技术，而不研究其底层的基本原理，仅仅在技术潮流的风向改变时学习新的技能。\n如今，涌入计算机行业的人数激增，然而计算机专业的毕业生数量基本上未曾改变。第二种工程师的供过于求正在开始减少他们的工作机会，使他们无法涉足行业内更加有意义的工作。对你而言，不论正在努力成为第一种工程师，还是只想让自己的职业生涯更加安全，学习计算机科学是唯一可靠的途径。\n 23333 然而他们... pic.twitter.com/XVNYlXAHar\n— Jenna Bilotta (@jenna) 2017年3月4日\n 分科目指引 编程 大多数计算机专业本科教学以程序设计“导论”作为开始。这类课程的最佳版本不仅能满足初学者的需要，还适用于那些在初学编程阶段遗漏了某些有益的概念和程序设计模式的人。\n对于这部分内容，我们的标准推荐是这部经典著作：《计算机程序的构造和解释》。在网络上，这本书既可供免费阅读（英文版），也作为MIT的免费视频课程。不过尽管这些视频课程很不错，我们对于视频课程的推荐实际上是Brian Harvey 开设的 SICP 课程（即 Berkeley 的 61A 课程）。比起MIT的课程，它更加完善，更适用于初学者。\n我们建议至少学完SICP的前三章，并完成配套的习题。如果需要额外的练习，可以去解决一些小的程序设计问题，比如exercism。\n 中文翻译新增：\n 关于SICP国内视频观看地址  MIT的免费视频课程（中英字幕） Brian Harvey 开设的 SICP 课程（英文字幕）   Scheme 学习的相关资源参见：https://github.com/DeathKing/Learning-SICP 更详细的补充说明：#3   自从 2016 年首次发布这份指南以来，最常被问到的一个问题是，我们是否推荐由 John DeNero 讲授的更新的 CS 61A 课程，以及配套的书籍 《Composing Programs》，这本书“继承自 SICP” 但使用 Python 讲解。我们认为 DeNero 的课程也很不错，有的学生可能更喜欢，但我们还是建议把 SICP, Scheme 和 Brian Harvey 的视频课程作为首选。\n为什么这么说呢？因为 SICP 是独一无二的，它可以——至少很有可能——改变你对计算机和编程的基本认识。不是每个人都有这样的体验。有的人讨厌这本书，有的人看了前几页就放弃了。但潜在的回报让它值得一读。\n如果你觉得SICP过于难，试试 《Composing Programs》。如果还是不合适，那我们推荐 《程序设计方法》（中文版，英文版） ；如果你觉得SICP过于简单，那我们推荐 《Concepts, Techniques, and Models of Computer Programming》 。如果读这些书让你觉得没有收获，也行你应该先学习其他科目，一两年后再重新审视编程的理念。\n 新版原文删除了对 《Concepts, Techniques, and Models of Computer Programming》 一书的推荐，但这本书对各种编程模型有深入的见解，值得一读。所以译文中依然保留。 — 译者注\n 最后，有一点要说明的是：本指南不适用于完全不懂编程的新手。我们假定你是一个没有计算机专业背景的程序员，希望填补一些知识空白。事实上，我们把“编程”章节包括进来只是提醒你还有更多知识需要学习。对于那些从来没有学过编程，但又想学的人来说，这份指南更合适。\n\n计算机架构 计算机架构——有时候又被称为“计算机系统”或者“计算机组成”——是了解软件底层的的重要视角。根据我们的经验，这是自学的软件工程师最容易忽视的领域。\n我们最喜欢的入门书是 《深入理解计算机系统》。典型的计算机体系结构导论课程会涵盖本书的 1 - 6 章。\n我们喜爱《深入理解计算机系统》，因为它的实用性，并且站在程序员的视角。虽然计算机体系结构的内容比本书所涉及的内容多得多，但对于那些想了解计算机系统以求编写更快、更高效、更可靠的软件的人来说，这本书是很好的起点。\n对于那些既想了解这个主题又想兼顾硬件和软件的知识的人来说，我们推荐 《计算机系统要素》，又名“从与非门到俄罗斯方块”（“Nand2Tetris”），这本书规模宏大，让读者对计算机内的所有部分如何协同工作有完全的认识。这本书的每一章节对应如何构建计算机整体系统中的一小部分，从用HDL（硬件描述语言）写基本的逻辑门电路出发，途经CPU和汇编，最终抵达诸如俄罗斯方块这般规模的应用程序。\n我们推荐把此书的前六章读完，并完成对应的项目练习。这么做，你将更加深入地理解，计算机架构和运行其上的软件之间的关系。\n这本书的前半部分（包括所有对应的项目）均可从Nand2Tetris的网站上免费获得。同时，在Coursera上，这是一门视频课程。\n为了追求简洁和紧凑，这本书牺牲了内容上的深度。尤其值得注意的是，流水线和存储层次结构是现代计算机架构中极其重要的两个概念，然而这本书对此几乎毫无涉及。\n当你掌握了Nand2Tetris的内容后，我们推荐要么回到《深入理解计算机系统》，或者考虑Patterson和Hennessy二人所著的 《计算机组成与设计》，一本优秀的经典著作。这本书中的不同章节重要程度不一，因此我们建议根据Berkeley的CS61C课程 “计算机架构中的伟大思想”来着重阅读一些章节。这门课的笔记和实验在网络上可以免费获得，并且在互联网档案中有这门课程的过往资料。\n \n 硬件是平台。\n— Mike Acton, Engine Director at Insomniac Games (观看他在CppCon上的演说)\n 算法与数据结构 正如几十年来的共识，我们认为，计算机科学教育所赋予人们的最大能量在于对常见算法和数据结构的熟悉。此外，这也可以训练一个人对于各种问题的解决能力，有助于其他领域的学习。\n关于算法与数据结构，有成百上千的书可供使用，但是我们的最爱是Steven Skiena编写的 《算法设计手册》。显而易见，他对此充满热爱，迫不及待地想要帮助其他人理解。在我们看来，这本书给人一种焕然一新的体验，完全不同于那些更加经常被推荐的书（比如Cormen，Leiserson，Rivest 和 Stein，或者 Sedgewick的书，后两者充斥着过多的证明，不适合以 解决问题 为导向的学习）。\n如果你更喜欢视频课程，Skiena慷慨地提供了他的课程。此外，Tim Roughgarden的课程也很不错， 在Stanford的MOOC平台Lagunita，或者Coursera上均可获得。Skiena和Roughgarden的这两门课程没有优劣之分，选择何者取决于个人品味。\n至于练习，我们推荐学生在Leetcode上解决问题。Leetcode上的问题往往有趣且带有良好的解法和讨论。此外，在竞争日益激烈的软件行业，这些问题可以帮助你评估自己应对技术面试中常见问题的能力。我们建议解决大约100道随机挑选的Leetcode问题，作为学习的一部分。\n最后，我们强烈推荐 《怎样解题》。这本书极为优秀且独特，指导人们解决广义上的问题，因而一如其适用于数学，它适用于计算机科学。\n \n 我可以广泛推荐的方法只有一个： 写之前先思考。\n— Richard Hamming\n 数学知识 从某个角度说，计算机科学是应用数学的一个“发育过度”的分支。尽管许多软件工程师试图——并且在不同程度上成功做到——忽视这一点，我们鼓励你用学习来拥抱数学。如若成功，比起那些没有掌握数学的人，你将获得巨大的竞争优势。\n对于计算机科学，数学中最相关的领域是“离散数学”，其中的“离散”与“连续”相对立，大致上指的是应用数学中那些有趣的主题，而不是微积分之类的。由于定义比较含糊，试图掌握离散数学的全部内容是没有意义的。较为现实的学习目标是，了解逻辑、排列组合、概率论、集合论、图论以及密码学相关的一些数论知识。考虑到线性代数在计算机图形学和机器学习中的重要性，该领域同样值得学习。\n学习离散数学，我们建议从László Lovász的课程笔记开始。Lovász教授成功地让这些内容浅显易懂且符合直觉，因此，比起正式的教材，这更适合初学者。\n对于更加高阶的学习，我们推荐 《计算机科学中的数学》，MIT同名课程的课程笔记，篇幅与书籍相当（事实上，现已出版）。这门课程的视频同样可免费获得，是我们所推荐的学习视频。\n对于线性代数，我们建议从Essence of linear algebra系列视频开始，然后再去学习Gilbert Strang的《线性代数导论》和视频课程。\n\n 如果人们不相信数学是简单的，那么只能是因为他们没有意识到生活有多么复杂。\n— John von Neumann\n 操作系统 《操作系统概念》 （“恐龙书”）和 《现代操作系统》 是操作系统领域的经典书籍。二者都因为写作风格和对学生不友好而招致了一些批评。\n《操作系统导论》（Operating Systems: Three Easy Pieces） 是一个不错的替代品，并且可在网上免费获得（英文版）。我们格外喜欢这本书的结构，并且认为这本书的习题很值得一做。\n在读完《操作系统导论》后，我们鼓励你探索特定操作系统的设计。可以借助“{OS name} Internals”风格的书籍，比如 Lion's commentary on Unix， The Design and Implementation of the FreeBSD Operating System，以及 Mac OS X Internals。对于 Linux ，我们推荐 Robert Love 的 《Linux内核设计与实现》。\n为了巩固对操作系统的理解，阅读小型系统内核的代码并且为其增加特性是一个很不错的方法。比如，xv6，由MIT的一门课程所维护的从Unix V6到ANSI C和x86的移植，就是一个很棒的选择。《操作系统导论》有一个附录，记载了一些可能的xv6实验项目，其中充满了关于潜在项目的很棒想法。\n\n计算机网络 鉴于有那么多关于网络服务端和客户端的软件工程，计算机网络是计算机科学中价值最为“立竿见影”的领域之一。我们的学生，系统性地学习了计算机网络，最终能够理解那些曾困扰他们多年的术语、概念和协议。\n在这一主题上，我们最爱的书籍是 《计算机网络：自顶向下方法》。书中的小项目和习题相当值得练习，尤其是其中的“Wireshark labs”（这部分在网上可以获得）。\n如果更喜欢视频课程，我们推荐Stanford的Introduction to Computer Networking，可在他们的MOOC平台Lagunita上免费观看。\n对于计算机网络的学习，做项目比完成小的习题更有益。一些可能的项目有：HTTP服务器，基于UDP的聊天APP，迷你TCP栈，代理，负载均衡器，或者分布式哈希表。\n\n 你无法盯着水晶球预见未来，未来的互联网何去何从取决于社会。\n— Bob Kahn\n 数据库 比起其他主题，自学数据库系统需要更多的付出。这是一个相对年轻的研究领域，并且出于很强的商业动机，研究者把想法藏在紧闭的门后。此外，许多原本有潜力写出优秀教材的作者反而选择了加入或创立公司。\n鉴于如上情况，我们鼓励自学者大体上抛弃教材，而是从2015年春季学期的CS 186课程（Joe Hellerstein在Berkeley的数据库课程）开始，然后前往阅读论文。\n对于初学者，有一篇格外值得提及的论文：“Architecture of a Database System”。这篇论文提供了独特的对关系型数据库管理系统（RDBMS）如何工作的高层次观点，是后续学习的实用梗概。\n《Readings in Database Systems》，或者以数据库“红书”更为人知，是由Peter Bailis，Joe Hellerstein和Michael Stonebraker编纂的论文合集。对于那些想要在CS 186课程的水平更进一步的学习者，“红书”应当是下一步。\n如果你坚持一定要一本导论教材，那我们推荐Ramakrishnan和Gehrke所著的 《数据库管理系统：原理与设计》。如需更深一步，Jim Gray的经典著作 《Transaction Processing: Concepts and Techniques》 值得一读，不过我们不建议把这本书当作首要资源。\n如果没有编写足够数量的代码，很难巩固数据库理论。CS 186课程的学生给Spark添加特性，倒是不错的项目，不过我们仅仅建议从零实现一个简单的关系型数据库管理系统。自然，它将不会有太多的特性，但是即便只实现典型的关系型数据库管理系统每个方面最基础的功能，也是相当有启发的。\n最后，数据模型往往是数据库中一个被忽视的、教学不充分的方面。关于这个主题，我们推荐的书籍是 Data and Reality: A Timeless Perspective on Perceiving and Managing Information in Our Imprecise World。\n \n编程语言与编译器 多数程序员学习编程语言的知识，而多数计算机科学家学习编程语言 相关 的知识。这使得计算机科学家比起程序员拥有显著的优势，即便在编程领域！因为他们的知识可以推而广之：相较只学习过特定编程语言的人，他们可以更深入更快速地理解新的编程语言。\n我们推荐的入门书是 Bob Nystrom 所著的优秀的 Crafting Interpreters，可在网上免费获取。这本书条理清晰，富有趣味性，非常适合那些想要更好地理解语言和语言工具的人。我们建议你花时间读完整本书，并尝试任何一个感兴趣的“挑战”。\n另一本更为传统的推荐书籍是 《编译原理》，通常称为“龙书”。不幸的是，这本书不是为自学者而设计的，而是供教师从中挑选一些主题用于1-2学期的教学。\n如果你选择使用龙书进行自学，你需要从中甄选主题，而且最好是在导师的帮助下。我们建议依据某个视频课程来设定学习的结构，然后按需从龙书中获取深入的内容。我们推荐的在线课程是Alex Aiken在MOOC平台 edX 所开设的。\n\n 不要做一个只写样板代码的程序员。相反，给用户和其他程序员创造工具。从纺织工业和钢铁工业中学习历史教训：你想制造机器和工具，还是操作这些机器？\n— Ras Bodik 在他的编译器课程伊始\n 分布式系统 随着计算机在数量上的增加，计算机同样开始 分散。尽管商业公司过去愿意购买越来越大的大型机，现在的典型情况是，甚至很小的应用程序都同时在多台机器上运行。思考这样做的利弊权衡，即是分布式系统的研究所在，也是越来越重要的一项技能。\n我们推荐的自学参考书是 Martin Kleppmann 的 《数据密集型应用系统设计》。与传统的教科书相比，它是一本为实践者设计的具有很高的可读性的书，并且保持了深度和严谨性。\n对于那些偏爱传统教材，或者希望可以从网上免费获取的人，我们推荐的教材是Maarten van Steen和Andrew Tanenbaum所著的 《分布式系统原理与范型》（中文第二版，英文第三版）。\n对于喜欢视频课程的人，MIT的6.824 是一门很好的在线视频课程，由 Robert Morris 教授的研究生课程，在这里可以看到课程安排。\n不管选择怎样的教材或者其他辅助资料，学习分布式系统必然要求阅读论文。这里有一个不错的论文清单，而且我们强烈建议你出席你当地的Papers We Love（仅限美国）。\n\n常见问题解答 这份指引的目标受众是？ 我们面向自学的软件工程师、培训班学生、“早熟的”高中生或者想要通过自学补充正式教育的大学生。关于何时开启这段自学旅程，完全取决于个人，不过多数人在有一定的职业经历后深入学习计算机科学理论会获益匪浅。比如，我们注意到，如果学生在工作中曾经使用过数据库，他们会 喜爱 学习数据库系统课程；如果学生从事过一两个Web项目，他们会 喜爱 学习计算机网络。\n人工智能/计算机图形学/XX主题怎么样？ 我们试图把计算机科学主题清单限制到那些我们认为 每一个软件工程师 都应该了解的内容，不限于专业或行业。拥有了这些基础，你将能更加轻松地挑选教材或论文，然而无需指引地学习核心概念。在这里，我们给出一些其他常见主题的自学起点：\n 人工智能：通过观看视频并完成Pacman项目来学习Berkeley的AI课程。至于教材，使用Russell和Norvig编写的 《人工智能：一种现代方法》。 机器学习：学习吴恩达在Coursera上的课程。耐心学习，先确保理解了基础概念再奔向类如深度学习的诱人新主题。 计算机图形学：学习Berkeley CS 184课程的材料，使用《计算机图形学：原理及实践》作为教材。  一定要严格遵守推荐的学习次序吗？ 事实上，所有主题之间都有一定程度的重叠，彼此循环引用。以离散数学和算法的关系为例：先学习数学可以帮助你更深入地分析和理解算法，然而先学习算法可以为学习离散数学提供更大的动力和应用背景。理想情况下，你将在你的职业生涯多次重温二者。\n因此，我们所推荐的次序主要是为了帮助你 起步……如果你出于某种强烈的原因而倾向以不同的顺序学习，那也没有关系，勇敢开始吧！不过在我们看来，最重要的“先决条件”是：先学计算机架构再学操作系统或数据库，先学计算机网络和操作系统再学分布式系统。\n和Open Source Society、freeCodeCamp curricula等比起来，这份指引? OSS指引涵盖太多主题，在许多主题中推荐劣质资源，没有就特定课程哪些方面有价值提供原因或指引。我们努力对这份指引中的课程加以限制，仅仅包括那些你作为软件工程师 确实需要了解的，不论你的专业方向，并且对每门课程为何必要做出了解释以帮助你理解。\nFreeCodeCamp主要关注编程，而不是计算机科学。至于你为什么要学习计算机科学，参见上文。如果你是个新手，我们建议先学 freeCodeCamp 的课程，一两年后再回归本指南。\nXX编程语言怎么样? 学习一门特定的编程语言和学习计算机科学的一个领域完全不在一个维度——相比之下，学习语言 容易 且 缺乏价值。如果你已经了解了一些语言，我们强烈建议遵照我们的指引，然后在学习的空当中习得语言，或者暂且不管以后再说。如果你已经把编程学得不错了（比如学完了 《计算机程序的构造和解释》），尤其是如果你学习过编译器，那么面对一门新的语言，你只需要花一个周末稍多的时间即可基本掌握，之后你可以在工作中学习相关的类库/工具/生态。\nXX流行技术怎么样? 没有任何一种技术的重要程度可以达到学习其使用足以成为计算机科学教学的核心部分。不过，你对学习那门技术充满热情，这很不错。诀窍是先从特定的技术回退到基本的领域或概念，判断这门流行技术在技术的宏观大局中位于何处，然后才深入学习这门技术。\n为什么你们还在推荐SICP? 先尝试读一下，有些人觉得 SICP 让人神魂颠倒，这在其他书很少见。如果你不喜欢，你可以尝试其他的东西，也许以后再回到 SICP。\n为什么你们还在推荐龙书? 龙书依旧是内容最为完整的编译器单本书籍。由于过分强调一些如今不够时新的主题的细节，比如解析，这本书招致了恶评。然而事实上，这本书从未打算供人一页一页的学习，而仅仅是为了给教师准备一门课程提供足够的材料。类似地，自学者可以从书中量身按需挑选主题，或者最好依照公开课授课教师在课程大纲中的建议。\n如何便宜获取教材? 我们所建议的许多教材在网上都可以免费获得，这多亏了作者们的慷慨。对于那些不免费的书籍，我们建议购买旧版本的二手书籍。广而言之，如果一本教材有多个版本，旧版本大概率是完全足够使用的。即便新版本的价格是旧版本的10倍，新版本也绝不可能比旧版本好10倍！\n中文翻译新增： 事实上，比起美国，在国内购买技术书籍可以说是相当“廉价”了。如果仍旧寻求更加便宜的购买渠道，可以参考这篇V2EX上的讨论帖子，其中提到了一些不错的购买渠道。\n这份指引是谁写的? 这份指引由Bradfield School of Computer Science（旧金山）的两位教员：Ozan Onay和Myles Byrne编写，并由 Oz 于 2020 年更新。这份指引基于我们对数千名自学成才的工程师和培训班学生教授计算机科学基础的经验。感谢我们所有学生对自学资源的持续反馈。\n只要有足够的时间和动力，我们非常有信心，你可以自学完以上所有课程。如果你喜欢一个集中式、结构化、由教师指导的课程，你可能对我们的计算机科学强化班感兴趣。我们不建议你去攻读硕士学位。\n这份指引是谁翻译的？ 这份指引的中文翻译是社区共同贡献的成果，我们欢迎任何反馈和改进！\n","description":"","tags":["methodology"],"title":"计算机科学自学指南","uri":"/blog/posts/computer-science-selfstudy-guide/"},{"categories":null,"content":"使用Graphviz创建图表  转载自：https://ncona.com/2020/06/create-diagrams-with-code-using-graphviz/\n 您是否曾为绘制过架构图时重复的单击和拖动而感到乏味？\n您是否需要对该图进行修改发现改动却很复杂？\nGraphviz 是一个开源的图形可视化软件，它使我们能够使用代码描述图表，并为我们自动绘制。如果将来需要修改该图，我们只需要修改描述代码，节点和边将自动为我们重新定位。\n绘制图形 在开始编写图形之前，我们需要学习如何将代码转换为图像，以便可以测试正在做的事情。\nWebgraphviz.com 可用于从浏览器绘制图形。\n我们可以使用 apt 在 Ubuntu 中安装命令行工具：\n1  1 sudo apt install graphviz   在 macOS 环境 使用 brew 安装\n1  brew install graphviz\t  除其他外，这将安装 dot CLI，该CLI可用于从文本文件生成图像：\n1  1 dot -Tpng input.gv -o output.png   在上面的示例中，我们将 png 指定为output（-Tpng），但是有许多可用的选项。如我们所见，输入文件通常使用gv扩展名。\nDOT DOT是用于描述要由Graphviz解析的图形的最常见格式。\n基本 一个简单的图形具有以下形式：\ngraph MyGraph { begin -- end } \n如果要使用有向图（带箭头），则需要使用digraph：\ndigraph MyGraph { begin -\u003e end } \n箭头可以单向或双向：\ndigraph MyGraph { a -\u003e b a -\u003e c [dir=both] } \n形状 如果我们不喜欢椭圆形，可以使用其他形状：\ndigraph MyGraph { a [shape=box] b [shape=polygon,sides=6] c [shape=triangle] d [shape=invtriangle] e [shape=polygon,sides=4,skew=.5] f [shape=polygon,sides=4,distortion=.5] g [shape=diamond] h [shape=Mdiamond] i [shape=Msquare] a -\u003e b a -\u003e c a -\u003e d a -\u003e e a -\u003e f a -\u003e g a -\u003e h a -\u003e i } \n可以在其文档的“ 节点形状”部分中找到不同的受支持形状。\n我们还可以向节点添加一些颜色和样式：\ndigraph MyGraph { a [style=filled,color=green] b [peripheries=4,color=blue] c [fontcolor=crimson] d [style=filled,fillcolor=dodgerblue,color=coral4,penwidth=3] e [style=dotted] f [style=dashed] g [style=diagonals] h [style=filled,color=\"#333399\"] i [style=filled,color=\"#ff000055\"] j [shape=box,style=striped,fillcolor=\"red:green:blue\"] k [style=wedged,fillcolor=\"green:white:red\"] a -\u003e b a -\u003e c a -\u003e d a -\u003e e b -\u003e f b -\u003e g b -\u003e h b -\u003e i d -\u003e j j -\u003e k } \n可以在 颜色名称文档 中找到不同的 颜色名称。\n箭头 箭头的尾巴和头部也可以修改：\ndigraph MyGraph { a -\u003e b [dir=both,arrowhead=open,arrowtail=inv] a -\u003e c [dir=both,arrowhead=dot,arrowtail=invdot] a -\u003e d [dir=both,arrowhead=odot,arrowtail=invodot] a -\u003e e [dir=both,arrowhead=tee,arrowtail=empty] a -\u003e f [dir=both,arrowhead=halfopen,arrowtail=crow] a -\u003e g [dir=both,arrowhead=diamond,arrowtail=box] } \n可以在箭头形状文档中找到不同的箭头类型。\n以及向箭头线添加样式：\ndigraph MyGraph { a -\u003e b [color=\"black:red:blue\"] a -\u003e c [color=\"black:red;0.5:blue\"] a -\u003e d [dir=none,color=\"green:red:blue\"] a -\u003e e [dir=none,color=\"green:red;.3:blue\"] a -\u003e f [dir=none,color=\"orange\"] d -\u003e g [arrowsize=2.5] d -\u003e h [style=dashed] d -\u003e i [style=dotted] d -\u003e j [penwidth=5] } \n如果我们注意上面的代码和图表，我们可以看到，当我们为箭头指定多种颜色时，如果不指定任何权重，每种颜色将只有一行。如果我们想要一个带有多种颜色的箭头，则至少一种颜色必须指定要覆盖的线条的重量百分比：\n1 a -\u003e e [dir=none,color=\"green:red;.3:blue\"] 标签 我们可以向节点添加标签：\ndigraph MyGraph { begin [label=\"This is the beginning\"] end [label=\"It ends here\"] begin -\u003e end } \n以及顶点：\ndigraph MyGraph { begin end begin -\u003e end [label=\"Beginning to end\"] } \n我们可以设置标签样式：\ndigraph MyGraph { begin [label=\"This is the beginning\",fontcolor=green,fontsize=10] end [label=\"It ends here\",fontcolor=red,fontsize=10] begin -\u003e end [label=\"Beginning to end\",fontcolor=gray,fontsize=16] } \n集群 聚类也称为子图。集群的名称必须以开头cluster_，否则将不会包含在框中。\ndigraph MyGraph { subgraph cluster_a { b c -\u003e d } a -\u003e b d -\u003e e } \n集群可以根据需要嵌套：\ndigraph MyGraph { subgraph cluster_a { subgraph cluster_b { subgraph cluster_c { d } c -\u003e d } b -\u003e c } a -\u003e b d -\u003e e } \nHTML HTML使我们可以创建更复杂的节点，这些节点可以分为多个部分。可以在图中独立地引用每个部分：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  digraph MyGraph { a [shape=plaintext,label=\u003c \u003ctable\u003e \u003ctr\u003e \u003ctd\u003eHello\u003c/td\u003e \u003ctd\u003eworld!\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd colspan=\"2\" port=\"a1\"\u003eare you ok?\u003c/td\u003e \u003c/tr\u003e \u003c/table\u003e \u003e] b [shape=plaintext,label=\u003c \u003ctable border=\"0\" cellborder=\"1\" cellspacing=\"0\"\u003e \u003ctr\u003e \u003ctd rowspan=\"3\"\u003eleft\u003c/td\u003e \u003ctd\u003etop\u003c/td\u003e \u003ctd rowspan=\"3\" port=\"b2\"\u003eright\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd port=\"b1\"\u003ecenter\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003ebottom\u003c/td\u003e \u003c/tr\u003e \u003c/table\u003e \u003e] a:a1 -\u003e b:b1 a:a1 -\u003e b:b2 }   \n只有HTML的一个子集可用于创建节点，并且规则非常严格。为了使节点正确显示，我们需要将设置shape为plaintext。\n需要注意的另一件事是port属性，它使我们可以使用冒号（a:a1）来引用该特定单元格。\n我们可以设置HTML节点的样式，但只能使用HTML的子集：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  digraph MyGraph { a [shape=plaintext,label=\u003c \u003ctable\u003e \u003ctr\u003e \u003ctd color=\"#ff0000\" bgcolor=\"#008822\"\u003e\u003cfont color=\"#55ff00\"\u003eHello\u003c/font\u003e\u003c/td\u003e \u003ctd\u003eworld!\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd colspan=\"2\" color=\"#00ff00\" bgcolor=\"#ff0000\"\u003e \u003cfont color=\"#ffffff\"\u003eare you ok?\u003c/font\u003e \u003c/td\u003e \u003c/tr\u003e \u003c/table\u003e \u003e] }   \n图片 有时我们想为节点使用指定图标，这可以通过image属性来完成：\ndigraph MyGraph { ec2 [shape=none,label=\"\",image=\"icons/ec2.png\"] igw [shape=none,label=\"\",image=\"icons/igw.png\"] rds [shape=none,label=\"\",image=\"icons/rds.png\"] vpc [shape=none,label=\"\",image=\"icons/vpc.png\"] subgraph cluster_vpc { label=\"VPC\" subgraph cluster_public_subnet { label=\"Public Subnet\" ec2 } subgraph cluster_private_subnet { label=\"Private Subnet\" ec2 -\u003e rds } vpc igw -\u003e ec2 } users -\u003e igw } \nRank 等级是最难理解的事情之一，因为它们会改变渲染引擎的工作方式。在这里，我将介绍一些我认为有用的基本知识。\n图表通常会从上到下呈现：\ndigraph MyGraph { a -\u003e b b -\u003e c a -\u003e d a -\u003e c } \n使用rankdir属性，我们可以从左到右渲染它：\ndigraph MyGraph { rankdir=LR a -\u003e b b -\u003e c a -\u003e d a -\u003e c } \n排名还可以用于强制一个节点与另一个节点处于同一级别：\ndigraph MyGraph { rankdir=LR a -\u003e b b -\u003e c a -\u003e d a -\u003e c {rank=same;c;b} } \n在上面的示例中，我们用于rank=same将node c与node 对齐b。\n该rankdir属性是全局属性，因此无法在集群内部更改，但是使用rank我们可以模拟LR集群内部的方向：\ndigraph MyGraph { subgraph cluster_A { a1 -\u003e a2 a2 -\u003e a3 {rank=same;a1;a2;a3} } subgraph cluster_B { a3 -\u003e b1 b1 -\u003e b2 b2 -\u003e b3 {rank=same;b1;b2;b3} } begin -\u003e a1 } \n我们可以结合rank使用constraint=false以创建更紧凑的图形：\ndigraph MyGraph { subgraph cluster_A { a1 a2 a3 {rank=same;a1;a2;a3} } subgraph cluster_B { b1 b2 b3 {rank=same;b1;b2;b3} } begin -\u003e a1 a1 -\u003e a2 [constraint=false] a2 -\u003e a3 [constraint=false] a3 -\u003e b1 b1 -\u003e b2 b2 -\u003e b3 } \n等级还可以用于指定每个节点之间的距离：\ndigraph MyGraph { rankdir=LR ranksep=1 a -\u003e b b -\u003e c c -\u003e d } \n其缺省值ranksep是.5。\n总结 在这篇文章中，我们学习了如何使用 Graphviz 基于声明性语言生成图。这使我在将来更容易绘制架构图并对其进行修改。\n我介绍了我认为对于日常使用最重要的功能，但是坦率地说，很多功能我仍还不了解。\n","description":"","tags":["graph","tool"],"title":"使用Graphviz创建图表","uri":"/blog/posts/%E4%BD%BF%E7%94%A8graphviz%E5%88%9B%E5%BB%BA%E5%9B%BE%E8%A1%A8/"},{"categories":null,"content":"如何配置你的 VSCode 这篇主要分享下 VSCode 的用法，以及如何使用其强大的插件来提升效率，我列出了一些自己用到的比较使用的插件。\n在拓展里面都能看到插件的相关文档，使用与配置。\n欢迎大家补充 :)\n本地化 Chinese (Simplified) Language Pack for Visual Studio Code\n 适用于 VS Code 的中文（简体）语言包\n 开发 Remote Development\n An extension pack that lets you open any folder in a container, on a remote machine, or in WSL and take advantage of VS Code's full feature set.\n可在远程主机上开发或者在容器内开发\n Code Runner\n Run C, C++, Java, JS, PHP, Python, Perl, Ruby, Go, Lua, Groovy, PowerShell, CMD, BASH, F#, C#, VBScript, TypeScript, CoffeeScript, Scala, Swift, Julia, Crystal, OCaml, R, AppleScript, Elixir, VB.NET, Clojure, Haxe, Obj-C, Rust, Racket, Scheme, AutoHotkey, AutoIt, Kotlin, Dart, Pascal, Haskell, Nim,\n支持各种语言运行，动态语言需要配置下 interpreter，静态语言配置 compiler\n 编程语言 Python\n Python extension pack\n集成了针对 Python 智能提示，语法检查，格式化等功能\n  IntelliSense: Edit your code with auto-completion, code navigation, syntax checking and more Linting: Get additional code analysis with Pylint, Flake8 and more Code formatting: Format your code with black, autopep or yapf Debugging: Debug your Python scripts, web apps, remote or multi-threaded processes Testing: Run and debug tests through the Test Explorer with unittest, pytest or nose Jupyter Notebooks: Create and edit Jupyter Notebooks, add and run code cells, render plots, visualize variables through the variable explorer, visualize dataframes with the data viewer, and more Environments: Automatically activate and switch between virtualenv, venv, pipenv, conda and pyenv environments Refactoring: Restructure your Python code with variable extraction, method extraction and import sorting  XML\n XML Language Support by Red Hat\nRedhat 出品，必属精品。\n  Syntax error reporting General code completion Auto-close tags Automatic node indentation Symbol highlighting Document folding Document links Document symbols and outline Renaming support Document Formatting DTD validation DTD completion DTD formatting XSD validation XSD based hover XSD based code completion XSL support XML catalogs File associations Code actions Schema Caching  YAML\n YAML Language Support by Red Hat, with built-in Kubernetes and Kedge syntax support\nRedhat 出品，必属精品。\n  YAML validation:  Detects whether the entire file is valid yaml Detects errors such as:  Node is not found Node has an invalid key node type Node has an invalid type Node is not a valid child node     Document Outlining (Ctrl + Shift + O):  Provides the document outlining of all completed nodes in the file   Auto completion (Ctrl + Space):  Auto completes on all commands Scalar nodes autocomplete to schema's defaults if they exist   Hover support:  Hovering over a node shows description if provided by schema   Formatter:  Allows for formatting the current file    Markdown All in One\n All you need to write Markdown (keyboard shortcuts, table of contents, auto preview and more)\n提供了语法提示，支持 Latex，格式化支持，预览等一条龙服务。\n 格式 Auto Rename Tag\n Auto rename paired HTML/XML tag\n Auto Complete Tag\n Extension Packs to add close tag and rename paired tag automatically for HTML/XML\n Auto Close Tag\n Automatically add HTML/XML close tag, same as Visual Studio IDE or Sublime Text\n Bracket Pair Colorizer\n A customizable extension for colorizing matching brackets\n Better Comments\n Improve your code commenting by annotating with alert, informational, TODOs, and more!\n 可视化 Excel Viewer\n View Excel spreadsheets and CSV files within Visual Studio Code workspaces.\n Draw.io Integration\n This extension integrates Draw.io into VS Code.\n CI/CD JenkinsFile Support\n Extension provides basic jenkinsfile support (highlighting, snippets and completion)\n Jenkins Jack\n Jack into your remote Jenkins to execute Pipeline scripts, provide Pipeline step auto-completions, pull Shared Library step documenation, run console groovy scripts across multiple nodes, and more! Honestly, not that much more.\n ","description":"","tags":["vscode"],"title":"如何配置你的 VSCode","uri":"/blog/posts/how-to-configure-your-vscode/"},{"categories":["Python"],"content":" 转载来源：https://linuxops.org/blog/python/prettytable.html\n 一、前言 最近在用python写一个小工具，这个工具主要就是用来管理各种资源的信息，比如阿里云的ECS等信息，因为我工作的电脑使用的是LINUX，所以就想着用python写一个命令行的管理工具，基本的功能就是同步阿里云的资源的信息到数据库，然后可以使用命令行查询。\n因为信息是展现在命令行中的，众所周知，命令行展现复杂的文本看起来着实累人，于是就想着能像表格那样展示，那看起来就舒服多了。\nprettytable库就是这么一个工具，prettytable可以打印出美观的表格，并且对中文支持相当好（如果有试图自己实现打印表格，你就应该知道处理中文是多么的麻烦）\n 说明：本文使用Markdown语法编写，为了展示方便，以及复制方便，所以本文中没有使用截图，因为格式控制的问题，文章中的运行结果会出现一些分割线的偏移，在终端中呈现并此问题，请各位手动去操作验证。\n 二、安装 prettytable并非python的内置库，通过 pip install prettytable即可安装。\n三、一个小示例 我们先来看一个示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  #!/usr/bin/python #**coding:utf-8** import sys from prettytable import PrettyTable reload(sys) sys.setdefaultencoding('utf8') table = PrettyTable(['编号','云编号','名称','IP地址']) table.add_row(['1','server01','服务器01','172.16.0.1']) table.add_row(['2','server02','服务器02','172.16.0.2']) table.add_row(['3','server03','服务器03','172.16.0.3']) table.add_row(['4','server04','服务器04','172.16.0.4']) table.add_row(['5','server05','服务器05','172.16.0.5']) table.add_row(['6','server06','服务器06','172.16.0.6']) table.add_row(['7','server07','服务器07','172.16.0.7']) table.add_row(['8','server08','服务器08','172.16.0.8']) table.add_row(['9','server09','服务器09','172.16.0.9']) print(table)   以上示例运行结果如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  linuxops@deepin:~$ python p.py +------+----------+----------+------------+ | 编号 | 云编号 | 名称 | IP地址 | +------+----------+----------+------------+ | 1 | server01 | 服务器01 | 172.16.0.1 | | 2 | server02 | 服务器02 | 172.16.0.2 | | 3 | server03 | 服务器03 | 172.16.0.3 | | 4 | server04 | 服务器04 | 172.16.0.4 | | 5 | server05 | 服务器05 | 172.16.0.5 | | 6 | server06 | 服务器06 | 172.16.0.6 | | 7 | server07 | 服务器07 | 172.16.0.7 | | 8 | server08 | 服务器08 | 172.16.0.8 | | 9 | server09 | 服务器09 | 172.16.0.9 | +------+----------+----------+------------+   在以上的示例中，我们通过form导入了表格库。 table实例化了一个表格库，并且添加了['编号','云编号','名称','IP地址']为表头，如果没有添加表头，那么会以默认的Field+编号显示，例如：\n1 2 3  +---------+----------+----------+------------+ | Field 1 | Field 2 | Field 3 | Field 4 | +---------+----------+----------+------------+   所以为更直观看出每一列的意义，还是要添加表头的。\n四、添加数据 prettytable提供了多种的添加数据的方式，最常用的应该就是按行按列添加数据了。\nA、按行添加数据 table.add_row 在上面简单的示例中，我们就是按行添加数据的。\n添加的数据必须要是列表的形式，而且数据的列表长度要和表头的长度一样。在实际的使用中，我们应该要关注到添加的数据是否和表头对应，这一点很重要。\nB、按列添加数据 table.add_column() 看下面的示例：\n1 2 3 4 5 6 7 8 9 10 11  #!/usr/bin/python #**coding:utf-8** import sys from prettytable import PrettyTable reload(sys) sys.setdefaultencoding('utf8') table = PrettyTable() table.add_column('项目', ['编号','云编号','名称','IP地址']) table.add_column('值', ['1','server01','服务器01','172.16.0.1']) print(table)   运行结果如下：\n1 2 3 4 5 6 7 8  +-------+--------+------------+ | index | 项目 | 值 | +-------+--------+------------+ | 1 | 编号 | 1 | | 2 | 云编号 | server01 | | 3 | 名称 | 服务器01 | | 4 | IP地址 | 172.16.0.1 | +-------+--------+------------+   以上示例中，我们通过add_column来按列添加数据，按列添加数据不需要在实例化表格的时候制定表头，它的表头是在添加列的时候指定的。\ntable.add_column('项目', ['编号','云编号','名称','IP地址']) 这一行代码为例，项目指定了这个列的表头名为\"项目\"，['编号','云编号','名称','IP地址']为列的值，同样为列表。\nC、从csv文件添加数据 PrettyTable不仅提供了手动按行按列添加数据，也支持直接从csv文件中读取数据。\n1 2 3 4 5 6 7 8 9 10 11 12 13  #!/usr/bin/python #**coding:utf-8** import sys from prettytable import PrettyTable from prettytable import from_csv reload(sys) sys.setdefaultencoding('utf8') table = PrettyTable() fp = open(\"res.csv\", \"r\") table = from_csv(fp) print(table) fp.close()   如果要读取cvs文件数据，必须要先导入from_csv，否则无法运行。上面的示例运行结果如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13  +------+----------+----------+------------+ | 编号 | 云编号 | 名称 | IP地址 | +------+----------+----------+------------+ | 1 | server01 | 服务器01 | 172.16.0.1 | | 2 | server02 | 服务器02 | 172.16.0.2 | | 3 | server03 | 服务器03 | 172.16.0.3 | | 4 | server04 | 服务器04 | 172.16.0.4 | | 5 | server05 | 服务器05 | 172.16.0.5 | | 6 | server06 | 服务器06 | 172.16.0.6 | | 7 | server07 | 服务器07 | 172.16.0.7 | | 8 | server08 | 服务器08 | 172.16.0.8 | | 9 | server09 | 服务器09 | 172.16.0.9 | +------+----------+----------+------------+    csv文件不能通过xls直接重命名得到，会报错。如果是xls文件，请用另存为csv获得csv文件\n D、从sql查询值添加 从数据库查询出来的数据可以直接导入到表格打印，下面的例子使用了sqlite3,如果使用的是mysql也是一样的，只要能查询到数据就能导入到表格中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  #!/usr/bin/python #**coding:utf-8** import sys from prettytable import PrettyTable from prettytable import from_db_cursor import sqlite3 reload(sys) sys.setdefaultencoding('utf8') conn = sqlite3.connect(\"/tmp/aliyun.db\") cur = conn.cursor() cur.execute(\"SELECT * FROM res\") table = from_db_cursor(cur) print(table)   运行结果如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13  +------+----------+----------+------------+ | 编号 | 云编号 | 名称 | IP地址 | +------+----------+----------+------------+ | 1 | server01 | 服务器01 | 172.16.0.1 | | 2 | server02 | 服务器02 | 172.16.0.2 | | 3 | server03 | 服务器03 | 172.16.0.3 | | 4 | server04 | 服务器04 | 172.16.0.4 | | 5 | server05 | 服务器05 | 172.16.0.5 | | 6 | server06 | 服务器06 | 172.16.0.6 | | 7 | server07 | 服务器07 | 172.16.0.7 | | 8 | server08 | 服务器08 | 172.16.0.8 | | 9 | server09 | 服务器09 | 172.16.0.9 | +------+----------+----------+------------+   E、从HTML导入数据 支持从html的表格中导入，请看下面这个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  #!/usr/bin/python #**coding:utf-8** import sys from prettytable import PrettyTable from prettytable import from_html reload(sys) sys.setdefaultencoding('utf8') html_string='''\u003ctable\u003e \u003ctr\u003e \u003cth\u003e编号\u003c/th\u003e \u003cth\u003e云编号\u003c/th\u003e \u003cth\u003e名称\u003c/th\u003e \u003cth\u003eIP地址\u003c/th\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003e1\u003c/td\u003e \u003ctd\u003eserver01\u003c/td\u003e \u003ctd\u003e服务器01\u003c/td\u003e \u003ctd\u003e172.16.0.1\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003e2\u003c/td\u003e \u003ctd\u003eserver02\u003c/td\u003e \u003ctd\u003e服务器02\u003c/td\u003e \u003ctd\u003e172.16.0.2\u003c/td\u003e \u003c/tr\u003e \u003c/table\u003e''' table = from_html(html_string) print(table[0])   运行结果如下：\n1 2 3 4 5 6  +------+----------+----------+------------+ | 编号 | 云编号 | 名称 | IP地址 | +------+----------+----------+------------+ | 1 | server01 | 服务器01 | 172.16.0.1 | | 2 | server02 | 服务器02 | 172.16.0.2 | +------+----------+----------+------------+   如上示例中，我们可以导入html的表格，但是不一样的地方是print语句，使用html表格导入数据的时候print的必须是列表中的第一个元素，否则有可能会报[\u003cprettytable.PrettyTable object at 0x7fa87feba590\u003e]这样的错误。\n这是因为table并不是PrettyTable对象，而是包含单个PrettyTable对象的列表，它通过解析html而来，所以无法直接打印table，而需要打印table[0]\n五、表格输出格式 正如支持多种输入一样，表格的输出也支持多种格式，我们在上面中的例子中已经使用了print的方式输出，这是一种常用的输出方式。\nA、print 直接通过print打印出表格。这种方式打印出的表格会带边框。\nB、输出HTML格式的表格 print(table.get_html_string())可以打印出html标签的表格。\n在上面的例子中，使用print(table.get_html_string())会打印出如下结果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  \u003ctable\u003e \u003ctr\u003e \u003cth\u003e编号\u003c/th\u003e \u003cth\u003e云编号\u003c/th\u003e \u003cth\u003e名称\u003c/th\u003e \u003cth\u003eIP地址\u003c/th\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003e1\u003c/td\u003e \u003ctd\u003eserver01\u003c/td\u003e \u003ctd\u003e服务器01\u003c/td\u003e \u003ctd\u003e172.16.0.1\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003e2\u003c/td\u003e \u003ctd\u003eserver02\u003c/td\u003e \u003ctd\u003e服务器02\u003c/td\u003e \u003ctd\u003e172.16.0.2\u003c/td\u003e \u003c/tr\u003e \u003c/table\u003e   六、选择性输出 prettytable在创建表格之后，你依然可以有选择的输出某些特定的行.\nA、输出指定的列 print table.get_string(fields=[\"编号\", \"IP地址\"])可以输出指定的列\nB、输出前两行 通过print(table.get_string(start = 0, end = 2))的可以打印出指定的列，当然start和end参数让我可以自由控制显示区间。当然区间中包含start不包含end，是不是很熟悉这样的用法？\n 根据输出指定行列的功能，我们可以同时指定行和列来输出，这里就不说明了。\n C、将表格切片 从上面的输出区间，我们做一个大胆的假设，既然区间包含start不包含end这种规则和切片的一样，我们可以不可通过切片来生成一个新的表格然后将其打印。\n事实上是可以的。\n1 2  new_table = table[0:2] print(new_table)   如上代码段中，我们就可以打印出0到1行共2行的表格，python的切片功能异常强大，配合切片我们可以自由的输入任意的行。\nD、输出排序 有时候我们需要对输出的表格进行排序，使用print table.get_string(sortby=\"编号\", reversesort=True)就可以对表格进行排序，其中reversesort指定了是否倒序排序,默认为False，即默认正序列排序。\nsortby指定了排序的字段。\n七、表格的样式 A、内置样式 通过set_style()可以设置表格样式，prettytable内置了多种的样式个人觉得MSWORD_FRIENDLY，PLAIN_COLUMNS，DEFAULT 这三种样式看起来比较清爽，在终端下显示表格本来看起就很累，再加上一下花里胡哨的东西看起来就更累。\n除了以上推荐的三种样式以外，还有一种样式不得不说，那就是RANDOM，这是一种随机的样式，每一次打印都会在内置的样式中随机选择一个，比较好玩。\n具体内置了几种样式，请各位参考官网完整自己尝试输出看看。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  #!/usr/bin/python #**coding:utf-8** import sys from prettytable import PrettyTable from prettytable import MSWORD_FRIENDLY from prettytable import PLAIN_COLUMNS from prettytable import RANDOM from prettytable import DEFAULT reload(sys) sys.setdefaultencoding('utf8') table = PrettyTable(['编号','云编号','名称','IP地址']) table.add_row(['1','server01','服务器01','172.16.0.1']) table.add_row(['3','server03','服务器03','172.16.0.3']) table.add_row(['2','server02','服务器02','172.16.0.2']) table.add_row(['9','server09','服务器09','172.16.0.9']) table.add_row(['4','server04','服务器04','172.16.0.4']) table.add_row(['5','server05','服务器05','172.16.0.5']) table.add_row(['6','server06','服务器06','172.16.0.6']) table.add_row(['8','server08','服务器08','172.16.0.8']) table.add_row(['7','server07','服务器07','172.16.0.7']) table.set_style(DEFAULT) print(table)   B、自定义样式 除了内置的样式以外，PrettyTable也提供了用户自定义，例如对齐方式，数字输出格式，边框连接符等等\nC、设置对齐方式 align提供了用户设置对齐的方式，值有l，r，c方便代表左对齐，右对齐和居中 如果不设置，默认居中对齐。\nD、控制边框样式 在PrettyTable中，边框由三个部分组成，横边框，竖边框，和边框连接符（横竖交叉的链接符号）\n如下示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  #!/usr/bin/python #**coding:utf-8** import sys from prettytable import PrettyTable reload(sys) sys.setdefaultencoding('utf8') table = PrettyTable(['编号','云编号','名称','IP地址']) table.add_row(['1','server01','服务器01','172.16.0.1']) table.add_row(['3','server03','服务器03','172.16.0.3']) table.add_row(['2','server02','服务器02','172.16.0.2']) table.add_row(['9','server09','服务器09','172.16.0.9']) table.add_row(['4','server04','服务器04','172.16.0.4']) table.add_row(['5','server05','服务器05','172.16.0.5']) table.add_row(['6','server06','服务器06','172.16.0.6']) table.add_row(['8','server08','服务器08','172.16.0.8']) table.add_row(['7','server07','服务器07','172.16.0.7']) table.align[1] = 'l' table.border = True table.junction_char='$' table.horizontal_char = '+' table.vertical_char = '%' print(table) table.border`控制是否显示边框，默认是`True   table.junction_char控制边框连接符\ntable.horizontal_char控制横边框符号\ntable.vertical_char控制竖边框符号\n上例运行如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13  $++++++$++++++++++$++++++++++$++++++++++++$ % 编号 % 云编号 % 名称 % IP地址 % $++++++$++++++++++$++++++++++$++++++++++++$ % 1 % server01 % 服务器01 % 172.16.0.1 % % 3 % server03 % 服务器03 % 172.16.0.3 % % 2 % server02 % 服务器02 % 172.16.0.2 % % 9 % server09 % 服务器09 % 172.16.0.9 % % 4 % server04 % 服务器04 % 172.16.0.4 % % 5 % server05 % 服务器05 % 172.16.0.5 % % 6 % server06 % 服务器06 % 172.16.0.6 % % 8 % server08 % 服务器08 % 172.16.0.8 % % 7 % server07 % 服务器07 % 172.16.0.7 % $++++++$++++++++++$++++++++++$++++++++++++$   以上简单介绍了表格常用的一些样式设置，具体的请参考官方网站。\nhttps://github.com/jazzband/prettytable\nhttps://code.google.com/archive/p/prettytable/wikis/Tutorial.wiki\n","description":"","tags":["python","linux"],"title":"用 prettytable 在终端输出漂亮的表格","uri":"/blog/posts/python/use-prettytable-to-output-a-pretty-table-in-the-terminal/"},{"categories":["Python","Fluent-Python"],"content":" 有很多人抱怨，把这个特性命名为“装饰器”不好。主要原因是，这个名称与 GoF 书使用的不一致。装饰器这个名称可能更适合在编译器领域使用，因为它会遍历并注解语法书。 —“PEP 318 — Decorators for Functions and Methods”\n 本章的最终目标是解释清楚函数装饰器的工作原理，包括最简单的注册装饰器和较复杂的参数化装饰器。\n讨论内容：\n Python 如何计算装饰器语法 Python 如何判断变量是不是局部的 闭包存在的原因和工作原理 nonlocal 能解决什么问题 实现行为良好的装饰器 标准库中有用的装饰器 实现一个参数化的装饰器  装饰器基础 装饰器是可调用的对象，其参数是一个函数（被装饰的函数）。\n装饰器可能会处理被装饰的函数，然后把它返回，或者将其替换成另一个函数或可调用对象。\n装饰器两大特性：\n 能把被装饰的函数替换成其他函数 装饰器在加载模块时立即执行  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  # 装饰器通常会把函数替换成另一个函数 def decorate(func): def wrapped(): print('Running wrapped()') return wrapped @decorate def target(): print('running target()') target() # 以上写法等同于 def target(): print('running target()') target = decorate(target) target() # 这里真正调用的是装饰器返回的函数 def deco(func): def inner(): print('running iner()') return inner @deco def target(): print('running target()') target() # target 现在是 inner 的引用 target   Python 何时执行装饰器 装饰器在导入时（模块加载时）立即执行\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  # registration.py registry = [] def register(func): print('running register {}'.format(func)) registry.append(func) return func @register def f1(): print('running f1()') @register def f2(): print('running f2()') def f3(): print('running f3()') def main(): print('running main()') print('registry -\u003e', registry) f1() f2() f3() if __name__=='__main__': main() # python3 registration.py # output: # running register \u003cfunction f1 at 0x10b4194d0\u003e # running register \u003cfunction f2 at 0x10b419ef0\u003e # running main() # registry -\u003e [\u003cfunction f1 at 0x10b4194d0\u003e, \u003cfunction f2 at 0x10b419ef0\u003e] # running f1() # running f2() # running f3() # import registration # running register \u003cfunction f1 at 0x10d89e950\u003e # running register \u003cfunction f2 at 0x10d89e050\u003e   通过上面的例子，强调装饰器函数在导入模块式立即执行，而普通函数在被调用时运行。导入时和运行时的区别。\n 装饰器函数通常与被装饰函数不在同一模块。 register 装饰器返回的函数没有变化  上面的装饰器会原封不动地返回被装饰的函数，而不一定会对函数做修改。 这种装饰器叫注册装饰器，通过使用它来中心化地注册函数，例如把 URL 模式映射到生成 HTTP 响应的函数上的注册处。\n使用装饰器 1 2 3 4 5 6 7 8 9 10  promos = [] def promotion(promo_func): promos.append(promo_func) return promo_func @promotion def fidelity(order): \"\"\"积分 \u003e= 1000 提供 5% 折扣\"\"\" return order.total() * .05 if order.customer.fidelity \u003e= 1000 else 0   变量作用域规则 1 2 3 4 5 6 7 8 9 10 11 12 13 14  # 比较两个例子 b = 6 def f1(a): print(a) print(b) f1(3) def f2(a): print(a) print(b) b = 9 # b 此时为局部变量 f2(3)   Python 假定在函数体内部的变量为局部变量。如果未在局部变量中找到，会逐级向上查找变量。\n如果想在函数中赋值时让解释器把 b 当做全局变量，用 global 关键字\n1 2 3 4 5 6  def f3(a): global b print(a) print(b) b = 9 f3(3)   闭包 闭包和匿名函数常被弄混。只有涉及到嵌套函数时才有闭包问题。\n闭包指延伸了作用域的函数，其中包含函数定义体中的引用，但非定义体中定义的非全局变量。和函数是否匿名无关。关键是能访问定义体之外定义的非全局变量。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  class Averager(): def __init__(self): self.series = [] def __call__(self, new_value): self.series.append(new_value) total = sum(self.series) return total/len(self.series) avg = Averager() avg(10) avg(11) avg(12) def make_averager(): series = [] # 自由变量 def averager(new_value): series.append(new_value) total = sum(series) return total/len(series) return averager avg = make_averager() avg(10) avg(11) avg(12) avg.__code__.co_varnames avg.__code__.co_freevars avg.__closure__ avg.__closure__[0].cell_contents   在 averager 函数中，series 是自由变量，指未在本地作用域绑定的变量。\n通过 __code__.co_freevars __closure__ 查看自由变量和闭包\n闭包是一种函数，保留定义函数时存在的自由变量的绑定。调用函数时，虽然定义作用域不可用了，但仍能使用那些绑定\n 只有嵌套在其他函数中的函数才可能需要处理不在全局作用域的外部变量\n nonlocal 声明 下面一个例子有缺陷：\n1 2 3 4 5 6 7 8 9 10 11 12 13  def make_averager(): count = 0 total = 0 def averager(new_value): count += 1 total += new_value return total / count return averager avg = make_averager() avg(10)   注意 count， total 的赋值语句使它们成为局部变量，在赋值是会隐式创建局部变量，这样它们就不是自由变量了，因此不会保存在闭包中。\n为解决这个问题，Python3 引入了 nonlocal 声明，作用是吧变量标记为自由变量，即使在函数中为变量新值了，也会变成自由变量。在闭包中的绑定也会更新\n 对于没有 nonlocal 的 Python2 PEP3104\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14  def make_averager(): count = 0 total = 0 def averager(new_value): nonlocal count, total count += 1 total += new_value return total / count return averager avg = make_averager() avg(10)   实现一个简单的装饰器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  import time def clock(func): def clocked(*args): t0 = time.perf_counter() result = func(*args) elapsed = time.perf_counter() - t0 name = func.__name__ arg_str = ', '.join(repr(arg) for arg in args) print('[%0.8fs] %s(%s) -\u003e % r' %(elapsed, name, arg_str, result)) return result return clocked @clock def snooze(seconds): time.sleep(seconds) @clock def factorial(n): return 1 if n \u003c 2 else n * factorial(n-1) if __name__=='__main__': print('*' * 40, 'Calling snooze(.123)') snooze(.123) print('*' * 40, 'Calling factorial(6)') print('6! =', factorial(6))   装饰器的典型行为：把被装饰的函数替换成新函数，二者接受相同的参数，而且(通常)返回被装装饰函数本该返回的值，同时做一些额外操作\n1  factorial.__name__   上述实现的 clock 装饰器有几个缺点：不支持关键字参数，而且遮盖了被装饰函数的 __name__, __doc__ 属性\nfunctools.wraps 装饰器把相关属性从 func 复制到 clocked 中，还能正确处理关键字函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  import time import functools def clock(func): @functools.wraps(func) def clocked(*args, **kwargs): t0 = time.perf_counter() result = func(*args, **kwargs) elapsed = time.perf_counter() - t0 name = func.__name__ arg_lst = [] if args: arg_str = ', '.join(repr(arg) for arg in args) if kwargs: pairs = ['%s=%s' % (k, w) for k, w in sorted(kwargs.items())] arg_lst.append(', '.join(pairs)) arg_str = ', '.join(arg_lst) print('[%0.8fs] %s(%s) -\u003e % r' %(elapsed, name, arg_str, result)) return result return clocked if __name__=='__main__': print('*' * 40, 'Calling snooze(.123)') snooze(.123) print('*' * 40, 'Calling factorial(6)') print('6! =', factorial(6))   标准库中的装饰器 Python 内置的三个装饰器分别为 property, classmethod 和 staticmethod.\n但 Python 内置的库中，有两个装饰器很常用，分别为 functools.lru_cache 和 functools.singledispatch.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  @clock def fibonacci(n): if n \u003c 2: return n return fibonacci(n-2) + fibonacci(n-1) print(fibonacci(6)) @functools.lru_cache() # () 是因为 lru_cache 可以接受配置参数 # functools.lru_cache(maxsize=128, typed=False) @clock # 叠放装饰器 def fibonacci(n): if n \u003c 2: return n return fibonacci(n-2) + fibonacci(n-1) print(fibonacci(6))   单分派反函数 Python 不支持重载方法或函数，所以我们不能使用不同的签名定义 htmlize 的辩题，也无法使用不同的方式处理不同的数据类型。\n一种常见的方法是把 htmlize 编程一个分派函数，使用 if-elif-else 分别调用专门的函数。但这样不便于模块的拓展，而且臃肿\nfunctoos.singledispatch 装饰器可以把整体方案拆分成多个模块，甚至可以为你无法修改的类提供专门的函数。 使用 functoos.singledispatch 装饰的普通函数会变成反函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42  # 生成 HTML 显示不同类型的 python 对象 import html def htmlize(obj): content = html.escape(repr(obj)) return '\u003cpre\u003e{}\u003c/pre\u003e'.format(content) # htmlize({1, 2, 3}) # htmlize(abs) # htmlize('hwimich \u0026 Co.\\n- a game') # htmlize(42) # print(htmlize(['alpha', 66, {3, 2, 1}])) from functools import singledispatch from collections import abc import numbers @singledispatch # 标记处理 object 类型的基函数 def htmlize(obj): content = html.escape(repr(obj)) return '\u003cpre\u003e{}\u003c/pre\u003e'.format(content) @htmlize.register(str) def _(text): content = html.escape(text).replace('\\n', '\u003cbr\u003e\\n') return '\u003cp\u003e{0}\u003c/p\u003e'.format(content) @htmlize.register(numbers.Integral) # Integral 是 int 的虚拟超类 def _(n): return '\u003cpre\u003e{0} (0x{0:x})\u003c/pre\u003e'.format(n) @htmlize.register(tuple) @htmlize.register(abc.MutableSequence) def _(seq): inner = '\u003c/li\u003e\\n\u003cli\u003e'.join(htmlize(item) for item in seq) return '\u003cul\u003e\\n\u003cli\u003e' + inner + '\u003c/li\u003e\\n\u003cul\u003e' htmlize({1, 2, 3}) htmlize(abs) htmlize('hwimich \u0026 Co.\\n- a game') htmlize(42) print(htmlize(['alpha', 66, {3, 2, 1}]))   只要可能，注册的专门函数应该处理抽象基类(numbers.Integral, abc.MutableSequence)， 不要处理具体实现（int，list）\n这样代码支持的兼容类型更广泛。\n使用 singledispatch 可以在系统的任何地方和任何模块注册专门函数。\n叠放装饰器 1 2 3 4 5 6 7  @d1 @d2 def func(): pass # 等同于 func = d1(d2(func))   参数化装饰器 为了方便理解，可以把参数化装饰器看成一个函数：这个函数接受任意参数，返回一个装饰器（参数为 func 的另一个函数）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  # 参数化的注册装饰器 registry = set() # 这是一个工厂函数，用来构建装饰器函数 def register(active=True): # decorate 是真正的装饰器 def decorate(func): print('running register(active=%s)-\u003edecorate(%s)' % (active, func)) if active: registry.add(func) else: registry.discard(func) return func return decorate @register(active=False) def f1(): print('running f1()') @register() def f2(): print('running f2()') def f3(): print('running f3()') f1() f2() f3() register()(f3) registry register(active=False)(f2)   参数化 clock 装饰器 为 clock 装饰器添加一个功能，让用户传入一个格式化字符串，控制被装饰函数的输出。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  import time DEFAULT_FMT = '[{elapsed:0.8f}s] {name}({args}) -\u003e {result}' def clock(fmt=DEFAULT_FMT): def decorate(func): def clocked(*_args): t0 = time.time() _result = func(*_args) elapsed = time.time() - t0 name = func.__name__ args = ', '.join(repr(arg) for arg in _args) result = repr(_result) print(fmt.format(**locals())) return _result return clocked return decorate # @clock() # @clock('{name}: {elapsed}s') @clock('{name}{args} dt={elapsed:0.3f}s') def snooze(seconds): time.sleep(seconds) for i in range(3): snooze(.123)   小结 本节先编写了一个没有内部函数的 @register 装饰器。 然后实现了有两层嵌套函数的参数化装饰器 @clock()\n参数化装饰器基本上设计至少两层嵌套函数。\n标准库 functools 提供两个非常重要的装饰器 @lru_cache() 和 @singledispatch\n理解装饰器，需要区分导入时、运行时、变量作用域，闭包等。\n推荐阅读：decorator 第三方库\n1    ","description":"","tags":["python"],"title":"《流畅的Python》函数装饰器与闭包","uri":"/blog/posts/python/fluent-python/fluent-python-function-decorators-and-closures/"},{"categories":["Python","Fluent-Python"],"content":" 不管别人怎么说或怎么想，我从未觉得 Python 受到来自函数式语言的太多影响。我非常熟悉命令式语言，如 C 和 Algol 68，虽然我把函数定为一等对象，但是我并不把 Python 当作函数式编程语言。\n—— Guido van Rossum: Python 仁慈的独裁者\n 在 Python 中，函数是一等对象。\n编程语言理论家把“一等对象”定义为满足下述条件的程序实体：\n 在运行时创建 能赋值给变量或数据结构中的元素 能作为参数传给函数 能作为函数的返回结果  函数即为对象 1 2 3 4 5 6 7  def factorial(n): \"\"\"returns n!\"\"\" return 1 if n \u003c 2 else n * factorial(n-1) factorial(42) factorial.__doc__ type(factorial)   通过 type(factorial) 可以看到 function 是一种类型，或者说，函数也是对象，可以通过__doc__ 去访问它的属性。\n那么作为对象的函数，也能作为参数被传递。函数式风格编程也基于此\n1 2 3 4 5  fact = factorial fact fact(5) map(factorial, range(11)) list(map(fact, range(11)))   高阶函数 输入或者输出是函数的即为高阶函数(higher order function)。例如：map， sorted。\n1 2 3  fruits = ['strawberry', 'fig', 'apple', 'cherry', 'raspberry', 'banana'] # function len() as key sorted(fruits, key=len)   map、filter 和 reduce 的替代品 函数式语言通常提供 map、filter 和 reduce 三个高阶函数。 在 Python 中引入了列表推导和生成式表达式，可以替代它们且更容易阅读。\n1 2 3 4  list(map(fact, range(6))) [fact(n) for n in range(6)] list(map(factorial, filter(lambda n : n % 2, range(6)))) [factorial(n) for n in range(6) if n % 2]   map 和 filter 返回生成器，可用生成器表达式替代 reduce 常用求和，目前最好使用 sum 替代\n1 2 3 4 5  from functools import reduce from operator import add reduce(add, range(100)) sum(range(100))   sum 和 reduce 把操作连续应用在序列元素上，得到返回值\nall(iterable), any(iterable) 也是规约函数\n all(iterable): 每个元素为真，返回真 any(iterable): 存在一个元素为真，返回真  匿名函数 Python 支持 lambda 表达式。 它是函数对象，在句法上被限制只能用存表达式。\n参数列表中最适合使用匿名函数。\n1 2 3 4  # 根据单词末尾字符排序 fruits = ['strawberry', 'fig', 'apple', 'cherry', 'raspberry', 'banana'] sorted(fruits, key=lambda word: word[::-1])   Python 的可调用对象\n 用户定义的函数：使用 def 或 lambda 创建 内置函数：如 len 或 time.strfttime 内置方法：如 dict.get 类：先调用 __new__ 创建实例，再对实例运行 __init__ 方法 类的实例：如果类上定义了 __call__ 方法，则实例可以作为函数调用 生成器函数：使用 yield 关键字的函数或方法，调用生成器函数会返回生成器对象  判断对象是否能调用，使用内置的 callable() 函数\n1 2  abs, str, 13 [callable(obj) for obj in (abs, str, 13)]   用户定义的可调用类型 任何 Python 对象都可以表现得像函数，只需实现实例方法 __call__\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  import random class BingoCage: def __init__(self, items): self._items = list(items) random.shuffle(self._items) def pick(self): try: return self._items.pop() except IndexError: raise LookupError('pick from empty BingoCage') def __call__(self): return self.pick() bingo = BingoCage(range(3)) bingo.pick() bingo() callable(bingo)   实现 __call__ 方法的类是创建函数类对象的简便方式。 函数类对象有自己的状态，即为实例变量。装饰器函数也可以有.\n函数内省 内省（introspection）可以查看函数内部的细节，函数有许多属性。使用 dir 函数可以查看，或使用 code 属性\n1 2  dir(factorial) # factorial.__code__.co_varnames   1 2 3 4 5 6 7  # eg:5-9 # 列出常规对象没有而函数有的属性 class C: pass obj = C() def func(): pass sorted(set(dir(func)) - set(dir(obj)))   函数属性说明 // 插入表格\n从定位参数到仅限关键字参数 本节讨论 python 参数处理机制。py3 提供了仅限关键字参数（keyword-only argument） 调用函数使用 * 和 ** 展开可迭代对象。\n positional argument 位置参数 keyword-only argument 仅限关键字参数  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  def tag(name, *content, cls=None, **attrs): \"\"\"生成一个或多个 HTML 标签\"\"\" if cls is not None: attrs['class'] = cls if attrs: attr_str = ''.join(' %s=\"%s\"' % (attr, value) for attr, value in sorted(attrs.items())) else: attr_str = '' if content: return '\\n'.join('\u003c%s%s\u003e%s\u003c/%s\u003e' % (name, attr_str, c, name) for c in content) else: return '\u003c%s%s/\u003e' % (name, attr_str) tag('br') tag('p', 'hello') tag('p', 'hello', 'world') # 'hello', 'world' -\u003e *content tag('p', 'hello', id=33) # id=33 -\u003e **attrs tag('p', 'hello', 'world', cls='sidebar') tag(content='testing', name=\"img\") my_tag = { 'name': 'img', 'title': 'Sunset Boulevard', 'src': 'sunset.jpg', 'cls': 'framed' } tag(**my_tag)   cls 参数只能通过关键字指定，而不能通过位置参数指定。\n定义函数时若只想定仅限关键字参数，要把它放在带有 * 参数后面，如果不想支持数量不定的位置参数，但支持 keyowrd-only, 在函数签名中放一个 *\n1 2 3 4 5  def f(a, *, b): return a, b # f(1, 2) f(1, b=2)   获取关于参数的信息 上面提到，函数内省可以查看函数内部信息，通过 HTTP 微框架 Bobo 作为例子来看下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  # eg: 5-12 # hello.py import bobo @bobo.query('/') def hello(person): return 'Hello %s!' % person # 在环境中执行 bobo -f hello.py, 若运行端口为 http://localhost:8080/ # 没有传入参数 # curl -i http://localhost:8080/ # HTTP/1.0 403 Forbidden # Date: Wed, 22 Apr 2020 06:23:33 GMT # Server: WSGIServer/0.2 CPython/3.7.4 # Content-Type: text/html; charset=UTF-8 # Content-Length: 103 # \u003chtml\u003e # \u003chead\u003e\u003ctitle\u003eMissing parameter\u003c/title\u003e\u003c/head\u003e # \u003cbody\u003eMissing form variable person\u003c/body\u003e # \u003c/html\u003e # 传入参数 # curl -i http://localhost:8080/?person=Jim # HTTP/1.0 200 OK # Date: Wed, 22 Apr 2020 06:24:47 GMT # Server: WSGIServer/0.2 CPython/3.7.4 # Content-Type: text/html; charset=UTF-8 # Content-Length: 10 # Hello Jim!%    Bobo 如何知道函数需要哪个参数呢？\n函数对象有 __defaults__ 属性，其值为一个元祖，保存着位置参数和关键字参数的默认值。\nkeyword-only 参数默认值保存在 __kwdefaults__ 属性中。\n参数的名称在 __code__ 属性中，其值为 code 对象的引用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  def clip(text, max_len=80): \"\"\"在 max_len 前后的第一个空格处截断文本\"\"\" end = None if (len(text)) \u003e max_len: space_before = text.rfind(' ', 0, max_len) if space_before \u003e= 0: end = space_before else: space_after = text.rfind(' ', max_len) if space_after \u003e= 0: end = space_after if end is None: end = len(text) return text[:end].rstrip() clip.__defaults__ # clip.__code__ # clip.__code__.co_varnames # clip.__code__.co_argcount   函数签名信息，参数和默认值是分开的。可以使用 inspect 模块提取这些信息\n1 2 3 4 5 6 7  from inspect import signature sig = signature(clip) sig str(sig) for name, param in sig.parameters.items(): print(param.kind, ':', name, '=', param.default)   kind 属性值在 _Parameterkind 类中，列举如下：\n POSTIONAL_OR_KEYWORD VAR_POSITIONAL VAR_KEYWORD KEYWORD-ONLY POSITIONAL_ONLY  inspect.Signature 有 bind 方法，可以把任意个参数绑定在签名中的形参上。\n框架可以使用此方法在调用函数前验证参数\n1 2 3 4 5 6 7 8 9 10 11 12 13  import inspect sig = inspect.signature(tag) my_tag = { 'name': 'img', 'title': 'Sunset Boulevard', 'src': 'sunset.jpg', 'cls': 'framed'} bound_args = sig.bind(**my_tag) bound_args del my_tag['name'] # missing argument error bound_args = sig.bind(**my_tag)   框架和 IDE 工具可以使用这些信息验证代码\n函数注解（annotation） 各个参数可以在 : 后添加注解表达式。\n参数有默认值，注解放在参数名和 = 号之间，注解返回值在函数声明末尾添加 -\u003e 和表达式\n注解不会做任何处理，只存储在函数 __annotations__ 属性中。\n注解只是元数据，可以供 IDE，框架和装饰器等工具使用\ninspect.signature() 函数知道怎么提取注解\n1 2 3 4  def clip(text: str, max_len: 'int \u003e 0' = 80) -\u003e str: pass clip.__annotations__   1 2 3 4 5 6 7 8 9  from inspect import signature sig = signature(clip) sig.return_annotation for param in sig.parameters.values(): note = repr(param.annotation).ljust(13) print(note, ':', param.name, '=', param.default)   支持函数式编程的包 operator 模块 operator 里有很多函数，对应着 Python 中的内置运算符，使用它们可以避免编写很多无趣的 lambda 函数，如：\n add: lambda a, b: a + b or_: lambda a, b: a or b itemgetter: lambda a, b: a[b] attrgetter: lambda a, b: getattr(a, b)  1 2 3 4 5 6 7 8  from functools import reduce from operator import mul def fact(n): return reduce(lambda a, b: a*b, range(1, n+1)) def fact(n): return reduce(mul, range(1, n+1))   还有一类函数，能替代从序列中取出或读取元素属性的 lambda 表达式。如 itemgetter，attrgetter\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  metro_data = [ ('Tokyo', 'JP', 36.933, (35.689722, 139.691667)), # \u003c1\u003e ('Delhi NCR', 'IN', 21.935, (28.613889, 77.208889)), ('Mexico City', 'MX', 20.142, (19.433333, -99.133333)), ('New York-Newark', 'US', 20.104, (40.808611, -74.020386)), ('Sao Paulo', 'BR', 19.649, (-23.547778, -46.635833)), ] from operator import itemgetter for city in sorted(metro_data, key=lambda fields: fields[1]): print(city) for city in sorted(metro_data, key=itemgetter(1)): print(city) # itemgetter 返回提取的值构成的元祖，可以用来提取指定字段或调整元祖顺序 cc_name = itemgetter(1, 0) for city in metro_data: print(cc_name(city))   itemgetter 使用 [] 运算符，因为它不仅支持序列，还支持映射和任何实现 __getitem__ 的类\nattrgetter 作用相似，它创建的函数根据名称提取对象的属性。包含 . 的，会进入到嵌套对象提取属性\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  from collections import namedtuple LatLong = namedtuple('Latlong', 'lat long') Metorpolis = namedtuple('Metorpolis', 'name cc pop coord') metro_areas = [Metorpolis(name, cc, pop, LatLong(lat, long)) for name, cc, pop, (lat, long) in metro_data] metro_areas[0] metro_areas[0].coord.lat from operator import attrgetter name_lat = attrgetter('name', 'coord.lat') for city in sorted(metro_areas, key=attrgetter('coord.lat')): print(name_lat(city))   1 2  import operator [name for name in dir(operator) if not name.startswith('_')]   operator 模块的函数可以通过 dir(operator) 查看。\n介绍 methodcaller, 它的作用与前两个函数相似，它创建的函数会在对象调用参数指定的方法\n1 2 3 4 5 6 7  from operator import methodcaller s = 'The time has come' upcase = methodcaller('upper') upcase(s) hiphenate = methodcaller('replace', ' ', '-') hiphenate(s)   使用 functools.partial 冻结参数 functools 最常用的函数有 reduce，之前已经介绍过。余下函数中最有用的是 partial 及其变体 partialmethod\n它的作用是：把原函数某些参数固定。\npartial 第一个函数是可调用对象，后面跟任意个位置参数和关键字参数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  from operator import mul from functools import partial triple = partial(mul, 3) triple(7) list(map(triple, range(1, 10))) picture = partial(tag, 'img', cls='pic-frame') picture(src='wumpus.jepg') picture picture.func picture.args picture.keywords   functoos.partialmethod 作用与 partial 一样，不过适用于处理方法的\n小结 探讨 Python 函数的一等特性。意味着可以把函数赋值给变量，传入其他函数，存储于数据结构中，以及访问函数属性。\n高阶函数是函数式编程的重要组成。\nPython 的可调用对象: 7种\n函数及其注解有丰富的特性。可通过 inspect 模块读取\n最后介绍了 operator 模块中的一些函数，可以替换掉功能有限的 lambda 表达式。\n","description":"","tags":["python"],"title":"《流畅的 Python》一等函数","uri":"/blog/posts/python/fluent-python/fluent-python-first-class-function/"},{"categories":["Python"],"content":"Beautiful is better than ugly. （优美比丑陋好）\nExplicit is better than implicit.（清晰比晦涩好）\nSimple is better than complex.（简单比复杂好）\nComplex is better than complicated.（复杂比错综复杂好）\nFlat is better than nested.（扁平比嵌套好）\nSparse is better than dense.（稀疏比密集好）\nReadability counts.（可读性很重要）\nSpecial cases aren't special enough to break the rules.（特殊情况也不应该违反这些规则）\nAlthough practicality beats purity.（但现实往往并不那么完美）\nErrors should never pass silently.（异常不应该被静默处理）\nUnless explicitly silenced.（除非你希望如此）\nIn the face of ambiguity, refuse the temptation to guess.（遇到模棱两可的地方，不要胡乱猜测）\nThere should be one-- and preferably only one --obvious way to do it.（肯定有一种通常也是唯一一种最佳的解决方案）\nAlthough that way may not be obvious at first unless you're Dutch.（虽然这种方案并不是显而易见的，因为你不是那个荷兰人^这里指的是Python之父Guido^）\nNow is better than never.（现在开始做比不做好）\nAlthough never is often better than *right* now.（不做比盲目去做好^极限编程中的YAGNI原则^）\nIf the implementation is hard to explain, it's a bad idea.（如果一个实现方案难于理解，它就不是一个好的方案）\nIf the implementation is easy to explain, it may be a good idea.（如果一个实现方案易于理解，它很有可能是一个好的方案）\nNamespaces are one honking great idea -- let's do more of those!（命名空间非常有用，我们应当多加利用）\n","description":"","tags":["python"],"title":"Python 之禅","uri":"/blog/posts/python/zen-of-python/"},{"categories":["Web"],"content":"dumpdata 命令：\n它可以用来备份（导出）模型实例或整个数据库\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  ./manage.py dumpdata --help usage: manage.py dumpdata [-h] [--format FORMAT] [--indent INDENT] [--database DATABASE] [-e EXCLUDE] [--natural-foreign] [--natural-primary] [-a] [--pks PRIMARY_KEYS] [-o OUTPUT] [--version] [-v {0,1,2,3}] [--settings SETTINGS] [--pythonpath PYTHONPATH] [--traceback] [--no-color] [--force-color] [app_label[.ModelName] [app_label[.ModelName] ...]] Output the contents of the database as a fixture of the given format (using each model's default manager unless --all is specified). positional arguments: app_label[.ModelName] Restricts dumped data to the specified app_label or app_label.ModelName. optional arguments: -h, --help show this help message and exit --format FORMAT Specifies the output serialization format for fixtures. --indent INDENT Specifies the indent level to use when pretty-printing output. --database DATABASE Nominates a specific database to dump fixtures from. Defaults to the \"default\" database. -e EXCLUDE, --exclude EXCLUDE An app_label or app_label.ModelName to exclude (use multiple --exclude to exclude multiple apps/models). --natural-foreign Use natural foreign keys if they are available. --natural-primary Use natural primary keys if they are available. -a, --all Use Django's base manager to dump all models stored in the database, including those that would otherwise be filtered or modified by a custom manager. --pks PRIMARY_KEYS Only dump objects with given primary keys. Accepts a comma-separated list of keys. This option only works when you specify one model. -o OUTPUT, --output OUTPUT Specifies file to which the output is written. --version show program's version number and exit -v {0,1,2,3}, --verbosity {0,1,2,3} Verbosity level; 0=minimal output, 1=normal output, 2=verbose output, 3=very verbose output --settings SETTINGS The Python path to a settings module, e.g. \"myproject.settings.main\". If this isn't provided, the DJANGO_SETTINGS_MODULE environment variable will be used. --pythonpath PYTHONPATH A directory to add to the Python path, e.g. \"/home/djangoprojects/myproject\". --traceback Raise on CommandError exceptions --no-color Don't colorize the command output. --force-color Force colorization of the command output.     基础数据库导出\n1  ./manage.py dumpdata \u003e db.json   这会导出整个数据库到 db.json\n  备份指定的 app\n1  ./manage.py dumpdata admin \u003e admin.json   这会导出 admin 应用的内容到 admin.json\n  备份指定的数据表\n1  ./manage.py dumpdata admin.logentry \u003e logentry.json   这会导出 admin.logentry 数据表的所有数据\n1  ./manage.py dumpdata auth.user \u003e user.json   这会导出 auth.user 数据表的所有数据\n  dumpdata —exclude\n—exclude 选项用来指定无需被导出的 apps/tables\n1  ./manage.py dumpdata --exclude auth.permission \u003e db.json   这会导出整个数据库，但不包括 auth.permisson\n  dumpdata —intent\n默认情况，dumpdata 的输出会挤在同一行，可读性很差。使用 —indent 可以设定缩进美化输出\n1  ./manage.py dumpdata auth.user --indent 2 \u003e user.json   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  [ { \"model\": \"auth.user\", \"pk\": 1, \"fields\": { \"password\": \"pbkdf2_sha256$150000$i8oET981EnSJ$d2RCpfY76gFHbwUs1HekSK+pOLYMJFcJ1wFcuyf6R28=\", \"last_login\": \"2020-04-13T09:21:34.639Z\", \"is_superuser\": true, \"username\": \"xiao\", \"first_name\": \"\", \"last_name\": \"\", \"email\": \"yuechuan.xiao@artosyn.cn\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2020-04-13T08:59:01.310Z\", \"groups\": [], \"user_permissions\": [] } }, { \"model\": \"auth.user\", \"pk\": 2, \"fields\": { \"password\": \"pbkdf2_sha256$150000$PgBKh5sMAE1y$xdFkYi+gprF1v2rlOyw2OOsRn87zSeTVLJ9dGfoXzIw=\", \"last_login\": null, \"is_superuser\": true, \"username\": \"qa\", \"first_name\": \"\", \"last_name\": \"\", \"email\": \"qa@artosyn.cn\", \"is_staff\": true, \"is_active\": true, \"date_joined\": \"2020-04-13T08:59:16.279Z\", \"groups\": [], \"user_permissions\": [] } } ]     dumpdata —format\n默认输出格式为 JSON。使用 —format 可以指定输出格式\n json xml yaml  1  ./manage.py dumpdata auth.user --indent 2 --format xml \u003e user.xml   这会输出 xml 文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e \u003cdjango-objects version=\"1.0\"\u003e \u003cobject model=\"auth.user\" pk=\"1\"\u003e \u003cfield name=\"password\" type=\"CharField\"\u003epbkdf2_sha256$150000$i8oET981EnSJ$d2RCpfY76gFHbwUs1HekSK+pOLYMJFcJ1wFcuyf6R28=\u003c/field\u003e \u003cfield name=\"last_login\" type=\"DateTimeField\"\u003e2020-04-13T09:21:34.639297+00:00\u003c/field\u003e \u003cfield name=\"is_superuser\" type=\"BooleanField\"\u003eTrue\u003c/field\u003e \u003cfield name=\"username\" type=\"CharField\"\u003exiao\u003c/field\u003e \u003cfield name=\"first_name\" type=\"CharField\"\u003e\u003c/field\u003e \u003cfield name=\"last_name\" type=\"CharField\"\u003e\u003c/field\u003e \u003cfield name=\"email\" type=\"CharField\"\u003eyuechuan.xiao@artosyn.cn\u003c/field\u003e \u003cfield name=\"is_staff\" type=\"BooleanField\"\u003eTrue\u003c/field\u003e \u003cfield name=\"is_active\" type=\"BooleanField\"\u003eTrue\u003c/field\u003e \u003cfield name=\"date_joined\" type=\"DateTimeField\"\u003e2020-04-13T08:59:01.310568+00:00\u003c/field\u003e \u003cfield name=\"groups\" rel=\"ManyToManyRel\" to=\"auth.group\"\u003e\u003c/field\u003e \u003cfield name=\"user_permissions\" rel=\"ManyToManyRel\" to=\"auth.permission\"\u003e\u003c/field\u003e \u003c/object\u003e \u003cobject model=\"auth.user\" pk=\"2\"\u003e \u003cfield name=\"password\" type=\"CharField\"\u003epbkdf2_sha256$150000$PgBKh5sMAE1y$xdFkYi+gprF1v2rlOyw2OOsRn87zSeTVLJ9dGfoXzIw=\u003c/field\u003e \u003cfield name=\"last_login\" type=\"DateTimeField\"\u003e\u003cNone\u003e\u003c/None\u003e\u003c/field\u003e \u003cfield name=\"is_superuser\" type=\"BooleanField\"\u003eTrue\u003c/field\u003e \u003cfield name=\"username\" type=\"CharField\"\u003eqa\u003c/field\u003e \u003cfield name=\"first_name\" type=\"CharField\"\u003e\u003c/field\u003e \u003cfield name=\"last_name\" type=\"CharField\"\u003e\u003c/field\u003e \u003cfield name=\"email\" type=\"CharField\"\u003eqa@artosyn.cn\u003c/field\u003e \u003cfield name=\"is_staff\" type=\"BooleanField\"\u003eTrue\u003c/field\u003e \u003cfield name=\"is_active\" type=\"BooleanField\"\u003eTrue\u003c/field\u003e \u003cfield name=\"date_joined\" type=\"DateTimeField\"\u003e2020-04-13T08:59:16.279788+00:00\u003c/field\u003e \u003cfield name=\"groups\" rel=\"ManyToManyRel\" to=\"auth.group\"\u003e\u003c/field\u003e \u003cfield name=\"user_permissions\" rel=\"ManyToManyRel\" to=\"auth.permission\"\u003e\u003c/field\u003e \u003c/object\u003e \u003c/django-objects\u003e     loaddata 命令\n用来导入 fixtures（dumpdata 导出的数据）到数据库\n1  ./manage.py loaddata user.json   这会导入 user.json 里的内容到数据库\n  恢复 fresh database\n当你通过 dumpdata 命令备份整个数据库时，它将备份所有数据表。若使用 dump 文件导入到另外的 Django 项目，会导致 IntegrityError。\n可以通过备份时加入选项 —exclude contenttypes 和 auth.permissions 数据表修复此问题\n1  ./manage.py dumpdata --exclude auth.permission --exclude contenttypes \u003e db.json   现在再用 loaddata 命令导入 fresh dababase\n1  ./manage.py loaddata db.json     ","description":"","tags":["django"],"title":"Django 导出和导入数据","uri":"/blog/posts/web/django-export-and-import-data/"},{"categories":["Python"],"content":"以下所有内容包含在官方 PEP(Python Enhancement Proposals) 链接为 [pep8][https://www.python.org/dev/peps/pep-0008/]\n简要版本   代码编排\n  缩进。4个空格的缩进（编辑器都可以完成此功能），不使用Tap，更不能混合使用Tap和空格。\n 针对不同编辑器兼容性，对 tab 可能有不同的标准，导致样式不统一。\n   每行最大长度79，换行可以使用反斜杠，最好使用圆括号。换行点要在操作符的后边敲回车。\n 早期 unix 主机终端只能显示 80 个字符。\n通过限制所需的编辑器窗口宽度，可以并排打开多个文件，并且在使用在相邻列中显示两个版本的代码查看工具时，效果很好。\n   类和top-level函数定义之间空两行；\n类中的方法定义之间空一行；\n函数内逻辑无关段落之间空一行；\n其他地方尽量不要再空行。\n    文档编排\n  模块内容的顺序：\n模块说明和docstring\nimport\nglobals\u0026constants\n其他定义。\n其中import部分，又按标准、三方和自己编写顺序依次排放，之间空一行。\n  不要在一句import中多个库，比如import os, sys不推荐。 如果采用from XX import XX引用库，可以省略‘module.’，都是可能出现命名冲突，这时就要采用import XX。\n如果有命名冲突。可以使用 from X import Y as Z\n  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  # -*- coding: utf-8 -*- #!/bin/python3 # ------------------------------------------------------------------------- # Author: Yuechuan Xiao # @Date: 2020-01-09 14:56:57 # @LastEditors: Yuechuan Xiao # @LastEditTime: 2020-03-30 16:33:48 # @Description: # report.py: gen build's jira issues html report. # ------------------------------------------------------------------------- \"\"\" Docstring reporter.py is used to generate a html report for specific build. \"\"\" # Standard library import os import re from collections import namedtuple # Third party lib # Import multi-subcass from A package. from jinja2 import ( Environment, FileSystemLoader, Template, select_autoescape) from jira import JIRA # If you have lcoal import  # from .utils import X # from . import utils     空格的使用 总体原则，避免不必要的空格。\n 各种右括号前不要加空格。 逗号、冒号、分号前不要加空格。 函数的左括号前不要加空格。如func(1)。 序列的左括号前不要加空格。如list[2]。 操作符左右各加一个空格，不要为了对齐增加空格。 函数默认参数使用的赋值符左右省略空格。 不要将多句语句写在同一行，尽管使用‘；’允许。 if/for/while语句中，即使执行语句只有一句，也必须另起一行。    命名规范 总体原则，新编代码必须按下面命名风格进行，现有库的编码尽量保持风格。\n 尽量单独使用小写字母l，大写字母O等容易混淆的字母。 模块命名尽量短小，使用全部小写的方式，可以使用下划线。 包命名尽量短小，使用全部小写的方式，不可以使用下划线。 类的命名使用CapWords的方式，模块内部使用的类采用_CapWords的方式。_ 异常命名使用CapWords+Error后缀的方式。 全局变量尽量只在模块内有效，类似C语言中的static。实现方法有两种，一是__all__机制;二是前缀一个下划线 函数命名使用全部小写的方式，可以使用下划线。 常量命名使用全部大写的方式，可以使用下划线。 类的属性（方法和变量）命名使用全部小写的方式，可以使用下划线。 类的属性有3种作用域public、non-public和subclass API，可以理解成C++中的public、private、protected，non-public属性前，前缀一条下划线。 类的属性若与关键字名字冲突，后缀一下划线，尽量不要使用缩略等其他方式。 为避免与子类属性命名冲突，在类的一些属性前，前缀两条下划线。比如：类Foo中声明__a,访问时，只能通过Foo._Foo__a，避免歧义。如果子类也叫Foo，那就无能为力了。 类的方法第一个参数必须是self，而静态方法第一个参数必须是cls。    注释 总体原则，错误的注释不如没有注释。所以当一段代码发生变化时，第一件事就是要修改注释！ 针对团队情况（是否国际化），注释倾向使用英文，最好是完整的句子，首字母大写，句后要有结束符，结束符后跟两个空格，开始下一句。如果是短语，可以省略结束符。\n 块注释，在一段代码前增加的注释。在‘#’后加一空格。段落之间以只有‘#’的行间隔。比如：  # Description : Module config. # # Input : None # # Output : None  行注释，在一句代码后加注释。比如：x = x + 1 # Increment x 但是这种方式尽量少使用。可以在 Magic Number 时使用。 避免无谓的注释。    文档描述 1 为所有的共有模块、函数、类、方法写docstrings；非共有的没有必要，但是可以写注释（在def的下一行）。 2 如果docstring要换行，参考如下例子,详见PEP 257\n1 2 3 4 5  \"\"\"Return a foobang Optional plotz says to frobnicate the bizbaz first. \"\"\"     编码建议\n  编码中考虑到其他python实现的效率等问题，比如运算符‘+’在CPython（Python）中效率很高，都是Jython中却非常低，所以应该采用.join()的方式。 2 尽可能使用i\n  s is not取代==，比如if x is not None 要优于if x。 3 使用基于类的异常，每个模块或包都有自己的异常类，此异常类继承自Exception。 4 异常中不要使用裸露的except，except后跟具体的exceptions。 5 异常中try的代码尽可能少。比如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  try: value = collection[key] except KeyError: return key_not_found(key) else: return handle_value(value) 要优于 try: # Too broad! return handle_value(collection[key]) except KeyError: # Will also catch KeyError raised by handle_value() return key_not_found(key)     使用startswith() and endswith()代替切片进行序列前缀或后缀的检查。比如\n1 2 3 4 5  Yes: if foo.startswith(‘bar’):优于 No: if foo[:3] == ‘bar’: - 使用isinstance()比较对象的类型。比如 Yes: if isinstance(obj, int): 优于 No: if type(obj) is type(1):     判断序列空或不空，有如下规则\n1 2 3 4 5  Yes: if not seq: if seq: 优于 No: if len(seq) if not len(seq)     字符串不要以空格收尾。\n  二进制数据判断使用 if boolvalue的方式。\n    Reference   [PEP8][https://www.python.org/dev/peps/pep-0008/]\n  Google Python 开源项目风格指南\n  ","description":"","tags":["python","codestyle"],"title":"Python 之代码规范","uri":"/blog/posts/python/python-codestyle/"},{"categories":["Web"],"content":" Django 项目本身可以通过 django-admin 或者直接运行 python manage.py ARGS 来进行脚手架生成。但是生成的项目框架层次不算太好。\n 首先生成一个 Django 项目：\n1  django-admin startproject backend   生成的项目框架如下：\n1 2 3 4 5 6 7 8  backend ├── backend │ ├── __init__.py │ ├── settings.py │ ├── urls.py │ └── wsgi.py └── manage.py   其中的两个 backend 分别表示项目，以及 app 全局配置\n建立文件夹 apps 用来放置应用，把内层 backend 改为 conf\n1 2 3 4 5 6 7 8  backend ├── apps ├── conf │ ├── __init__.py │ ├── settings.py │ ├── urls.py │ └── wsgi.py └── manage.py   注意这里需要配置以下几个文件：\n1 2 3 4 5  # manage.py  ... # os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'backend.settings') os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'conf.settings') ...   1 2 3 4 5 6 7 8  # settings.py ... # ROOT_URLCONF = 'backend.urls' ROOT_URLCONF = 'conf.urls' ... # WSGI_APPLICATION = 'backend.wsgi.application' WSGI_APPLICATION = 'conf.wsgi.application' ...   现在可以测试 python manage.py runserver 是否可以起来。\n接下来新建 Apps\n1 2  mkdir apps/login python manage.py startapp login apps/login   注册 app\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  # settings.py TEMPLATES = [ { 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'DIRS': ['apps'], # 添加 apps 文件夹 'APP_DIRS': True, 'OPTIONS': { 'context_processors': [ 'django.template.context_processors.debug', 'django.template.context_processors.request', 'django.contrib.auth.context_processors.auth', 'django.contrib.messages.context_processors.messages', ], }, }, ] INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'apps.login', ]   导入 URL\n1 2 3 4 5 6 7  ... from apps.login import urls as login_urls urlpatterns = [ path('admin/', admin.site.urls), path('login/', include(login_urls)), ]   现在一个基本的项目结构就建立好了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  backend ├── apps │ └── login │ ├── __init__.py │ ├── admin.py │ ├── apps.py │ ├── migrations │ │ └── __init__.py │ ├── models.py │ ├── tests.py │ └── views.py ├── conf │ ├── __init__.py │ ├── settings.py │ ├── urls.py │ └── wsgi.py ├── db.sqlite3 └── manage.py   相比起来层次更清晰，而且也更适合用作前后端分离的命名\n","description":"","tags":["web","django"],"title":"Django 项目后端模板","uri":"/blog/posts/web/django-project-backend-template/"},{"categories":null,"content":"理解递归的小故事 转载一篇对递归理解有帮助的小故事\n 对递归的理解的要点主要在于放弃!\n放弃你对于理解和跟踪递归全程的企图，只理解递归两层之间的交接，以及递归终结的条件。\n想象你来到某个热带丛林，意外发现了十层之高的汉诺塔。正当你苦苦思索如何搬动它时，林中出来一个土著，毛遂自荐要帮你搬塔。他名叫二傻，戴着一个草帽，草帽上有一个2字，号称会把一到二号盘搬到任意柱。\n你灵机一动，问道：“你该不会有个兄弟叫三傻吧？” “对对，老爷你咋知道的？他会搬一到三号盘。“ ”那你去把他叫来，我不需要你了。“ 于是三傻来了，他也带着个草帽，上面有个3字。\n你说：”三傻，你帮我把头三个盘子移到c柱吧。“ 三傻沉吟了一会，走进树林，你听见他大叫：”二傻，出来帮我把头两个盘子搬到C!“\n由于天气炎热你开始打瞌睡。朦胧中你没看见二傻是怎么工作的，二傻干完以后，走入林中大叫一声：“老三，我干完了!”\n三傻出来，把三号盘从A搬到B，然后又去叫二傻：“老二，帮我把头两个盘子搬回A!”\n余下的我就不多说了，总之三傻其实只搬三号盘，其他叫二傻出来干。最后一步是三傻把三号盘搬到C，然后呼叫二傻来把头两个盘子搬回C\n事情完了之后你把三傻叫来，对他说：“其实你不知道怎么具体一步一步把三个盘子搬到C，是吧？”\n三傻不解地说：“我不是把任务干完了？”\n你说：“可你其实叫你兄弟二傻干了大部分工作呀？”\n三傻说：“我外包给他和你屁相干？”\n你问到：“二傻是不是也外包给了谁？“\n三傻笑了：“这跟我有屁相干？”\n你苦苦思索了一夜，第二天，你走入林中大叫：“十傻，你在哪？”\n一个头上带着10号草帽的人，十傻，应声而出：“老爷，你有什么事？”\n“我要你帮把1到10号盘子搬到C柱“\n“好的，老爷。“十傻转身就向林内走。\n“慢着，你该不是回去叫你兄弟九傻吧“\n“老爷你怎么知道的？“\n“所以你使唤他把头九个盘子搬过来搬过去，你只要搬几次十号盘就好了，对吗？“\n“对呀！“\n“你知不知道他是怎么干的？“\n“这和我有屁相干？“\n你叹了一口气，决定放弃。十傻开始干活。树林里充满了此起彼伏的叫声：“九傻，来一下！“ “老八，到你了！““五傻！。。。“”三傻！。。。“”大傻！“\n你注意到大傻从不叫人，但是大傻的工作也最简单，他只是把一号盘搬来搬去。\n若干年后，工作结束了。十傻来到你面前。你问十傻：“是谁教给你们这么干活的？“\n十傻说：“我爸爸。他给我留了这张纸条。”\n他从口袋里掏出一张小纸条，上面写着：“照你帽子的号码搬盘子到目标柱。如果有盘子压住你，叫你上面一位哥哥把他搬走。如果有盘子占住你要去的柱子，叫你哥哥把它搬到不碍事的地方。等你的盘子搬到了目标，叫你哥哥把该压在你上面的盘子搬回到你上头。“\n你不解地问：“那大傻没有哥哥怎么办？“\n十傻笑了：“他只管一号盘，所以永远不会碰到那两个‘如果’，也没有盘子该压在一号上啊。”\n但这时他忽然变了颜色，好像泄漏了巨大的机密。他惊慌地看了你一眼，飞快地逃入树林。\n第二天，你到树林里去搜寻这十兄弟。他们已经不知去向。你找到了一个小屋，只容一个人居住，但是屋里有十顶草帽，写着一到十号的号码。\n作者：Fireman A 链接：https://www.zhihu.com/question/24385418/answer/257751077\n ","description":"","tags":["recursion"],"title":"理解递归的小故事","uri":"/blog/posts/a-story-to-understand-the-recursion/"},{"categories":["Python","Fluent-Python"],"content":" 字典这个数据结构活跃在所有 Python 程序的背后，即便你的源码里并没有直接用到它。\n——A. M. Kuchling\n dict 是 Python 语言的基石。\n可散列对象需要实现 __hash__ 和 __eq__ 函数。\n如果两个可散列对象是相等的，那么它们的散列值一定是一样的。\n范映射类型 collections.abc 模块中有 Mapping 和 MutableMapping 两个抽象基类，起作用是为 dict 和其他类似的类型定义形式接口。\n//pic\n但非抽象映射类型一般不会直接继承这些抽象基类，而是直接对 dict 或 collections.User.Dict 进行扩展。\n这些抽象基类的主要作用是作为形式化的文档，以及跟 isinstance 一起被用来判定某个数据是否为广义上的映射类型。\n1 2  my_dict = {} isinstance(my_dict, collections.abc.Mapping)   True   用 instance 而不是用 type 是用来避免参数可能不是 dict 而是其他的映射类型\n 标准库的所有映射类型都是利用 dict 实现。\n什么是可散列的数据类型？\n字典的提供了多种构造方法 link\n1 2 3 4 5 6 7  # 字典提供了很多种构造方法 a = dict(one=1, two=2, three=3) b = {'one': 1, 'two': 2, 'three': 3} c = dict(zip(['one', 'two', 'three'], [1, 2, 3])) d = dict([('two', 2), ('one', 1), ('three', 3)]) e = dict({'three': 3, 'one': 1, 'two': 2}) a == b == c == d == e   True  字典推导 字典推导（dictcomp）可以从任何以键值对为元素的可迭代对象构建出字典\n1 2 3 4 5 6 7 8  DIAL_CODES = [ (86, 'China'), (91, 'India'), (1, 'United States') ] country_code = {country: code for code, country in DIAL_CODES} country_code   {'China': 86, 'India': 91, 'United States': 1}  常见的映射方法 dict、defaultdict、OrderedDict 的常见方法，后两个数据类型是 dict 的变种，位于 collections 模块内。\n  setdefault 处理找不到的键\nd[k] 无法找到正确的键时，会抛出异常。\n用 d.get(k, default) 来代替 d[k], 可以对找不到的键设置默认返回值。\n  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  \"\"\" 03-dict-set/index0.py 创建一个从单词到其出现频率的映射 \"\"\" import sys import re WORD_RE = re.compile(r'\\w+') index = {} with open(sys.argv[1], encoding='uft-8') as fp: for line_no, line in enumerate(fp, 1): for match in WORD_RE.finditer(line): word = match.group() column_no = match.start() + 1 location = (line_no, column_no) # 提取单词出现情况，如果没有出现过返回 [] occurences = index.get(word, []) occurences.append(location) index[word] = occurences # 以字符顺序打印结果 for word in sorted(index, key=str.upper): print(word, index[word])   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  $ python index0.py zen.txt a [(19, 48), (20, 53)] Although [(11, 1), (16, 1), (18, 1)] ambiguity [(14, 16)] and [(15, 23)] are [(21, 12)] aren [(10, 15)] at [(16, 38)] bad [(19, 50)] be [(15, 14), (16, 27), (20, 50)] beats [(11, 23)] Beautiful [(3, 1)] better [(3, 14), (4, 13), (5, 11), (6, 12), (7, 9), (8, 11), (17, 8), (18, 25)] break [(10, 40)] by [(1, 20)] cases [(10, 9)] complex [(5, 23)] ...   使用 dict.setdefault\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  \"\"\" 03-dict-set/index.py 创建一个从单词到其出现频率的映射 \"\"\" import sys import re WORD_RE = re.compile(r'\\w+') index = {} with open(sys.argv[1], encoding='uft-8') as fp: for line_no, line in enumerate(fp, 1): for match in WORD_RE.finditer(line): word = match.group() column_no = match.start() + 1 location = (line_no, column_no) # 注意这行与上面的区别 index.setdefault(word, []).append(location) # 效果等同于： # if key not in my_dict: # my_dict[key] = [] # my_dict[key].append(new_value) # 以字符顺序打印结果 for word in sorted(index, key=str.upper): print(word, index[word])   映射的弹性键查询 某个键不存在时，希望读取时能得到一个默认值，有两个方式：\n 通过 defaultdict 类型 自定义 dict 子类  defaultdict 处理找不到的键 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  \"\"\" 03-dict-set/index_default.py 创建一个从单词到其出现频率的映射 \"\"\" import sys import re import collections WORD_RE = re.compile(r'\\w+') index = collections.defaultdict(list) with open(sys.argv[1], encoding='utf-8') as fp: for line_no, line in enumerate(fp, 1): for match in WORD_RE.finditer(line): word = match.group() column_no = match.start()+1 location = (line_no, column_no) # index 如何没有 word 的记录， default_factory 会被调用，这里是创建一个空列表返回 index[word].append(location) # print in alphabetical order for word in sorted(index, key=str.upper): print(word, index[word])   defaultdict 里的 default_factory 只在 getitem 里调用。 实际上，上面的机制是通过特殊方法 missing 支持的。\nmissing 如果 dict 继承类提供了 missing 方法，且 getitem 遇到找不到键的情况是会自动调用它，而不是抛出异常\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42  class StrKeyDict0(dict): # \u003c1\u003e def __missing__(self, key): if isinstance(key, str): # \u003c2\u003e raise KeyError(key) return self[str(key)] # \u003c3\u003e def get(self, key, default=None): try: return self[key] # \u003c4\u003e except KeyError: return default # \u003c5\u003e def __contains__(self, key): return key in self.keys() or str(key) in self.keys() # \u003c6\u003e d = StrKeyDict0([('2', 'Two'), ('4', 'Four')]) print(d['2']) print(d['4']) # d[1] error print(d.get('2')) print(d.get('4')) print(d.get(1, 'N/A')) # defaultdcit \u0026 __missing__ class mydefaultdict(dict): def __init__(self, value, value_factory): super().__init__(value) self._value_factory = value_factory def __missing__(self, key): # 要避免循环调用 # return self[key] self[key] = self._value_factory() return self[key] d = mydefaultdict({1:1}, list) print(d[1]) print(d[2]) d[3].append(1) print(d)   Two Four Two Four 'N/A'  字典的变种  此节总结了标准库 collections 模块中，除了 defaultdict 之外的不同映射类型\n   collections.OrderedDict\n  collections.ChainMap\n容纳多个不同的映射对象，然后在进行键查找操作时会从前到后逐一查找，直到被找到为止\n  collections.Counter\n  collections.UserDict\ndict 的纯 Python 实现，让用户集成写子类的\n  1 2 3 4 5 6 7 8 9 10 11  # UserDict # 定制化字典时，尽量继承 UserDict 而不是 dict from collections import UserDict class mydict(UserDict): def __getitem__(self, key): print('Getting key', key) return super().__getitem__(key) d = mydict({1:1}) print(d[1], d[2])   1 2 3 4 5 6 7 8 9 10 11 12 13  # MyppingProxyType 用于构建 Mapping 的只读实例 from types import MappingProxyType d = {1: 1} d_proxy = MappingProxyType(d) print(d_proxy[1]) try: d_proxy[1] = 1 except Exception as e: print(repr(e)) d[1] = 2 print(d_proxy[1])   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  # set 的操作 # 子集 \u0026 真子集 a, b = {1, 2}, {1, 2} print(a \u003c= b, a \u003c b) # discard a = {1, 2, 3} a.discard(3) print(a) # pop print(a.pop(), a.pop()) try: a.pop() except Exception as e: print(repr(e))   集合字面量 除空集之外，集合的字面量——{1}、{1, 2}，等等——看起来跟它的数学形式一模一样。如果是空集，那么必须写成 set() 的形式，否则它会变成一个 dict.\n跟 list 一样，字面量句法会比 set 构造方法要更快且更易读。\n集合和字典的实现 集合和字典采用散列表来实现：\n 先计算 key 的 hash, 根据 hash 的某几位（取决于散列表的大小）找到元素后，将该元素与 key 进行比较 若两元素相等，则命中 若两元素不等，则发生散列冲突，使用线性探测再散列法进行下一次查询。  这样导致的后果：\n 可散列对象必须支持 hash 函数； 必须支持 __eq__ 判断相等性； 若 a == b, 则必须有 hash(a) == hash(b)。  注：所有由用户自定义的对象都是可散列的，因为他们的散列值由 id() 来获取，而且它们都是不相等的。\n字典的空间开销 由于字典使用散列表实现，所以字典的空间效率低下。使用 tuple 代替 dict 可以有效降低空间消费。\n不过：内存太便宜了，不到万不得已也不要开始考虑这种优化方式，因为优化往往是可维护性的对立面。\n往字典中添加键时，如果有散列表扩张的情况发生，则已有键的顺序也会发生改变。所以，不应该在迭代字典的过程各种对字典进行更改。\n1 2 3 4 5 6 7 8 9 10 11 12  # 字典中就键的顺序取决于添加顺序 keys = [1, 2, 3] dict_ = {} for key in keys: dict_[key] = None for key, dict_key in zip(keys, dict_): print(key, dict_key) assert key == dict_key # 字典中键的顺序不会影响字典比较   ","description":"","tags":["python"],"title":"《流畅的Python》 字典和集合","uri":"/blog/posts/python/fluent-python/fluent-python-dict-and-collections/"},{"categories":["Python","Fluent-Python"],"content":" 你可能注意到了，之前提到的几个操作可以无差别地应用于文本、列表和表格上。\n我们把文本、列表和表格叫作数据火车……FOR 命令通常能作用于数据火车上。\n——Geurts、Meertens 和 Pemberton\nABC Programmer’s Handbook\n 内置序列类型概览  容器序列\nlist、tuple 和 collections.deque 这些序列能存放不同类型的数据。 扁平序列\nstr、bytes、bytearray、memoryview 和 array.array，这类序列只能容纳一种类型。  容器序列存放的是它们所包含的任意类型的对象的引用，而扁平序列里存放的是值而不是引用。换句话说，扁平序列其实是一段连续的内存空间。由此可见扁平序列其实更加紧凑，但是它里面只能存放诸如字符、字节和数值这种基础类型。\n序列类型还能按照能否被修改来分类。\n 可变序列\nlist、bytearray、array.array、collections.deque 和 memoryview。 不可变序列\ntuple、str 和 bytes  列表推导和生成器表达式 列表推导和可读性 列表推导是构建列表(list)的快捷方式，生成器表达式用来穿件其他任何类型的序列。\n1 2 3 4 5 6 7 8 9 10  # 比较两段代码 symbols = 'abcde' # 1 codes = [] for symbol in symbols: codes.append(ord(symbol)) print(codes) # 2 codes = [ord(symbol) for symbol in symbols] print(codes)   列表推导能够提升可读性。 只用列表推导来创建新的列表，并尽量保持简短（不要超过一行）\n列表推导同 filter 和 map 的比较 1 2 3 4 5 6 7  symbols = 'abcde' beyond_ascii = [ord(s) for s in symbols if ord(s) \u003e 100] print(beyond_ascii) beyond_ascii = list(filter(lambda c: c \u003e 100, map(ord, symbols))) print(beyond_ascii)   [101] [101]  笛卡尔积 1 2 3 4 5 6 7 8 9 10 11  colors = ['black', 'white'] sizes = ['S', 'M', 'L'] tshirts = [(color, size) for color in colors for size in sizes] print(tshirts) tshirts = [(color, size) for size in sizes for color in colors] print(tshirts) # 注意顺序是依照 for-loop   [('black', 'S'), ('black', 'M'), ('black', 'L'), ('white', 'S'), ('white', 'M'), ('white', 'L')] [('black', 'S'), ('white', 'S'), ('black', 'M'), ('white', 'M'), ('black', 'L'), ('white', 'L')]  生成器表达式 列表推导与生成器表达式的区别：\n 生成器表达式遵守实现了迭代器接口，可以逐个地产出元素。列表推导是先建立一个完整的列表，再将这个列表传递到构造函数里。 语法上近似，方括号换成圆括号  1 2 3 4 5  # symbols = 'abcde' print(tuple(ord(symbol) for symbol in symbols)) import array print(array.array('I', (ord(symbol) for symbol in symbols)))    如果生成器表达式是一个函数调用过程中的唯一参数，则不需要额外括号 生成器会在 for-loop 运行时才生成一个组合。逐个产出元素  1 2 3 4 5  colors = ['black', 'white'] sizes = ['S', 'M', 'L'] for tshirt in ('%s%s' %(c, s) for c in colors for s in sizes): print(tshirt)   black S black M black L white S white M white L  元祖不仅仅是不可变的列表 元祖与记录  元祖是对数据的记录 元祖的位置信息为数据赋予了意义。对元祖内元素排序，位置信息将丢失  1 2 3 4 5 6 7 8 9 10 11 12 13  # LA 国际机场经纬度 lax_coordinates = (33.9425, -118.408056) # 城市，年份，人口（单位：百万），人口变化（单位：百分比），面积 city, year, pop, chg, area = ('Tokyo', 2003, 32450, 0.66, 8014) # country_code, passport number traveler_ids = [('USA', '31195855'), ('BBA', 'CE342567'), ('ESP', 'XDA205856')] for passport in sorted(traveler_ids): print('%s%s' % passport) # 拆包（unpacking） for country, _ in traveler_ids: print(country)   BBACE342567 ESPXDA205856 USA31195855 USA BBA ESP  元祖拆包  平行赋值  1 2 3 4 5  lax_coordinates = (33.9425, -118.408056) # 元祖拆包 latitude, longtitude = lax_coordinates print(latitude) print(longtitude)   33.9425 -118.408056   交换变量值，不使用中间变量  1 2 3 4 5  a = 3 b = 4 b, a = a, b print(a) print(b)   4 3   * 运算符，把一个可迭代对象拆开作为函数参数  1 2 3 4 5 6 7 8  divmod(20, 8) t = (20, 8) divmod(*t) quotient, remainder = divmod(*t) print(quotient) print(remainder)   2 4   函数用元祖形式返回多个值   _ 用作占位符，可以用来处理不需要的数据\n 1 2 3 4  import os _, filename = os.path.split('/home/xiao/.ssh/id_rsa.pub') print(filename)   id_rsa.pub   用* 处理省下的元素  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  a, b, *rest = range(5) print(a, b, rest) a, b, *rest = range(3) print(a, b, rest) a, b, *rest = range(2) print(a, b, rest) # * 前缀只能用在一个变量前，该变量可出现在赋值表达式中任意位置 a, *body, c, d = range(5) print(a, body, c, d) *head, b, c, d = range(5) print(head, b, c, d)   0 1 [2, 3, 4] 0 1 [2] 0 1 [] 0 [1, 2] 3 4 [0, 1] 2 3 4  嵌套元祖拆包 1 2 3 4 5 6 7 8 9 10 11 12 13  metro_areas = [ ('Tokyo', 'JP', 36.933, (35.689722, 139.691667)), # \u003c1\u003e ('Delhi NCR', 'IN', 21.935, (28.613889, 77.208889)), ('Mexico City', 'MX', 20.142, (19.433333, -99.133333)), ('New York-Newark', 'US', 20.104, (40.808611, -74.020386)), ('Sao Paulo', 'BR', 19.649, (-23.547778, -46.635833)), ] print('{:15} | {:^9} | {:^9}'.format('', 'lat.', 'long.')) fmt = '{:15} | {:9.4f} | {:9.4f}' for name, cc, pop, (latitude, longitude) in metro_areas: # \u003c2\u003e if longitude \u003c= 0: # \u003c3\u003e print(fmt.format(name, latitude, longitude))    | lat. | long. Mexico City | 19.4333 | -99.1333 New York-Newark | 40.8086 | -74.0204 Sao Paulo | -23.5478 | -46.6358  将元祖作为记录仍缺少一个功能：字段命名\n具名元祖(numedtuple) collections.namedtuple 是一个工厂函数，用来构建带字段名的元祖和一个有名字的\n namedtuple 构建的类的实例所消耗的内存和元祖是一样的，因为字段名都存在对应的类里。 实例和普通的对象实例小一点，因为 Python 不会用 __dict__ 存放实例的属性\n 1 2 3 4 5 6 7 8  from collections import namedtuple # 需要两个参数，类名和类各个字段的名字 City = namedtuple('City', 'name country population coordinates') tokyo = City('Tokyo', 'JP', 36.933, (35.689722, 129.691667)) print(tokyo) print(tokyo.population) print(tokyo.coordinates)   City(name='Tokyo', country='JP', population=36.933, coordinates=(35.689722, 129.691667)) 36.933 (35.689722, 129.691667)  namedtuple 除了从普通元祖继承的属性外，还有一些专有属性。 常用的有：\n _fields 类属性 _make(iterable) 类方法 _asdict() 实例方法  1 2 3 4 5 6 7 8  print(City._fields) LatLong = namedtuple('LatLong', 'lat long') delhi_data = ('Delhi NCR', 'IN', 21.935, LatLong(28.613889, 77.208889)) delhi = City._make(delhi_data) print(delhi._asdict()) for key, value in delhi._asdict().items(): print(key + ':', value)   ('name', 'country', 'population', 'coordinates') OrderedDict([('name', 'Delhi NCR'), ('country', 'IN'), ('population', 21.935), ('coordinates', LatLong(lat=28.613889, long=77.208889))]) name: Delhi NCR country: IN population: 21.935 coordinates: LatLong(lat=28.613889, long=77.208889)  作为不可变列表的元祖 对比列表和元祖的方法 // 插入表格\n结论：\n 除了增减元素相关的方法和__reversed__ 外，元祖支持列表的其他所有方法。  切片 在 Python 里, 列表（list），元祖（tuple）和字符串（str）这类序列类型都支持切片操作\n为什么切片的区间会忽略最后一个元素  Python 以0 作为起始下标 当只有后一个位置信息时，可以快速导出切片和区间的元素数量 当起止位置信息课件是，可以快速计算出切片和区间的长度 （stop - start） 可利用任意一个下标把序列分割成不重叠的两部分。my_list[:x] my_list[x:]  1 2 3  ### 对对象进行切片 - 可以通过 s[a🅱️c] 的形式对 s 在 a 和 b 区间以 c 为间隔取值   1 2 3 4  s = 'bicycle' print(s[::3]) print(s[::-1]) print(s[::-2])   bye elcycib eccb  多维切片和省略 [] 运算符可以使用以逗号分开的多个索引或切片。\n如 a[i, j]，a[m:n, k:1]得到二维切片\n要正确处理[] 运算符，对象的特殊方法 __getitem__，__setitem__ 需要以元祖的形式来接受 a[i, j]的索引。\n给切片赋值 切片放在赋值语句左边，或作为 del 操作对象，可以对序列进行嫁接、切除或就地修改\n1 2 3 4 5 6 7 8 9 10 11 12 13  l = list(range(10)) print(l) l[2:5] = [20, 30] print(l) del l[5:7] print(l) l[3::2] = [11, 22] print(l) # l[2:5] = 100 WRONG   [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [0, 1, 20, 30, 5, 6, 7, 8, 9] [0, 1, 20, 30, 5, 8, 9] [0, 1, 20, 11, 5, 22, 9]  对序列使用 + 和 *  + 和 * 不修改原有的操作对象，而是构建一个新的序列  1 2 3 4  l = [1, 2, 3] print(l * 5) print(5 * 'abcd')   [1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3] abcdabcdabcdabcdabcd  建立由列表组成的列表  a * n，如果在序列 a 中存在对其他可变变量的引用的话，得到的序列中包含的是 n 个对指向同一地址的引用\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  board = [['_'] * 3 for i in range(3)] # 换一种形式 # board = [] # for i in range(3): # row = ['_'] * 3 # board.append(row) print(board) board[1][2] = 'X' print(board) # weird_board = [['_'] * 3] * 3 # 换一种形式 weird_board = [] row = ['_'] * 3 for i in range(3): weird_board.append(row) weird_board[1][2] = 'O' # 会发现 3 个指向同一列表的引用 print(weird_board)   [['_', '_', '_'], ['_', '_', '_'], ['_', '_', '_']] [['_', '_', '_'], ['_', '_', 'X'], ['_', '_', '_']] [['_', '_', 'O'], ['_', '_', 'O'], ['_', '_', 'O']]  序列的增量赋值 +=、*=  += 背后的特殊方法是 __iadd__ 方法，没有则退一步调用 __add__ 同理 *= 的特殊方法是 __imul__  1 2 3 4 5 6 7 8 9 10 11 12 13 14  l = [1, 2, 3] print(id(l)) l *= 2 print(l) # 列表ID 无改变 print(id(l)) t = (1, 2, 3) print(id(t)) t *= 2 print(t) # 新元祖被创建 print(id(t))   4534358344 [1, 2, 3, 1, 2, 3] 4534358344 4536971408 (1, 2, 3, 1, 2, 3) 4546754024  list.sort方法和内置函数sorted  list.sort 会就地排序列表，方法返回值为 None sorted 会新建一个列表作为返回值 两个方法都有 reverse 和 key 作为可选的关键字参数 reserve 为 True 时，降序输出。默认为 false key 只有一个参数的函数，将被用在序列的每一个元素上，其结果作为排序算法依赖的对比关键字  用bisect管理已排序的序列 bisect 模块有两个主要函数：\n bisect insort 都利用二分查找法来在有序序列中查找或插入人元素  用 bisect 来搜索 bisect(haystack, needle) 默认为升序，haystack 需要保持有序。 使用方法： bisect(index, needle) 查找位置 index，再使用 haystack.insert(index, needle) 插入新值\n也可以用 insort 来一步到位，且后者速度更快\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  # BEGIN BISECT_DEMO import bisect import sys HAYSTACK = [1, 4, 5, 6, 8, 12, 15, 20, 21, 23, 23, 26, 29, 30] NEEDLES = [0, 1, 2, 5, 8, 10, 22, 23, 29, 30, 31] ROW_FMT = '{0:2d} @ {1:2d} {2}{0:\u003c2d}' def demo(bisect_fn): for needle in reversed(NEEDLES): position = bisect_fn(HAYSTACK, needle) # \u003c1\u003e offset = position * ' |' # \u003c2\u003e print(ROW_FMT.format(needle, position, offset)) # \u003c3\u003e if __name__ == '__main__': if sys.argv[-1] == 'left': # \u003c4\u003e bisect_fn = bisect.bisect_left else: bisect_fn = bisect.bisect print('DEMO:', bisect_fn.__name__) # \u003c5\u003e print('haystack -\u003e', ' '.join('%2d' % n for n in HAYSTACK)) demo(bisect_fn) # END BISECT_DEMO   DEMO: bisect_right haystack -\u003e 1 4 5 6 8 12 15 20 21 23 23 26 29 30 31 @ 14 | | | | | | | | | | | | | |31 30 @ 14 | | | | | | | | | | | | | |30 29 @ 13 | | | | | | | | | | | | |29 23 @ 11 | | | | | | | | | | |23 22 @ 9 | | | | | | | | |22 10 @ 5 | | | | |10 8 @ 5 | | | | |8 5 @ 3 | | |5 2 @ 1 |2 1 @ 1 |1 0 @ 0 0  Array  虽然列表既灵活又简单，但面对各类需求时，我们可能会有更好的选择。比如，要存放 1000 万个浮点数的话，数组（array）的效率要高得多，因为数组在背后存的并不是 float 对象，而是数字的机器翻译，也就是字节表述。这一点就跟 C 语言中的数组一样。再比如说，如果需要频繁对序列做先进先出的操作，deque（双端队列）的速度应该会更快。\n array.tofile 和 fromfile 可以将数组以二进制格式写入文件，速度要比写入文本文件快很多，文件的体积也小。\n 另外一个快速序列化数字类型的方法是使用 pickle（https://docs.python.org/3/library/pickle.html）模块。pickle.dump 处理浮点数组的速度几乎跟array.tofile 一样快。不过前者可以处理几乎所有的内置数字类型，包含复数、嵌套集合，甚至用户自定义的类。前提是这些类没有什么特别复杂的实现。\n array 具有 type code 来表示数组类型：具体可见 array 文档.\nmemoryview  memoryview.cast 的概念跟数组模块类似，能用不同的方式读写同一块内存数据，而且内容字节不会随意移动。\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  import array arr = array.array('h', [1, 2, 3]) memv_arr = memoryview(arr) # 把 signed short 的内存使用 char 来呈现 memv_char = memv_arr.cast('B') print('Short', memv_arr.tolist()) print('Char', memv_char.tolist()) memv_char[1] = 2 # 更改 array 第一个数的高位字节 # 0x1000000001 print(memv_arr.tolist(), arr) print('-' * 10) bytestr = b'123' # bytes 是不允许更改的 try: bytestr[1] = '3' except TypeError as e: print(repr(e)) memv_byte = memoryview(bytestr) print('Memv_byte', memv_byte.tolist()) # 同样这块内存也是只读的 try: memv_byte[1] = 1 except TypeError as e: print(repr(e))   Deque collections.deque 是比 list 效率更高，且线程安全的双向队列实现。\n除了 collections 以外，以下 Python 标准库也有对队列的实现：\n queue.Queue (可用于线程间通信) multiprocessing.Queue (可用于进程间通信) asyncio.Queue heapq  ","description":"","tags":["python"],"title":"《流畅的Python》 序列构成的数组","uri":"/blog/posts/python/fluent-python/fluent-python-array-of-sequences/"},{"categories":null,"content":"Markdown 语法总结 斜体和粗体 1 2 3 4  *斜体*或_斜体_ **粗体** ***加粗斜体*** ~~删除线~~   斜体或_斜体_\n粗体\n加粗斜体\n删除线\n 分级标题 1 2 3 4 5 6  # 一级标题 ## 二级标题 ###三级标题 ### 四级标题 #### 五级标题 ##### 六级标题   一级标题字号最大，依级递减。\n 超链接 Markdown 支持两种形式的链接语法： 行内式和参考式两种形式，行内式一般使用较多。\n行内式 语法说明：[文字](链接)\n[]里写链接文字，()里写链接地址, ()中的“”中可以为链接指定title属性，title属性可加可不加。title属性的效果是鼠标悬停在链接上会出现指定的 title文字。链接地址与链接标题前有一个空格。\n1 2 3  欢迎来到[Django](https://docs.djangoproject.com/zh-hans/3.0/) 欢迎来到[Django](https://docs.djangoproject.com/zh-hans/3.0/ “Django”)   欢迎来到Django\n欢迎来到Django\n参考式 参考式超链接一般用在学术论文上面，或者另一种情况，如果某一个链接在文章中多处使用，那么使用引用 的方式创建链接将非常好，它可以让你对链接进行统一的管理。\n语法说明： [文字][链接文字] 参考式链接分为两部分，文中的写法 [链接文字][链接标记]，在文本的任意位置添加[链接标记]:链接地址 “链接标题”，链接地址与链接标题前有一个空格。\n如果链接文字本身可以做为链接标记，你也可以写成[链接文字][] [链接文字]：链接地址的形式，见代码的最后一行。\n1 2 3 4 5  我经常去的几个网站[Google][1],[技术博客1][2],[技术博客2][]。 [1]:http://www.google.com [2]:https://yuechuanx.top \"技术博客\" [技术博客]:https://yuechuanx.top/   我经常去的几个网站Google,Demi的随笔和技术空间,[Demi的随笔和技术空间][]。\n我经常去的几个网站Google,技术博客1,[技术博客2][]。\n自动链接 语法说明： Markdown 支持以比较简短的自动链接形式来处理网址和电子邮件信箱，只要是用\u003c\u003e包起来， Markdown 就会自动把它转成链接。一般网址的链接文字就和链接地址一样，例如：\n1 2  \u003chttp://example.com/\u003e \u003caddress@example.com\u003e   http://example.com/ address@example.com\n 锚点 网页中，锚点其实就是页内超链接，也就是链接本文档内部的某些元素，实现当前页面中的跳转。比如我这里写下一个锚点，点击回到目录，就能跳转到目录。 在目录中点击这一节，就能跳过来。还有下一节的注脚。这些根本上都是用锚点来实现的。\n注意：\n Markdown Extra 只支持在标题后插入锚点，其它地方无效。 Leanote 编辑器右侧显示效果区域暂时不支持锚点跳转，所以点来点去发现没有跳转不必惊慌，但是你发布成笔记或博文后是支持跳转的。  1 2 3  ## 跳转测试{#index}  跳转到[跳转测试](#index)    列表 无序列表 使用 *，+，- 表示无序列表。\n1 2 3  - 无序列表项 一 - 无序列表项 二 - 无序列表项 三    无序列表项 一 无序列表项 二 无序列表项 三  有序列表 有序列表则使用数字接着一个英文句点。\n1 2 3  1. 有序列表项 一 2. 有序列表项 二 3. 有序列表项 三    有序列表项 一 有序列表项 二 有序列表项 三  定义型列表 语法说明：\n定义型列表由名词和解释组成。一行写上定义，紧跟一行写上解释。解释的写法:紧跟一个缩进(Tab)\n1 2 3 4 5 6 7  代码块 1 Markdown : 轻量级文本标记语言，可以转换成html，pdf等格式（左侧有一个可见的冒号和四个不可见的空格） 代码块 2 : 这是代码块的定义（左侧有一个可见的冒号和四个不可见的空格） 代码块（左侧有八个不可见的空格）   view\n 代码块 1 Markdown 轻量级文本标记语言，可以转换成html，pdf等格式（左侧有一个可见的冒号和四个不可见的空格） 代码块 2 这是代码块的定义（左侧有一个可见的冒号和四个不可见的空格） 代码块（左侧有八个不可见的空格）    列表缩进 语法说明：\n列表项目标记通常是放在最左边，但是其实也可以缩进，最多 3 个空格，项目标记后面则一定要接着至少一个空格或制表符。\n1 2 3 4 5 6 7  * 轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。 那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。 软泥上的青荇， 油油的在水底招摇； 在康河的柔波里， 我甘心做一条水草！ * 那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。 寻梦？撑一支长篙， 向青草更青处漫溯； 满载一船星辉， 在星辉斑斓里放歌。 但我不能放歌， 悄悄是别离的笙箫； 夏虫也为我沉默， 沉默是今晚的康桥！ 悄悄的我走了， 正如我悄悄的来； 我挥一挥衣袖， 不带走一片云彩。   view\n 轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。 那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。 软泥上的青荇， 油油的在水底招摇； 在康河的柔波里， 我甘心做一条水草！ 那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。 寻梦？撑一支长篙， 向青草更青处漫溯； 满载一船星辉， 在星辉斑斓里放歌。 但我不能放歌， 悄悄是别离的笙箫； 夏虫也为我沉默， 沉默是今晚的康桥！ 悄悄的我走了， 正如我悄悄的来； 我挥一挥衣袖， 不带走一片云彩。  包含段落的列表 语法说明：\n列表项目可以包含多个段落，每个项目下的段落都必须缩进 4 个空格或是 1 个制表符（显示效果与代码一致）：\n1 2 3 4 5 6 7 8 9  * 轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。 那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。 软泥上的青荇， 油油的在水底招摇； 在康河的柔波里， 我甘心做一条水草！ 那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。 寻梦？撑一支长篙， 向青草更青处漫溯； 满载一船星辉， 在星辉斑斓里放歌。 但我不能放歌， 悄悄是别离的笙箫； 夏虫也为我沉默， 沉默是今晚的康桥！ * 悄悄的我走了， 正如我悄悄的来； 我挥一挥衣袖， 不带走一片云彩。   view\n  轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。 那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。 软泥上的青荇， 油油的在水底招摇； 在康河的柔波里， 我甘心做一条水草！\n那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。 寻梦？撑一支长篙， 向青草更青处漫溯； 满载一船星辉， 在星辉斑斓里放歌。 但我不能放歌， 悄悄是别离的笙箫； 夏虫也为我沉默， 沉默是今晚的康桥！\n  悄悄的我走了， 正如我悄悄的来； 我挥一挥衣袖， 不带走一片云彩。\n  包含引用的列表 语法说明：\n如果要在列表项目内放进引用，那 \u003e 就需要缩进：\n1 2 3  * 阅读的方法: \u003e 打开书本。 \u003e 打开电灯。   view\n 阅读的方法:  打开书本。 打开电灯。\n   包含代码区块的引用 语法说明： 如果要放代码区块的话，该区块就需要缩进两次，也就是 8 个空格或是 2 个制表符：\n一个特殊情况 在特殊情况下，项目列表很可能会不小心产生，像是下面这样的写法：\n1  1986. What a great season.   会显示成：\nWhat a great season.  换句话说，也就是在行首出现数字-句点-空白，要避免这样的状况，你可以在句点前面加上反斜杠：\n1  1986\\. What a great season.   才会正常显示成：\n1986. What a great season.\n 引用 语法说明： 引用需要在被引用的文本前加上\u003e符号。\n1 2 3 4 5 6  \u003e 这是一个有两段文字的引用, 无意义的占行文字1. 无意义的占行文字2. \u003e 无意义的占行文字3. 无意义的占行文字4.   view\n 这是一个有两段文字的引用, 无意义的占行文字1. 无意义的占行文字2.\n  无意义的占行文字3. 无意义的占行文字4.\n 引用的多层嵌套 区块引用可以嵌套（例如：引用内的引用），只要根据层次加上不同数量的 \u003e ：\n1 2 3 4 5  \u003e\u003e\u003e 请问 Markdwon 怎么用？ - 小白 \u003e\u003e 自己看教程！ - 愤青 \u003e 教程在哪？ - 小白      请问 Markdwon 怎么用？ - 小白\n     自己看教程！ - 愤青\n   教程在哪？ - 小白\n 引用其它要素 引用的区块内也可以使用其他的 Markdown 语法，包括标题、列表、代码区块等：\n1 2 3 4 5 6  \u003e 1. 这是第一行列表项。 \u003e 2. 这是第二行列表项。 \u003e \u003e 给出一些例子代码： \u003e \u003e return shell_exec(\"echo $input | $markdown_script\");     这是第一行列表项。 这是第二行列表项。  给出一些例子代码：\nreturn shell_exec(\"echo $input | $markdown_script\");    插入图像 图片的创建方式与超链接相似，而且和超链接一样也有两种写法，行内式和参考式写法。\n语法中图片Alt的意思是如果图片因为某些原因不能显示，就用定义的图片Alt文字来代替图片。 图片Title则和链接中的Title一样，表示鼠标悬停与图片上时出现的文字。 Alt 和 Title 都不是必须的，可以省略，但建议写上。\n行内式 语法说明：![图片Alt](图片地址 “图片Title”)\n1 2  美丽风景： ![美丽风景](https://yuhongjun.github.io/assets/media/scenery.jpeg \"美丽风景\")   view 美丽风景： 参考式\u0010 语法说明：\n在文档要插入图片的地方写![图片Alt][标记]\n在文档的最后写上[标记]:图片地址 “Title”\n1 2 3  ![美丽风景](https://yuhongjun.github.io/assets/media/scenery.jpeg \"美丽风景\") [scenery]:https://yuhongjun.github.io/assets/media/scenery.jpeg \"美丽风景\"   view  内容目录 在段落中填写 {toc} 以显示全文内容的目录结构。\n效果参见最上方的目录\n 注脚 语法说明：\n在需要添加注脚的文字后加上脚注名字[^注脚名字],称为加注。 然后在文本的任意位置(一般在最后)添加脚注，脚注前必须有对应的脚注名字。\n注意：经测试注脚与注脚之间必须空一行，不然会失效。成功后会发现，即使你没有把注脚写在文末，经Markdown转换后，也会自动归类到文章的最后。\n1 2 3 4 5 6 7  使用 Markdown[^1]可以效率的书写文档, 直接转换成 HTML[^2], 你可以使用 Leanote[^Le] 编辑器进行书写。 [^1]:Markdown是一种纯文本标记语言 [^2]:HyperText Markup Language 超文本标记语言 [^Le]:开源笔记平台，支持Markdown和笔记直接发为博文   view\n使用 Markdown1可以效率的书写文档, 直接转换成 HTML2, 你可以使用 Leanote3 编辑器进行书写。\n注：脚注自动被搬运到最后面，请到文章末尾查看，并且脚注后方的链接可以直接跳转回到加注的地方。\n LaTeX 公式 $ 表示行内公式： 1  质能守恒方程可以用一个很简洁的方程式 $E=mc^2$ 来表达。   view 质能守恒方程可以用一个很简洁的方程式 $E=mc^2$ 来表达。\n$$ 表示整行公式： 1 2 3  $$\\sum_{i=1}^n a_i=0$$ $$f(x_1,x_x,\\ldots,x_n) = x_1^2 + x_2^2 + \\cdots + x_n^2 $$ $$\\sum^{j-1}_{k=0}{\\widehat{\\gamma}_{kj} z_k}$$   $$\\sum_{i=1}^n a_i=0$$ $$f(x_1,x_x,\\ldots,x_n) = x_1^2 + x_2^2 + \\cdots + x_n^2 $$ $$\\sum^{j-1}_{k=0}{\\widehat{\\gamma}_{kj} z_k}$$\n访问 MathJax 参考更多使用方法。\n 流程图 1 2 3 4 5 6 7 8 9 10 11 12 13 14  st=\u003estart: Start|past:\u003ehttps://yuhongjun.github.io[blank] e=\u003eend: End:\u003ehttps://yuhongjun.github.io op1=\u003eoperation: My Operation|past op2=\u003eoperation: Stuff|current sub1=\u003esubroutine: My Subroutine|invalid cond=\u003econdition: Yes or No?|approved:\u003ehttps://yuhongjun.github.io c2=\u003econdition: Good idea|rejected io=\u003einputoutput: catch something...|request st-\u003eop1(right)-\u003econd cond(yes, right)-\u003ec2 cond(no)-\u003esub1(left)-\u003eop1 c2(yes)-\u003eio-\u003ee c2(no)-\u003eop2-\u003ee   st=\u003estart: Start|past:\u003ehttps://yuhongjun.github.io[blank] e=\u003eend: End:\u003ehttps://yuhongjun.github.io op1=\u003eoperation: My Operation|past op2=\u003eoperation: Stuff|current sub1=\u003esubroutine: My Subroutine|invalid cond=\u003econdition: Yes or No?|approved:\u003ehttps://yuhongjun.github.io c2=\u003econdition: Good idea|rejected io=\u003einputoutput: catch something...|request st-\u003eop1(right)-\u003econd cond(yes, right)-\u003ec2 cond(no)-\u003esub1(left)-\u003eop1 c2(yes)-\u003eio-\u003ee c2(no)-\u003eop2-\u003ee 更多语法参考：流程图语法参考\n 表格 语法说明：\n不管是哪种方式，第一行为表头，第二行分隔表头和主体部分，第三行开始每一行为一个表格行。 列于列之间用管道符|隔开。原生方式的表格每一行的两边也要有管道符。 第二行还可以为不同的列指定对齐方向。默认为左对齐，在-右边加上:就右对齐。\n 简单方式写表格：  1 2 3 4 5  学号|姓名|分数 -|-|- 小明|男|75 小红|女|79 小陆|男|92   2.原生方式写表格：\n1 2 3 4 5  |学号|姓名|分数| |-|-|-| |小明|男|75| |小红|女|79| |小陆|男|92|   3.为表格第二列指定方向：\n1 2 3 4  产品|价格 -|-: Leanote 高级账号|60元/年 Leanote 超级账号|120元/年   view\n 简单方式写表格：     学号 姓名 分数     小明 男 75   小红 女 79   小陆 男 92    2.原生方式写表格：\n   学号 姓名 分数     小明 男 75   小红 女 79   小陆 男 92    3.为表格第二列指定方向：\n   产品 价格     Leanote 高级账号 60元/年   Leanote 超级账号 120元/年    分隔线 你可以在一行中用三个以上的星号、减号、底线来建立一个分隔线，行内不能有其他东西。你也可以在星号或是减号中间插入空格。下面每种写法都可以建立分隔线：\n1 2 3 4 5 6 7 8 9  * * * *** ***** - - - ---------------------------------------   显示效果都一样\n 代码 对于程序员来说这个功能是必不可少的，插入程序代码的方式有两种，一种是利用缩进(Tab), 另一种是利用 ` 符号（一般在ESC键下方）包裹代码。\n语法说明：\n 插入行内代码，即插入一个单词或者一句代码的情况，使用code这样的形式插入。 插入多行代码，可以使用缩进或者“ code “,具体看示例。  注意： 缩进式插入前方必须有空行\n行内式 1  C语言里的函数 `scanf()` 怎么使用？   view C语言里的函数 scanf() 怎么使用？\n缩进式多行代码 缩进 4 个空格或是 1 个制表符\n一个代码区块会一直持续到没有缩进的那一行（或是文件结尾）。\n1 2 3 4 5  #include \u003cstdio.h\u003e int main(void) { printf(\"Hello world\\n\"); }   view\n#include \u003cstdio.h\u003e int main(void) { printf(\"Hello world\\n\"); }  包裹多行代码 1 2 3 4 5 6 7 8  \u003c!-- 用 ``` 或 ~~~ 包裹多行代码 --\u003e ` ` ` #include \u003cstdio.h\u003e int main(void) { printf(\"Hello world\\n\"); } 、、、   HTML 原始码 在代码区块里面， \u0026 、 \u003c 和 \u003e 会自动转成 HTML 实体，这样的方式让你非常容易使用 Markdown 插入范例用的 HTML 原始码，只需要复制贴上，剩下的 Markdown 都会帮你处理，例如：\n第一个例子：\n1 2 3  \u003cdiv class=\"footer\"\u003e © 2016 *** \u003c/div\u003e   view\n© 2016 ***   Markdown是一种纯文本标记语言 ↩︎\n HyperText Markup Language 超文本标记语言 ↩︎\n 开源笔记平台，支持Markdown和笔记直接发为博文 ↩︎\n   ","description":"","tags":["markdown"],"title":"Markdown 语法总结","uri":"/blog/posts/markdown-syntax-summary/"},{"categories":["Python","Fluent-Python"],"content":" Guido 对语言设计美学的深入理解让人震惊。我认识不少很不错的编程语言设计者，他们设计出来的东西确实很精彩，但是从来都不会有用户。Guido 知道如何在理论上做出一定妥协，设计出来的语言让使用者觉得如沐春风，这真是不可多得。\n——Jim Hugunin\nJython 的作者，AspectJ 的作者之一，.NET DLR 架构师\n Python 最好的品质之一是一致性：你可以轻松理解 Python 语言，并通过 Python 的语言特性在类上定义规范的接口，来支持 Python 的核心语言特性，从而写出具有“Python 风格”的对象。\nPython 解释器在碰到特殊的句法时，会使用特殊方法（我们称之为魔术方法）去激活一些基本的对象操作。\n __getitem__ 以双下划线开头的特殊方法，称为 dunder-getitem。特殊方法也称为双下方法(dunder-method)\n 如 my_c[key] 语句执行时，就会调用 my_c.__getitem__ 函数。这些特殊方法名能让你自己的对象实现和支持一下的语言构架，并与之交互：\n 迭代 集合类 属性访问 运算符重载 函数和方法的调用 对象的创建和销毁 字符串表示形式和格式化 管理上下文（即 with 块）  实现一个 Pythonic 的牌组 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  # 通过实现魔术方法，来让内置函数支持你的自定义对象 # https://github.com/fluentpython/example-code/blob/master/01-data-model/frenchdeck.py import collections import random Card = collections.namedtuple('Card', ['rank', 'suit']) class FrenchDeck: ranks = [str(n) for n in range(2, 11)] + list('JQKA') suits = 'spades diamonds clubs hearts'.split() def __init__(self): self._cards = [Card(rank, suit) for suit in self.suits for rank in self.ranks] def __len__(self): return len(self._cards) def __getitem__(self, position): return self._cards[position] deck = FrenchDeck()   可以容易地获得一个纸牌对象\n1 2  beer_card = Card('7', 'diamonds') print(beer_card)   和标准 Python 集合类型一样，使用 len() 查看一叠纸牌有多少张\n1 2 3  deck = FrenchDeck() # 实现 __len__ 以支持下标操作 print(len(deck))   可选取特定一张纸牌，这是由 __getitem__ 方法提供的\n1 2 3  # 实现 __getitem__ 以支持下标操作 print(deck[1]) print(deck[5::13])   随机抽取一张纸牌，使用 python 内置函数 random.choice\n1 2 3  from random import choice # 可以多运行几次观察 choice(deck)   实现特殊方法的两个好处：\n 对于标准操作有固定命名 更方便利用 Python 标准库  __getitem__ 方法把 [] 操作交给了 self._cards 列表，deck 类自动支持切片操作\n1 2  deck[12::13] deck[:3]   同时 deck 类支持迭代\n1 2 3 4 5 6  for card in deck: print(card) # 反向迭代 for card in reversed(deck): print(card)   迭代通常是隐式的，如果一个集合没有实现 __contains__ 方法，那么 in 运算符会顺序做一次迭代搜索。\n1 2  Card('Q', 'hearts') in deck Card('7', 'beasts') in deck   False  进行排序，排序规则： 2 最小，A最大。花色 黑桃 \u003e 红桃 \u003e 方块 \u003e 梅花\n1 2  card.rank   'A'  1 2 3 4 5 6 7 8 9 10  suit_values = dict(spades=3, hearts=2, diamonds=1, clubs=0) def spades_high(card): rank_value = FrenchDeck.ranks.index(card.rank) return rank_value * len(suit_values) + suit_values[card.suit] for card in sorted(deck, key=spades_high): print(card)   FrenchDeck 继承了 object 类。通过 __len__, __getitem__ 方法，FrenchDeck和 Python 自有序列数据类型一样，可体现 Python 核心语言特性（如迭代和切片），\nPython 支持的所有魔术方法，可以参见 Python 文档 Data Model 部分。\n比较重要的一点：不要把 len，str 等看成一个 Python 普通方法：由于这些操作的频繁程度非常高，所以 Python 对这些方法做了特殊的实现：它可以让 Python 的内置数据结构走后门以提高效率；但对于自定义的数据结构，又可以在对象上使用通用的接口来完成相应工作。但在代码编写者看来，len(deck) 和 len([1,2,3]) 两个实现可能差之千里的操作，在 Python 语法层面上是高度一致的。\n如何使用特殊方法 特殊方法的存在是为了被 Python 解释器调用 除非大量元编程，通常代码无需直接使用特殊方法 通过内置函数来使用特殊方法是最好的选择\n模拟数值类型 实现一个二维向量（Vector）类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  from math import hypot class Vector: def __init__(self, x=0, y=0): self.x = x self.y = y def __repr__(self): return 'Vector(%r, %r)' % (self.x, self.y) def __abs__(self): return hypot(self.x, self.y) def __bool__(self): return bool(abs(self)) def __add__(self, other): x = self.x + other.x y = self.y + other.y return Vector(x, y) def __mul__(self, scalar): return Vector(self.x * scalar, self.y * scalar) # 使用 + 运算符 v1 = Vector(2, 4) v2 = Vector(2, 1) v1 + v2 # 调用 abs 内置函数 v = Vector(3, 4) abs(v) # 使用 * 运算符 v * 3   Vector 类中 6 个方法（除 __init__ 外）并不会在类自身的代码中调用。一般只有解释器会频繁调用这些方法\n字符串的表示形式 内置函数 repr， 通过 __repr__ 特殊方法来得到一个对象的字符串表示形式。\n算数运算符 通过 __add__, __mul__， 向量类能够操作 + 和 * 两个算数运算符。\n 运算符操作对象不发生改变，返回一个产生的新值\n 自定义的布尔值  任何对象可用于需要布尔值的上下文中（if, while 语句， and, or, not 运算符） Python 调用 bool(x) 判定一个值 x，bool(x) 只能返回 True 或者 False 如果类没有实现 __bool__，则调用 __len__， 若返回 0，则 bool 返回 False  特殊方法一览 Reference\n为何 len 不是普通方法  “实用胜于纯粹“ The Zen of Python\n 为了让 Python 自带的数据结构走后门, CPython 会直接从结构体读取对象的长度,而不会调用方法. 这种处理方式在保持内置类型的效率和语言一致性保持了一个平衡.\n小结  通过实现特殊方法，自定义数据类型可以像内置类型一样处理 合理的字符串表示形式是Python对象的基本要求。__repr__, __str__ 序列类型的模拟是特殊方法最常用的地方  ","description":"","tags":["python"],"title":"《流畅的Python》数据类型","uri":"/blog/posts/python/fluent-python/fluent-python-data-types/"},{"categories":["Linux"],"content":"列举一些好用的命令行工具  列举你可能没注意过的好用的 Linux 命令行命令\n 现在做网站做移动应用最讲究的就是推广了，推广做的好那就成功了一大半，相对的没曝光产品再好也很难做下去。就这个角度而言绝大多数 Linux 命令行的推广简直是烂透了。繁多 Linux 有用极了的命令行工具就静静的躺在你发行版默认安装的包裹里，很多时候只有当你碰到什么问题的时候网上搜一圈才能知道。更蛋疼的是这里面很多东西你一旦知道了就会想我靠原来没这个到底是怎么过的下去。所以这里我会列出一些我用过的一些，大部分发行版默认就有，或者能用包裹管理工具轻松获取的东西。\n这篇文章仅讨论 Linux 环境下的东西，很显然对 MacOS 也适用。其实很多东西虽然有 Windows 也可以找的到但配置比较麻烦，这里不再仔细讲。很多东西像 Linux 老鸟看起来会觉得哈哈哈实在是太基础。但是像 cd, ls, mkdir 这些太基础的写在这里又显得太业余，所以很多十分常用的命令这边我也跳过了。像 git 这种重量级的工具，和 sed, awk 这些能单独出书的东西我觉得我也讲不清楚，所以这边都是功能简单的小东西。不过这些小问题就算了吧...\n如果你时间比较充裕 那么不如看看这本书吧: \u003cLinux 命令行使用\u003e。书的内容就跟标题一样，深入浅出的介绍了所谓 \"Linux 命令行\" 的方方面面，本文很多内容也是从书里看到的。网站上有 PDF 合法免费下载，书写的很好可以很随意的看不会觉得压力太大。最主要的，如果你是刚刚接触 Linux 那么这个说不定是最好的上手教程，我十分后悔原来不知道这么书。这么说起来另外一本 Linux 入门大师级教程应该是鸟哥私房菜，这个实在是太出名以至于我觉得没什么可以说的。\n如果你没什么空的话 那下面就以随机的顺序列出一些我觉得非常棒的命令行工具。这里不详细介绍各种参数，你应该做的是用 man xxx 来查看文档。如果这些程序在你的发行版里没有安装，那么请手动搜一下。Mac 用户的话在 homebrew 里可以应该都能找到。\ntmux 虽然说顺序很随机但这一条一定得排在第一个。很多人用 Linux 的状态都是自己的机器是 Windows，用 putty 连到一个哪里的 Linux 服务器进行工作。这样的话每次断开的时候你运行的程序都是会被杀掉的。你可能会希望退出的时候能把打开的程序保持在那里，下次用连接的时候又能自动到之前的工作状态。tmux 就是这个问题的终极解决方案。它们一方面的功能是能在一个 Terminal 里创建多个“窗口”，另一方面如果你关闭连接或者意外掉线，它们默认也不会关掉，下次连上去可以用 tmux attach 来恢复你之前的工作状态。\ntree ls 可能是你最常用的命令之一。tree 可以递归的列出目录下所有的文件，并以树状形式展现：\n对应的也有 pstree 可以以这样的方式来显示进程树。\nack 我记得我曾经在面试的时候被问到过“请写如何调用 grep 来列出当前目录下所有文件里，含有某个字符串的行”。这个问题我的回答是 “用 ack 就可以了”。ack 的官网域名就叫 betterthangrep.com。由于在当前目录下载所有文件里查找某个字串符是如此常见的一个操作，执行 ack foo 就可以在当前目录所有文件里查找 foo。ack 默认会跳过很多没用的目录和文件，让查找更快，输出结果更准确。另外像默认开启的彩色显示也让人用起来很舒畅。\nack 目前大部分发行版中没有，如果你使用的是 Ubuntu 的话其包裹名字是 ack-grep，执行文件的名字也一样。具体可以在这里查看文档。\nrsync 比如说你本地有一台电脑，远程有一台服务器。你想把你的一个文件夹全部拷贝到另外一边的某个地方去。你这个文件夹经常也要更新，希望通过某种方式把更新的部分能迅速同步过去。这应该怎么做？不知道 rsync 的话你可能会想用 git，搭建一个 ftp，或者用 scp 或者别的。但事实上 rsync 才是真正的为精确的解决这个问题而生的软件。rsync 最棒的地方就是差量更新，也就是只把另外一边缺少的东西传过去，而且你不需要任何额外配置，速度快的飞起。一个例子：\nrsync -arvuzp --chmod=g+rx ./built/ me@example.com:/var/www/site\n1 aspell 作为一个程序员你总有一天会要写英文文档。我等母语不是英文的出现拼写错误实在是太正常了。如果你用 Word 的话会有下划线提示你，但如果你是在代码里写注释或者再 Linux 下写 markdown 的话好像就没什么办法。事实上这也是一个已经被解决的问题，aspell 正是来做这个的。aspell 可以对任何纯文本进行拼写检查，作为面向程序员的工具它可以侦测文件类型，比如对 C++ 程序它就只检查注释里的单词。\ntee 有时候某些命令运行的结果会很长，你可能会用 less 来上下看。再或者你可能会用 \u003e 来重定向到文件里。但某些时候程序有可能需要你输入 y 来确认，或者某些程序运行的时间很长，仅仅重定向的话又不太确定是不是它在正常运行。tee 就能做到又输出到屏幕上，又同时重定向到文件。一个简单的例子：\n$ echo waht | tee out.txt\n1 waht 会被输出到屏幕上，同时也会被写到 out.txt 文件里。另外 tee 的意思其实是 T，把输入输出中间拉了又多扯出了一条，可谓是相当形象。\n值得一提的是 vim 也可以用在 pipe 里，例子如下：\n$ echo waht | vim -\n1 \u003cctrl+r\u003e 你肯定知道用键盘上下方向键可以来回找你的历史，那么比如有一个很久之前打过的命令你可能需要猛按上才能找到。其实这时候只要输入一部分然后按 \u003cctrl+r\u003e bash 就会帮你往回搜索。连续按 \u003cctrl+r\u003e 可以按顺序往前搜。(或者直接按 \u003cctrl+r\u003e 再进行输入)。接着上面一个的例子，输入 echo 后按 \u003cctrl+r\u003e 效果如下：\n(reverse-i-search)`echo': echo waht | vim -\n1 有往前搜索那么一般就有往后搜索。可惜的是往后搜索的快捷键是 \u003cctrl+s\u003e，如果你试着按一下的就会发现...好像机器没反应了。这个是因为 \u003cctrl+s\u003e 大部分情况下默认是 XOFF，代表暂停接收输入。按 \u003cctrl+q\u003e 就能恢复。当然你可以把向前搜索绑定到别的键上，请自行搜索。\ncloc 虽说代码行数不能说明任何问题，但有时候不知为什就是想知道。cloc 能精确的计算代码行数，把注释和空格都区分开。如果你是一名传说中的项目经理的话，从今天起开始用 cloc 给你手下的码农算工资吧！下附截屏：\n$ cloc /usr/include/\n9628 text files.\n9308 unique files.\n434 files ignored.\nT=39.0 s (227.6 files/s, 39948.2 lines/s)\n------------------------------------------------- Language files blank comment code\n------------------------------------------------- C/C++ Header 8875 217366 287013 1053368\nTeamcenter def 1 48 0 186\n------------------------------------------------- SUM: 8876 217414 287013 1053554\n------------------------------------------------- 1 2 3 4 5 6 7 8 9 10 11 12 13 14 printenv 用 set 可以查看所有的 Shell 变量还包括 Shell 函数，但是其中有一些是仅仅在当前 shell 里其作用的。而往往你需要找的是通过 export 来定义的环境变量。printenv 就是用来做这个的。\nset -o vi bash 或者可能绝大多数常见 shell 其实都是支持用 vi 的方式进行命令行编辑的，比如设置了 set -o vi 后你就可以用熟悉的 hjkl 来移动，用 w, b 来跳过单词等等。\n同样的如果你设置了 EDITOR 环境变量的话，输入 fc 就可以把之前输入的命令行放到编辑器里来编辑，只要保存了的话就会执行。相反的放弃保存就等于是放弃。\nfind 我把上面说到的那本书仔细看过以后，最大的收获之一就是终于学会了用 find。这个现在变成了我几乎每天都在用的一个命令。比如说我要把目录下所有的 png 文件加入到这次的 git commit 里面，我可以用:\nfind . -name '*.png' -exec git add {} ';'\n1 如果你熟悉 find 的话你会知道最后的 ; 可以换为 + 会更好，但用它就是有目的的。这个命令虽然看起来很简单，但里面的单引号省略或者换成双引号命令都是会失败的。这些牵涉到 \"shell variable expansion\" 和引号的 escape 规则，虽然感觉很恼火但其实这些只有几个简单的规则，而且一致性非常好。所以只要你肯花点时间把相关东西弄清楚，这种简单的问题就可以轻松搞定。\ntype 如果 foo 是一个命令行里可以直接运行的程序的话，你应该知道用 which foo 可以找到 foo 的可执行文件路径在那里。但在命令行里可以执行的命令并不一定都对应到某个可执行的文件，它可以是 alias, shell 自带的函数和用户自己的函数等等。所以有时候用 which 找到不到东西的时候会让人很疑惑。其实你可以用 type foo 看看 foo 到底是什么类型的。\nhelp 上面提到了 \"builtin command\" 也就是内置命令，就是由 shell 提供的一些基本的或者无法由外部程序做到的命令。平常你可以用 man 来查看文档，但是对于内置命令 man 会跳到 shell 自己的 manpage，在某些系统里那就是巨大的一页你要再里面找到你想看的东西，有些系统里干脆就没有相关的信息。这种时候用 help 这个内置命令就可以解决这个问题：比如要查看 set 的接受的选项，可以用 help set 来轻松找到。\nenv 你应该知道在 #! (shebang) 在脚本第一行的作用是指定其 'runtime'。比如说你想要写一个 Python 的脚本，但其实不太在意其版本，或者不确定其可执行文件在不同的机器上到底在哪里。那么 env 在这里就可以派上用场了。可以写成 #!/usr/bin/env python，这样执行的时候就会用当前 PATH 中找到的 python。另一方面这个也是一个给你一个在不修改代码的情况下，重新选择 'runtime' 的机会。\nfile 如果你想知道某个路径上的文件到底是什么类型的，那么用 file 是再合适不过的了。它能对任何东西都给出一个有意义的解释，对于二进制文件还会列出很多相关的重要信息。\nstrings “我把我的秘密，放在了这个用 C++ 编写的程序里面。运行它输入正确的密码才能看到”。其实万一遇到这种情况你只要跑 strings program-written-in-cxx 十有八九你就能看到了。它能比较准确的列出二进制文件里包含的 C 风格的字符串。看起来没什么意义但是其实作用完全要靠你发挥，比如要知道某个程序是哪个版本 GCC 编译出来的用 strings 可能有结果。\nod 全程应该是 \"object dump\"，可以将文件按八进制，十六进制或者其他方式显示出来。我觉得大部分情况下这大家都在用 od -c，将文件按 ASCII 码 dump 出来。一个用例是用来看文件的 line ending 到底是怎样的。比如执行 od -c foo.txt 显示如下结果：\n$ od -c foo.txt\n0000000 h e l l o \\t w o r l d \\r \\n y e a\n0000020 h\n0000021 1 2 3 4 可以清楚的看到 \\t 是 tab 字符， \\r\\n 是 Windows 风格的换行符。\n最后 没什么特别的，只是如果后面还碰到好用的命令行工具我会再添加在这里。\n","description":"","tags":["command-line"],"title":"列举一些好用的命令行工具","uri":"/blog/posts/linux/%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"命令行的艺术  熟练使用命令行是一种常常被忽视，或被认为难以掌握的技能，但实际上，它会提高你作为工程师的灵活性以及生产力。本文是一份我在 Linux 上工作时，发现的一些命令行使用技巧的摘要。有些技巧非常基础，而另一些则相当复杂，甚至晦涩难懂。这篇文章并不长，但当你能够熟练掌握这里列出的所有技巧时，你就学会了很多关于命令行的东西了。\n  前言 基础 日常使用 文件及数据处理 系统调试 单行脚本 冷门但有用 仅限 OS X 系统 仅限 Windows 系统 更多资源 免责声明  这篇文章是许多作者和译者共同的成果。 这里的部分内容 首次 出现 于 Quora， 但已经迁移到了 Github，并由众多高手做出了许多改进。 如果你在本文中发现了错误或者存在可以改善的地方，请[贡献你的一份力量]\n前言 涵盖范围：\n 这篇文章不仅能帮助刚接触命令行的新手，而且对具有经验的人也大有裨益。本文致力于做到覆盖面广（涉及所有重要的内容），具体（给出具体的最常用的例子），以及简洁（避免冗余的内容，或是可以在其他地方轻松查到的细枝末节）。在特定应用场景下，本文的内容属于基本功或者能帮助您节约大量的时间。 本文主要为 Linux 所写，但在仅限 OS X 系统章节和仅限 Windows 系统章节中也包含有对应操作系统的内容。除去这两个章节外，其它的内容大部分均可在其他类 Unix 系统或 OS X，甚至 Cygwin 中得到应用。 本文主要关注于交互式 Bash，但也有很多技巧可以应用于其他 shell 和 Bash 脚本当中。 除去“标准的”Unix 命令，本文还包括了一些依赖于特定软件包的命令（前提是它们具有足够的价值）。  注意事项：\n 为了能在一页内展示尽量多的东西，一些具体的信息可以在引用的页面中找到。我们相信机智的你知道如何使用 Google 或者其他搜索引擎来查阅到更多的详细信息。文中部分命令需要您使用 apt-get，yum，dnf，pacman， pip 或 brew（以及其它合适的包管理器）来安装依赖的程序。 遇到问题的话，请尝试使用 Explainshell 去获取相关命令、参数、管道等内容的解释。  基础   学习 Bash 的基础知识。具体地，在命令行中输入 man bash 并至少全文浏览一遍; 它理解起来很简单并且不冗长。其他的 shell 可能很好用，但 Bash 的功能已经足够强大并且到几乎总是可用的（ 如果你只学习 zsh，fish 或其他的 shell 的话，在你自己的设备上会显得很方便，但过度依赖这些功能会给您带来不便，例如当你需要在服务器上工作时）。\n  熟悉至少一个基于文本的编辑器。通常而言 Vim （vi） 会是你最好的选择，毕竟在终端中编辑文本时 Vim 是最好用的工具（甚至大部分情况下 Vim 要比 Emacs、大型 IDE 或是炫酷的编辑器更好用）。\n  学会如何使用 man 命令去阅读文档。学会使用 apropos 去查找文档。知道有些命令并不对应可执行文件，而是在 Bash 内置好的，此时可以使用 help 和 help -d 命令获取帮助信息。你可以用 type 命令 来判断这个命令到底是可执行文件、shell 内置命令还是别名。\n  学会使用 \u003e 和 \u003c 来重定向输出和输入，学会使用 | 来重定向管道。明白 \u003e 会覆盖了输出文件而 \u003e\u003e 是在文件末添加。了解标准输出 stdout 和标准错误 stderr。\n  学会使用通配符 * （或许再算上 ? 和 [...]） 和引用以及引用中 ' 和 \" 的区别（后文中有一些具体的例子）。\n  熟悉 Bash 中的任务管理工具：\u0026，ctrl-z，ctrl-c，jobs，fg，bg，kill 等。\n  学会使用 ssh 进行远程命令行登录，最好知道如何使用 ssh-agent，ssh-add 等命令来实现基础的无密码认证登录。\n  学会基本的文件管理工具：ls 和 ls -l （了解 ls -l 中每一列代表的意义），less，head，tail 和 tail -f （甚至 less +F），ln 和 ln -s （了解硬链接与软链接的区别），chown，chmod，du （硬盘使用情况概述：du -hs *）。 关于文件系统的管理，学习 df，mount，fdisk，mkfs，lsblk。知道 inode 是什么（与 ls -i 和 df -i 等命令相关）。\n  学习基本的网络管理工具：ip 或 ifconfig，dig。\n  学习并使用一种版本控制管理系统，例如 git。\n  熟悉正则表达式，学会使用 grep／egrep，它们的参数中 -i，-o，-v，-A，-B 和 -C 这些是很常用并值得认真学习的。\n  学会使用 apt-get，yum，dnf 或 pacman （具体使用哪个取决于你使用的 Linux 发行版）来查找和安装软件包。并确保你的环境中有 pip 来安装基于 Python 的命令行工具 （接下来提到的部分程序使用 pip 来安装会很方便）。\n  日常使用   在 Bash 中，可以通过按 Tab 键实现自动补全参数，使用 ctrl-r 搜索命令行历史记录（按下按键之后，输入关键字便可以搜索，重复按下 ctrl-r 会向后查找匹配项，按下 Enter 键会执行当前匹配的命令，而按下右方向键会将匹配项放入当前行中，不会直接执行，以便做出修改）。\n  在 Bash 中，可以按下 ctrl-w 删除你键入的最后一个单词，ctrl-u 可以删除行内光标所在位置之前的内容，alt-b 和 alt-f 可以以单词为单位移动光标，ctrl-a 可以将光标移至行首，ctrl-e 可以将光标移至行尾，ctrl-k 可以删除光标至行尾的所有内容，ctrl-l 可以清屏。键入 man readline 可以查看 Bash 中的默认快捷键。内容有很多，例如 alt-. 循环地移向前一个参数，而 alt-* 可以展开通配符。\n  你喜欢的话，可以执行 set -o vi 来使用 vi 风格的快捷键，而执行 set -o emacs 可以把它改回来。\n  为了便于编辑长命令，在设置你的默认编辑器后（例如 export EDITOR=vim），ctrl-x ctrl-e 会打开一个编辑器来编辑当前输入的命令。在 vi 风格下快捷键则是 escape-v。\n  键入 history 查看命令行历史记录，再用 !n（n 是命令编号）就可以再次执行。其中有许多缩写，最有用的大概就是 !$， 它用于指代上次键入的参数，而 !! 可以指代上次键入的命令了（参考 man 页面中的“HISTORY EXPANSION”）。不过这些功能，你也可以通过快捷键 ctrl-r 和 alt-. 来实现。\n  cd 命令可以切换工作路径，输入 cd ~ 可以进入 home 目录。要访问你的 home 目录中的文件，可以使用前缀 ~（例如 ~/.bashrc）。在 sh 脚本里则用环境变量 $HOME 指代 home 目录的路径。\n  回到前一个工作路径：cd -。\n  如果你输入命令的时候中途改了主意，按下 alt-# 在行首添加 # 把它当做注释再按下回车执行（或者依次按下 ctrl-a， #， enter）。这样做的话，之后借助命令行历史记录，你可以很方便恢复你刚才输入到一半的命令。\n  使用 xargs （ 或 parallel）。他们非常给力。注意到你可以控制每行参数个数（-L）和最大并行数（-P）。如果你不确定它们是否会按你想的那样工作，先使用 xargs echo 查看一下。此外，使用 -I{} 会很方便。例如：\n  1 2  find . -name '*.py' | xargs grep some_function cat hosts | xargs -I{} ssh root@{} hostname     pstree -p 以一种优雅的方式展示进程树。\n  使用 pgrep 和 pkill 根据名字查找进程或发送信号（-f 参数通常有用）。\n  了解你可以发往进程的信号的种类。比如，使用 kill -STOP [pid] 停止一个进程。使用 man 7 signal 查看详细列表。\n  使用 nohup 或 disown 使一个后台进程持续运行。\n  使用 netstat -lntp 或 ss -plat 检查哪些进程在监听端口（默认是检查 TCP 端口; 添加参数 -u 则检查 UDP 端口）或者 lsof -iTCP -sTCP:LISTEN -P -n (这也可以在 OS X 上运行)。\n  lsof 来查看开启的套接字和文件。\n  使用 uptime 或 w 来查看系统已经运行多长时间。\n  使用 alias 来创建常用命令的快捷形式。例如：alias ll='ls -latr' 创建了一个新的命令别名 ll。\n  可以把别名、shell 选项和常用函数保存在 ~/.bashrc，具体看下这篇文章。这样做的话你就可以在所有 shell 会话中使用你的设定。\n  把环境变量的设定以及登陆时要执行的命令保存在 ~/.bash_profile。而对于从图形界面启动的 shell 和 cron 启动的 shell，则需要单独配置文件。\n  要想在几台电脑中同步你的配置文件（例如 .bashrc 和 .bash_profile），可以借助 Git。\n  当变量和文件名中包含空格的时候要格外小心。Bash 变量要用引号括起来，比如 \"$FOO\"。尽量使用 -0 或 -print0 选项以便用 NULL 来分隔文件名，例如 locate -0 pattern | xargs -0 ls -al 或 find / -print0 -type d | xargs -0 ls -al。如果 for 循环中循环访问的文件名含有空字符（空格、tab 等字符），只需用 IFS=$'\\n' 把内部字段分隔符设为换行符。\n  在 Bash 脚本中，使用 set -x 去调试输出（或者使用它的变体 set -v，它会记录原始输入，包括多余的参数和注释）。尽可能地使用严格模式：使用 set -e 令脚本在发生错误时退出而不是继续运行；使用 set -u 来检查是否使用了未赋值的变量；试试 set -o pipefail，它可以监测管道中的错误。当牵扯到很多脚本时，使用 trap 来检测 ERR 和 EXIT。一个好的习惯是在脚本文件开头这样写，这会使它能够检测一些错误，并在错误发生时中断程序并输出信息：\n  1 2  set -euo pipefail trap \"echo 'error: Script failed: see failed command above'\" ERR    在 Bash 脚本中，子 shell（使用括号 (...)）是一种组织参数的便捷方式。一个常见的例子是临时地移动工作路径，代码如下：  1 2 3  # do something in current dir (cd /some/other/dir \u0026\u0026 other-command) # continue in original dir     在 Bash 中，变量有许多的扩展方式。${name:?error message} 用于检查变量是否存在。此外，当 Bash 脚本只需要一个参数时，可以使用这样的代码 input_file=${1:?usage: $0 input_file}。在变量为空时使用默认值：${name:-default}。如果你要在之前的例子中再加一个（可选的）参数，可以使用类似这样的代码 output_file=${2:-logfile}，如果省略了 $2，它的值就为空，于是 output_file 就会被设为 logfile。数学表达式：i=$(( (i + 1) % 5 ))。序列：{1..10}。截断字符串：${var%suffix} 和 ${var#prefix}。例如，假设 var=foo.pdf，那么 echo ${var%.pdf}.txt 将输出 foo.txt。\n  使用括号扩展（{...}）来减少输入相似文本，并自动化文本组合。这在某些情况下会很有用，例如 mv foo.{txt,pdf} some-dir（同时移动两个文件），cp somefile{,.bak}（会被扩展成 cp somefile somefile.bak）或者 mkdir -p test-{a,b,c}/subtest-{1,2,3}（会被扩展成所有可能的组合，并创建一个目录树）。\n  通过使用 \u003c(some command) 可以将输出视为文件。例如，对比本地文件 /etc/hosts 和一个远程文件：\n  1  diff /etc/hosts \u003c(ssh somehost cat /etc/hosts)    编写脚本时，你可能会想要把代码都放在大括号里。缺少右括号的话，代码就会因为语法错误而无法执行。如果你的脚本是要放在网上分享供他人使用的，这样的写法就体现出它的好处了，因为这样可以防止下载不完全代码被执行。  1 2 3  { # 在这里写代码 }     了解 Bash 中的“here documents”，例如 cat \u003c\u003cEOF ...。\n  在 Bash 中，同时重定向标准输出和标准错误：some-command \u003elogfile 2\u003e\u00261 或者 some-command \u0026\u003elogfile。通常，为了保证命令不会在标准输入里残留一个未关闭的文件句柄捆绑在你当前所在的终端上，在命令后添加 \u003c/dev/null 是一个好习惯。\n  使用 man ascii 查看具有十六进制和十进制值的ASCII表。man unicode，man utf-8，以及 man latin1 有助于你去了解通用的编码信息。\n  使用 screen 或 tmux 来使用多份屏幕，当你在使用 ssh 时（保存 session 信息）将尤为有用。而 byobu 可以为它们提供更多的信息和易用的管理工具。另一个轻量级的 session 持久化解决方案是 dtach。\n  ssh 中，了解如何使用 -L 或 -D（偶尔需要用 -R）开启隧道是非常有用的，比如当你需要从一台远程服务器上访问 web 页面。\n  对 ssh 设置做一些小优化可能是很有用的，例如这个 ~/.ssh/config 文件包含了防止特定网络环境下连接断开、压缩数据、多通道等选项：\n   TCPKeepAlive=yes ServerAliveInterval=15 ServerAliveCountMax=6 Compression=yes ControlMaster auto ControlPath /tmp/%r@%h:%p ControlPersist yes   一些其他的关于 ssh 的选项是与安全相关的，应当小心翼翼的使用。例如你应当只能在可信任的网络中启用 StrictHostKeyChecking=no，ForwardAgent=yes。\n  考虑使用 mosh 作为 ssh 的替代品，它使用 UDP 协议。它可以避免连接被中断并且对带宽需求更小，但它需要在服务端做相应的配置。\n  获取八进制形式的文件访问权限（修改系统设置时通常需要，但 ls 的功能不那么好用并且通常会搞砸），可以使用类似如下的代码：\n  1  stat -c '%A %a %n' /etc/timezone     使用 percol 或者 fzf 可以交互式地从另一个命令输出中选取值。\n  使用 fpp（PathPicker）可以与基于另一个命令(例如 git）输出的文件交互。\n  将 web 服务器上当前目录下所有的文件（以及子目录）暴露给你所处网络的所有用户，使用： python -m SimpleHTTPServer 7777 （使用端口 7777 和 Python 2）或python -m http.server 7777 （使用端口 7777 和 Python 3）。\n  以其他用户的身份执行命令，使用 sudo。默认以 root 用户的身份执行；使用 -u 来指定其他用户。使用 -i 来以该用户登录（需要输入_你自己的_密码）。\n  将 shell 切换为其他用户，使用 su username 或者 sudo - username。加入 - 会使得切换后的环境与使用该用户登录后的环境相同。省略用户名则默认为 root。切换到哪个用户，就需要输入_哪个用户的_密码。\n  了解命令行的 128K 限制。使用通配符匹配大量文件名时，常会遇到“Argument list too long”的错误信息。（这种情况下换用 find 或 xargs 通常可以解决。）\n  当你需要一个基本的计算器时，可以使用 python 解释器（当然你要用 python 的时候也是这样）。例如：\n  \u003e\u003e\u003e 2+3 5 文件及数据处理   在当前目录下通过文件名查找一个文件，使用类似于这样的命令：find . -iname '*something*'。在所有路径下通过文件名查找文件，使用 locate something （但注意到 updatedb 可能没有对最近新建的文件建立索引，所以你可能无法定位到这些未被索引的文件）。\n  使用 ag 在源代码或数据文件里检索（grep -r 同样可以做到，但相比之下 ag 更加先进）。\n  将 HTML 转为文本：lynx -dump -stdin。\n  Markdown，HTML，以及所有文档格式之间的转换，试试 pandoc。\n  当你要处理棘手的 XML 时候，xmlstarlet 算是上古时代流传下来的神器。\n  使用 jq 处理 JSON。\n  使用 shyaml 处理 YAML。\n  要处理 Excel 或 CSV 文件的话，csvkit 提供了 in2csv，csvcut，csvjoin，csvgrep 等方便易用的工具。\n  当你要处理 Amazon S3 相关的工作的时候，s3cmd 是一个很方便的工具而 s4cmd 的效率更高。Amazon 官方提供的 aws 以及 saws 是其他 AWS 相关工作的基础，值得学习。\n  了解如何使用 sort 和 uniq，包括 uniq 的 -u 参数和 -d 参数，具体内容在后文单行脚本节中。另外可以了解一下 comm。\n  了解如何使用 cut，paste 和 join 来更改文件。很多人都会使用 cut，但遗忘了 join。\n  了解如何运用 wc 去计算新行数（-l），字符数（-m），单词数（-w）以及字节数（-c）。\n  了解如何使用 tee 将标准输入复制到文件甚至标准输出，例如 ls -al | tee file.txt。\n  要进行一些复杂的计算，比如分组、逆序和一些其他的统计分析，可以考虑使用 datamash。\n  注意到语言设置（中文或英文等）对许多命令行工具有一些微妙的影响，比如排序的顺序和性能。大多数 Linux 的安装过程会将 LANG 或其他有关的变量设置为符合本地的设置。要意识到当你改变语言设置时，排序的结果可能会改变。明白国际化可能会使 sort 或其他命令运行效率下降许多倍。某些情况下（例如集合运算）你可以放心的使用 export LC_ALL=C 来忽略掉国际化并按照字节来判断顺序。\n  你可以单独指定某一条命令的环境，只需在调用时把环境变量设定放在命令的前面，例如 TZ=Pacific/Fiji date 可以获取斐济的时间。\n  了解如何使用 awk 和 sed 来进行简单的数据处理。 参阅 One-liners 获取示例。\n  替换一个或多个文件中出现的字符串：\n  1  perl -pi.bak -e 's/old-string/new-string/g' my-files-*.txt    使用 repren 来批量重命名文件，或是在多个文件中搜索替换内容。（有些时候 rename 命令也可以批量重命名，但要注意，它在不同 Linux 发行版中的功能并不完全一样。）  1 2 3 4 5 6  # 将文件、目录和内容全部重命名 foo -\u003e bar: repren --full --preserve-case --from foo --to bar . # 还原所有备份文件 whatever.bak -\u003e whatever: repren --renames --from '(.*)\\.bak' --to '\\1' *.bak # 用 rename 实现上述功能（若可用）: rename 's/\\.bak$//' *.bak    根据 man 页面的描述，rsync 是一个快速且非常灵活的文件复制工具。它闻名于设备之间的文件同步，但其实它在本地情况下也同样有用。在安全设置允许下，用 rsync 代替 scp 可以实现文件续传，而不用重新从头开始。它同时也是删除大量文件的最快方法之一：  1  mkdir empty \u0026\u0026 rsync -r --delete empty/ some-dir \u0026\u0026 rmdir some-dir     若要在复制文件时获取当前进度，可使用 pv，pycp，progress，rsync --progress。若所执行的复制为block块拷贝，可以使用 dd status=progress。\n  使用 shuf 可以以行为单位来打乱文件的内容或从一个文件中随机选取多行。\n  了解 sort 的参数。显示数字时，使用 -n 或者 -h 来显示更易读的数（例如 du -h 的输出）。明白排序时关键字的工作原理（-t 和 -k）。例如，注意到你需要 -k1，1 来仅按第一个域来排序，而 -k1 意味着按整行排序。稳定排序（sort -s）在某些情况下很有用。例如，以第二个域为主关键字，第一个域为次关键字进行排序，你可以使用 sort -k1，1 | sort -s -k2，2。\n  如果你想在 Bash 命令行中写 tab 制表符，按下 ctrl-v [Tab] 或键入 $'\\t' （后者可能更好，因为你可以复制粘贴它）。\n  标准的源代码对比及合并工具是 diff 和 patch。使用 diffstat 查看变更总览数据。注意到 diff -r 对整个文件夹有效。使用 diff -r tree1 tree2 | diffstat 查看变更的统计数据。vimdiff 用于比对并编辑文件。\n  对于二进制文件，使用 hd，hexdump 或者 xxd 使其以十六进制显示，使用 bvi，hexedit 或者 biew 来进行二进制编辑。\n  同样对于二进制文件，strings（包括 grep 等工具）可以帮助在二进制文件中查找特定比特。\n  制作二进制差分文件（Delta 压缩），使用 xdelta3。\n  使用 iconv 更改文本编码。需要更高级的功能，可以使用 uconv，它支持一些高级的 Unicode 功能。例如，这条命令移除了所有重音符号：\n  1  uconv -f utf-8 -t utf-8 -x '::Any-Lower; ::Any-NFD; [:Nonspacing Mark:] \u003e; ::Any-NFC; ' \u003c input.txt \u003e output.txt     拆分文件可以使用 split（按大小拆分）和 csplit（按模式拆分）。\n  操作日期和时间表达式，可以用 dateutils 中的 dateadd、datediff、strptime 等工具。\n  使用 zless、zmore、zcat 和 zgrep 对压缩过的文件进行操作。\n  文件属性可以通过 chattr 进行设置，它比文件权限更加底层。例如，为了保护文件不被意外删除，可以使用不可修改标记：sudo chattr +i /critical/directory/or/file\n  使用 getfacl 和 setfacl 以保存和恢复文件权限。例如：\n  1 2  getfacl -R /some/path \u003e permissions.txt setfacl --restore=permissions.txt    为了高效地创建空文件，请使用 truncate（创建稀疏文件），fallocate（用于 ext4，xfs，btrf 和 ocfs2 文件系统），xfs_mkfile（适用于几乎所有的文件系统，包含在 xfsprogs 包中），mkfile（用于类 Unix 操作系统，比如 Solaris 和 Mac OS）。  系统调试   curl 和 curl -I 可以被轻松地应用于 web 调试中，它们的好兄弟 wget 也是如此，或者也可以试试更潮的 httpie。\n  获取 CPU 和硬盘的使用状态，通常使用使用 top（htop 更佳），iostat 和 iotop。而 iostat -mxz 15 可以让你获悉 CPU 和每个硬盘分区的基本信息和性能表现。\n  使用 netstat 和 ss 查看网络连接的细节。\n  dstat 在你想要对系统的现状有一个粗略的认识时是非常有用的。然而若要对系统有一个深度的总体认识，使用 glances，它会在一个终端窗口中向你提供一些系统级的数据。\n  若要了解内存状态，运行并理解 free 和 vmstat 的输出。值得留意的是“cached”的值，它指的是 Linux 内核用来作为文件缓存的内存大小，而与空闲内存无关。\n  Java 系统调试则是一件截然不同的事，一个可以用于 Oracle 的 JVM 或其他 JVM 上的调试的技巧是你可以运行 kill -3 \u003cpid\u003e 同时一个完整的栈轨迹和堆概述（包括 GC 的细节）会被保存到标准错误或是日志文件。JDK 中的 jps，jstat，jstack，jmap 很有用。SJK tools 更高级。\n  使用 mtr 去跟踪路由，用于确定网络问题。\n  用 ncdu 来查看磁盘使用情况，它比寻常的命令，如 du -sh *，更节省时间。\n  查找正在使用带宽的套接字连接或进程，使用 iftop 或 nethogs。\n  ab 工具（Apache 中自带）可以简单粗暴地检查 web 服务器的性能。对于更复杂的负载测试，使用 siege。\n  wireshark，tshark 和 ngrep 可用于复杂的网络调试。\n  了解 strace 和 ltrace。这俩工具在你的程序运行失败、挂起甚至崩溃，而你却不知道为什么或你想对性能有个总体的认识的时候是非常有用的。注意 profile 参数（-c）和附加到一个运行的进程参数 （-p）。\n  了解使用 ldd 来检查共享库。但是永远不要在不信任的文件上运行。\n  了解如何运用 gdb 连接到一个运行着的进程并获取它的堆栈轨迹。\n  学会使用 /proc。它在调试正在出现的问题的时候有时会效果惊人。比如：/proc/cpuinfo，/proc/meminfo，/proc/cmdline，/proc/xxx/cwd，/proc/xxx/exe，/proc/xxx/fd/，/proc/xxx/smaps（这里的 xxx 表示进程的 id 或 pid）。\n  当调试一些之前出现的问题的时候，sar 非常有用。它展示了 cpu、内存以及网络等的历史数据。\n  关于更深层次的系统分析以及性能分析，看看 stap（SystemTap），perf，以及sysdig。\n  查看你当前使用的系统，使用 uname，uname -a（Unix／kernel 信息）或者 lsb_release -a（Linux 发行版信息）。\n  无论什么东西工作得很欢乐（可能是硬件或驱动问题）时可以试试 dmesg。\n  如果你删除了一个文件，但通过 du 发现没有释放预期的磁盘空间，请检查文件是否被进程占用： lsof | grep deleted | grep \"filename-of-my-big-file\"\n  单行脚本 一些命令组合的例子：\n 当你需要对文本文件做集合交、并、差运算时，sort 和 uniq 会是你的好帮手。具体例子请参照代码后面的，此处假设 a 与 b 是两内容不同的文件。这种方式效率很高，并且在小文件和上 G 的文件上都能运用（注意尽管在 /tmp 在一个小的根分区上时你可能需要 -T 参数，但是实际上 sort 并不被内存大小约束），参阅前文中关于 LC_ALL 和 sort 的 -u 参数的部分。  1 2 3  sort a b | uniq \u003e c # c 是 a 并 b sort a b | uniq -d \u003e c # c 是 a 交 b sort a b b | uniq -u \u003e c # c 是 a - b     使用 grep . *（每行都会附上文件名）或者 head -100 *（每个文件有一个标题）来阅读检查目录下所有文件的内容。这在检查一个充满配置文件的目录（如 /sys、/proc、/etc）时特别好用。\n  计算文本文件第三列中所有数的和（可能比同等作用的 Python 代码快三倍且代码量少三倍）：\n  1  awk '{ x += $3 } END { print x }' myfile    如果你想在文件树上查看大小/日期，这可能看起来像递归版的 ls -l 但比 ls -lR 更易于理解：  1  find . -type f -ls    假设你有一个类似于 web 服务器日志文件的文本文件，并且一个确定的值只会出现在某些行上，假设一个 acct_id 参数在 URI 中。如果你想计算出每个 acct_id 值有多少次请求，使用如下代码：  1  egrep -o 'acct_id=[0-9]+' access.log | cut -d= -f2 | sort | uniq -c | sort -rn     要持续监测文件改动，可以使用 watch，例如检查某个文件夹中文件的改变，可以用 watch -d -n 2 'ls -rtlh | tail'；或者在排查 WiFi 设置故障时要监测网络设置的更改，可以用 watch -d -n 2 ifconfig。\n  运行这个函数从这篇文档中随机获取一条技巧（解析 Markdown 文件并抽取项目）：\n  1 2 3 4 5 6 7 8  function taocl() { curl -s https://raw.githubusercontent.com/jlevy/the-art-of-command-line/master/README-zh.md| pandoc -f markdown -t html | iconv -f 'utf-8' -t 'unicode' | xmlstarlet fo --html --dropdtd | xmlstarlet sel -t -v \"(html/body/ul/li[count(p)\u003e0])[$RANDOMmod last()+1]\" | xmlstarlet unesc | fmt -80 }   冷门但有用   expr：计算表达式或正则匹配\n  m4：简单的宏处理器\n  yes：多次打印字符串\n  cal：漂亮的日历\n  env：执行一个命令（脚本文件中很有用）\n  printenv：打印环境变量（调试时或在写脚本文件时很有用）\n  look：查找以特定字符串开头的单词或行\n  cut，paste 和 join：数据修改\n  fmt：格式化文本段落\n  pr：将文本格式化成页／列形式\n  fold：包裹文本中的几行\n  column：将文本格式化成多个对齐、定宽的列或表格\n  expand 和 unexpand：制表符与空格之间转换\n  nl：添加行号\n  seq：打印数字\n  bc：计算器\n  factor：分解因数\n  gpg：加密并签名文件\n  toe：terminfo 入口列表\n  nc：网络调试及数据传输\n  socat：套接字代理，与 netcat 类似\n  slurm：网络流量可视化\n  dd：文件或设备间传输数据\n  file：确定文件类型\n  tree：以树的形式显示路径和文件，类似于递归的 ls\n  stat：文件信息\n  time：执行命令，并计算执行时间\n  timeout：在指定时长范围内执行命令，并在规定时间结束后停止进程\n  lockfile：使文件只能通过 rm -f 移除\n  logrotate： 切换、压缩以及发送日志文件\n  watch：重复运行同一个命令，展示结果并／或高亮有更改的部分\n  when-changed：当检测到文件更改时执行指定命令。参阅 inotifywait 和 entr。\n  tac：反向输出文件\n  shuf：文件中随机选取几行\n  comm：一行一行的比较排序过的文件\n  strings：从二进制文件中抽取文本\n  tr：转换字母\n  iconv 或 uconv：文本编码转换\n  split 和 csplit：分割文件\n  sponge：在写入前读取所有输入，在读取文件后再向同一文件写入时比较有用，例如 grep -v something some-file | sponge some-file\n  units：将一种计量单位转换为另一种等效的计量单位（参阅 /usr/share/units/definitions.units）\n  apg：随机生成密码\n  xz：高比例的文件压缩\n  ldd：动态库信息\n  nm：提取 obj 文件中的符号\n  ab 或 wrk：web 服务器性能分析\n  strace：调试系统调用\n  mtr：更好的网络调试跟踪工具\n  cssh：可视化的并发 shell\n  rsync：通过 ssh 或本地文件系统同步文件和文件夹\n  wireshark 和 tshark：抓包和网络调试工具\n  ngrep：网络层的 grep\n  host 和 dig：DNS 查找\n  lsof：列出当前系统打开文件的工具以及查看端口信息\n  dstat：系统状态查看\n  glances：高层次的多子系统总览\n  iostat：硬盘使用状态\n  mpstat： CPU 使用状态\n  vmstat： 内存使用状态\n  htop：top 的加强版\n  last：登入记录\n  w：查看处于登录状态的用户\n  id：用户/组 ID 信息\n  sar：系统历史数据\n  iftop 或 nethogs：套接字及进程的网络利用情况\n  ss：套接字数据\n  dmesg：引导及系统错误信息\n  sysctl： 在内核运行时动态地查看和修改内核的运行参数\n  hdparm：SATA/ATA 磁盘更改及性能分析\n  lsblk：列出块设备信息：以树形展示你的磁盘以及磁盘分区信息\n  lshw，lscpu，lspci，lsusb 和 dmidecode：查看硬件信息，包括 CPU、BIOS、RAID、显卡、USB设备等\n  lsmod 和 modinfo：列出内核模块，并显示其细节\n  fortune，ddate 和 sl：额，这主要取决于你是否认为蒸汽火车和莫名其妙的名人名言是否“有用”\n  仅限 OS X 系统 以下是仅限于 OS X 系统的技巧。\n  用 brew （Homebrew）或者 port （MacPorts）进行包管理。这些可以用来在 OS X 系统上安装以上的大多数命令。\n  用 pbcopy 复制任何命令的输出到桌面应用，用 pbpaste 粘贴输入。\n  若要在 OS X 终端中将 Option 键视为 alt 键（例如在上面介绍的 alt-b、alt-f 等命令中用到），打开 偏好设置 -\u003e 描述文件 -\u003e 键盘 并勾选“使用 Option 键作为 Meta 键”。\n  用 open 或者 open -a /Applications/Whatever.app 使用桌面应用打开文件。\n  Spotlight：用 mdfind 搜索文件，用 mdls 列出元数据（例如照片的 EXIF 信息）。\n  注意 OS X 系统是基于 BSD UNIX 的，许多命令（例如 ps，ls，tail，awk，sed）都和 Linux 中有微妙的不同（ Linux 很大程度上受到了 System V-style Unix 和 GNU 工具影响）。你可以通过标题为 \"BSD General Commands Manual\" 的 man 页面发现这些不同。在有些情况下 GNU 版本的命令也可能被安装（例如 gawk 和 gsed 对应 GNU 中的 awk 和 sed ）。如果要写跨平台的 Bash 脚本，避免使用这些命令（例如，考虑 Python 或者 perl ）或者经过仔细的测试。\n  用 sw_vers 获取 OS X 的版本信息。\n  仅限 Windows 系统 以下是仅限于 Windows 系统的技巧。\n在 Winodws 下获取 Unix 工具   可以安装 Cygwin 允许你在 Microsoft Windows 中体验 Unix shell 的威力。这样的话，本文中介绍的大多数内容都将适用。\n  在 Windows 10 上，你可以使用 Bash on Ubuntu on Windows，它提供了一个熟悉的 Bash 环境，包含了不少 Unix 命令行工具。好处是它允许 Linux 上编写的程序在 Windows 上运行，而另一方面，Windows 上编写的程序却无法在 Bash 命令行中运行。\n  如果你在 Windows 上主要想用 GNU 开发者工具（例如 GCC），可以考虑 MinGW 以及它的 MSYS 包，这个包提供了例如 bash，gawk，make 和 grep 的工具。MSYS 并不包含所有可以与 Cygwin 媲美的特性。当制作 Unix 工具的原生 Windows 端口时 MinGW 将特别地有用。\n  另一个在 Windows 下实现接近 Unix 环境外观效果的选项是 Cash。注意在此环境下只有很少的 Unix 命令和命令行可用。\n  实用 Windows 命令行工具   可以使用 wmic 在命令行环境下给大部分 Windows 系统管理任务编写脚本以及执行这些任务。\n  Windows 实用的原生命令行网络工具包括 ping，ipconfig，tracert，和 netstat。\n  可以使用 Rundll32 命令来实现许多有用的 Windows 任务 。\n  Cygwin 技巧   通过 Cygwin 的包管理器来安装额外的 Unix 程序。\n  使用 mintty 作为你的命令行窗口。\n  要访问 Windows 剪贴板，可以通过 /dev/clipboard。\n  运行 cygstart 以通过默认程序打开一个文件。\n  要访问 Windows 注册表，可以使用 regtool。\n  注意 Windows 驱动器路径 C:\\ 在 Cygwin 中用 /cygdrive/c 代表，而 Cygwin 的 / 代表 Windows 中的 C:\\cygwin。要转换 Cygwin 和 Windows 风格的路径可以用 cygpath。这在需要调用 Windows 程序的脚本里很有用。\n  学会使用 wmic，你就可以从命令行执行大多数 Windows 系统管理任务，并编成脚本。\n  要在 Windows 下获得 Unix 的界面和体验，另一个办法是使用 Cash。需要注意的是，这个环境支持的 Unix 命令和命令行参数非常少。\n  要在 Windows 上获取 GNU 开发者工具（比如 GCC）的另一个办法是使用 MinGW 以及它的 MSYS 软件包，该软件包提供了 bash、gawk、make、grep 等工具。然而 MSYS 提供的功能没有 Cygwin 完善。MinGW 在创建 Unix 工具的 Windows 原生移植方面非常有用。\n  更多资源  awesome-shell：一份精心组织的命令行工具及资源的列表。 awesome-osx-command-line：一份针对 OS X 命令行的更深入的指南。 Strict mode：为了编写更好的脚本文件。 shellcheck：一个静态 shell 脚本分析工具，本质上是 bash／sh／zsh 的 lint。 Filenames and Pathnames in Shell：有关如何在 shell 脚本里正确处理文件名的细枝末节。 Data Science at the Command Line：用于数据科学的一些命令和工具，摘自同名书籍。  免责声明 除去特别小的工作，你编写的代码应当方便他人阅读。能力往往伴随着责任，你 有能力 在 Bash 中玩一些奇技淫巧并不意味着你应该去做！;)\n授权条款 \n本文使用授权协议 Creative Commons Attribution-ShareAlike 4.0 International License。\n","description":"","tags":["command-line"],"title":"命令行的艺术","uri":"/blog/posts/linux/%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%9A%84%E8%89%BA%E6%9C%AF/"},{"categories":null,"content":"HTTP 状态码分类及解释  HTTP 协议中状态码繁多，本文介绍 HPPT/1.1 协议中各种状态码\n Hypertext Transfer Protocol -- HTTP/1.1\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42  Status-Code = \"100\" ; Section 10.1.1: Continue | \"101\" ; Section 10.1.2: Switching Protocols | \"200\" ; Section 10.2.1: OK | \"201\" ; Section 10.2.2: Created | \"202\" ; Section 10.2.3: Accepted | \"203\" ; Section 10.2.4: Non-Authoritative Information | \"204\" ; Section 10.2.5: No Content | \"205\" ; Section 10.2.6: Reset Content | \"206\" ; Section 10.2.7: Partial Content | \"300\" ; Section 10.3.1: Multiple Choices | \"301\" ; Section 10.3.2: Moved Permanently | \"302\" ; Section 10.3.3: Found | \"303\" ; Section 10.3.4: See Other | \"304\" ; Section 10.3.5: Not Modified | \"305\" ; Section 10.3.6: Use Proxy | \"307\" ; Section 10.3.8: Temporary Redirect | \"400\" ; Section 10.4.1: Bad Request | \"401\" ; Section 10.4.2: Unauthorized | \"402\" ; Section 10.4.3: Payment Required | \"403\" ; Section 10.4.4: Forbidden | \"404\" ; Section 10.4.5: Not Found | \"405\" ; Section 10.4.6: Method Not Allowed | \"406\" ; Section 10.4.7: Not Acceptable | \"407\" ; Section 10.4.8: Proxy Authentication Required | \"408\" ; Section 10.4.9: Request Time-out | \"409\" ; Section 10.4.10: Conflict | \"410\" ; Section 10.4.11: Gone | \"411\" ; Section 10.4.12: Length Required | \"412\" ; Section 10.4.13: Precondition Failed | \"413\" ; Section 10.4.14: Request Entity Too Large | \"414\" ; Section 10.4.15: Request-URI Too Large | \"415\" ; Section 10.4.16: Unsupported Media Type | \"416\" ; Section 10.4.17: Requested range not satisfiable | \"417\" ; Section 10.4.18: Expectation Failed | \"500\" ; Section 10.5.1: Internal Server Error | \"501\" ; Section 10.5.2: Not Implemented | \"502\" ; Section 10.5.3: Bad Gateway | \"503\" ; Section 10.5.4: Service Unavailable | \"504\" ; Section 10.5.5: Gateway Time-out | \"505\" ; Section 10.5.6: HTTP Version not supported | extension-code   状态码分类 这些状态码被分为五大类：\n  100-199 用于指定客户端应相应的某些动作。\n  200-299 用于表示请求成功。\n  300-399 用于已经移动的文件并且常被包含在定位头信息中指定新的地址信息。\n  400-499 用于指出客户端的错误。\n  500-599 用于支持服务器错误。\n  HttpServletResponse中的常量代表关联不同标准消息的状态码。在servlet程序中，你会更多地用到这些常量的标识来使用状态码。例如：你一般会使用response.setStatus(response.SC_NO_CONTENT)而不是 response.setStatus(204)，因为后者不易理解而且容易导致错误。但是，你应当注意到服务器允许对消息轻微的改变，而客户端只注意状态码的数字值。所以服务器可能只返回 HTTP/1.1 200 而不是 HTTP/1.1 200 OK。\n状态码详解   100 (Continue/继续)\n如果服务器收到头信息中带有100-continue的请求，这是指客户端询问是否可以在后续的请求中发送附件。在这种情况下，服务器用100(SC_CONTINUE)允许客户端继续或用417 (Expectation Failed)告诉客户端不同意接受附件。这个状态码是 HTTP 1.1中新加入的。\n  101 (Switching Protocols/转换协议)\n  101 (SC_SWITCHING_PROTOCOLS)状态码是指服务器将按照其上的头信息变为一个不同的协议。这是 HTTP 1.1中新加入的。\n  200 (OK/正常)\n200 (SC_OK)的意思是一切正常。一般用于相应GET和POST请求。这个状态码对servlet是缺省的；如果没有调用setStatus方法的话，就会得到200。\n  201 (Created/已创建)\n  201 (SC_CREATED)表示服务器在请求的响应中建立了新文档；应在定位头信息中给出它的URL。\n  202 (Accepted/接受)\n  202 (SC_ACCEPTED)告诉客户端请求正在被执行，但还没有处理完。\n  203 (Non-Authoritative Information/非官方信息)\n状态码203 (SC_NON_AUTHORITATIVE_INFORMATION)是表示文档被正常的返回，但是由于正在使用的是文档副本所以某些响应头信息可能不正确。这是 HTTP 1.1中新加入的。\n  204 (No Content/无内容)\n在并没有新文档的情况下，204 (SC_NO_CONTENT)确保浏览器继续显示先前的文档。这各状态码对于用户周期性的重载某一页非常有用，并且你可以确定先前的页面是否已经更新。例如，某个servlet可能作如下操作：\n1 2 3 4 5 6 7 8 9 10 11  int pageVersion =Integer.parseInt(request.getParameter(\"pageVersion\")); if (pageVersion \u003e;= currentVersion) { response.setStatus(response.SC_NO_CONTENT); } else { ​ // Create regular page  }   但是，这种方法对通过刷新响应头信息或等价的HTML标记自动重载的页面起作用，因为它会返回一个204状态码停止以后的重载。但基于JavaScript脚本的自动重载在这种情况下仍然需要能够起作用。可以阅读本书7.2 ( HTTP 1.1 Response Headers and Their Meaning/HTTP 1.1响应头信息以及他们的意义)部分的详细讨论。\n  205 (Reset Content/重置内容)\n重置内容205 (SC_RESET_CONTENT)的意思是虽然没有新文档但浏览器要重置文档显示。这个状态码用于强迫浏览器清除表单域。这是 HTTP 1.1中新加入的。\n  206 (Partial Content/局部内容)\n206 (SC_PARTIAL_CONTENT)是在服务器完成了一个包含Range头信息的局部请求时被发送的。这是 HTTP 1.1中新加入的。\n  300 (Multiple Choices/多重选择)\n300 (SC_MULTIPLE_CHOICES)表示被请求的文档可以在多个地方找到，并将在返回的文档中列出来。如果服务器有首选设置，首选项将会被列于定位响应头信息中。\n  301 (Moved Permanently)\n301 (SC_MOVED_PERMANENTLY)状态是指所请求的文档在别的地方；文档新的URL会在定位响应头信息中给出。浏览器会自动连接到新的URL。\n  302 (Found/找到)\n与301有些类似，只是定位头信息中所给的URL应被理解为临时交换地址而不是永久的。注意：在 HTTP 1.0中，消息是临时移动(Moved Temporarily)的而不是被找到，因此HttpServletResponse中的常量是SC_MOVED_TEMPORARILY不是我们以为的SC_FOUND。\n Notice 代表状态码302的常量是SC_MOVED_TEMPORARILY而不是SC_FOUND。\n状态码302是非常有用的因为浏览器自动连接在定为响应头信息中给出的新URL。这非常有用，而且为此有一个专门的方法——sendRedirect。使用response.sendRedirect(url)比调用response.setStatus(response.SC_MOVED_TEMPORARILY)和response.setHeader(\"Location\", url)多几个好处。首先，response.sendRedirect(url)方法明显要简单和容易。第二，servlet自动建立一页保存这一连接以提供给那些不能自动转向的浏览器显示。最后，在servlet 2.2版本（J2EE中的版本）中，sendRedirect能够处理相对路径，自动转换为绝对路径。但是你只能在2.1版本中使用绝对路径。\n如果你将用户转向到站点的另一页中，你要用 HttpServletResponse 中的 encodeURL 方法传送URL。这么做可预防不断使用基于URL重写的会话跟踪的情况。URL重写是一种在你的网站跟踪不使用 cookies 的用户的方法。这是通过在每一个URL尾部附加路径信息实现的，但是 servlet 会话跟踪API会自动的注意这些细节。会话跟踪在第九章讨论，并且养成使用 encodeURL 的习惯会使以后添加会话跟踪的功能更容易很多。\n  核心技巧\n如果你将用户转向到你的站点的其他页面，用 response.sendRedirect(response.encodeURL(url)) 的方式事先计划好会话跟踪(session tracking)要比只是调用 response.sendRedirect(url) 好的多。\n这个状态码有时可以与301交换使用。例如，如果你错误的访问了http://www.talentdigger.cn/home/link.php?url=aG9zdC9%2BdXNlcg%3D%3D（路径信息不完整），有些服务器就会回复301状态码而有些则回复302。从技术上说，如果最初的请求是GET浏览器只是被假定自动转向。如果想了解更多细节，请看状态码307的讨论。\n   303 (See Other/参见其他信息)\n这个状态码和 301、302 相似，只是如果最初的请求是 POST，那么新文档（在定位头信息中给出）药用 GET 找回。这个状态码是新加入 HTTP 1.1中的。\n  304 (Not Modified/为修正)\n当客户端有一个缓存的文档，通过提供一个 If-Modified-Since 头信息可指出客户端只希望文档在指定日期之后有所修改时才会重载此文档，用这种方式可以进行有条件的请求。304 (SC_NOT_MODIFIED)是指缓冲的版本已经被更新并且客户端应刷新文档。另外，服务器将返回请求的文档及状态码 200。servlet一般情况下不会直接设置这个状态码。它们会实现getLastModified方法并根据修正日期让默认服务方法处理有条件的请求。这个方法的例程已在2.8部分(An Example Using Servlet Initialization and Page Modification Dates/一个使用servlet初始化和页面修正日期的例子)给出。\n  305 (Use Proxy/使用代理)\n305 (SC_USE_PROXY)表示所请求的文档要通过定位头信息中的代理服务器获得。这个状态码是新加入 HTTP 1.1中的。\n  307 (Temporary Redirect/临时重定向)\n浏览器处理307状态的规则与302相同。307状态被加入到 HTTP 1.1中是由于许多浏览器在收到302响应时即使是原始消息为POST的情况下仍然执行了错误的转向。只有在收到303响应时才假定浏览器会在POST请求时重定向。添加这个新的状态码的目的很明确：在响应为303时按照GET和POST请求转向；而在307响应时则按照GET请求转向而不是POST请求。注意：由于某些原因在HttpServletResponse中还没有与这个状态对应的常量。该状态码是新加入HTTP 1.1中的。\n 注意\n在 HttpServletResponse 中没有 SC_TEMPORARY_REDIRECT 常量，所以你只能显示的使用307状态码。\n   400 (Bad Request/错误请求)\n400 (SC_BAD_REQUEST)指出客户端请求中的语法错误。\n  401 (Unauthorized/未授权)\n401 (SC_UNAUTHORIZED)表示客户端在授权头信息中没有有效的身份信息时访问受到密码保护的页面。这个响应必须包含一个WWW-Authenticate的授权信息头。例如，在本书4.5部分中的“Restricting Access to Web Pages./限制访问Web页。”\n  403 (Forbidden/禁止)\n403 (SC_FORBIDDEN)的意思是除非拥有授权否则服务器拒绝提供所请求的资源。这个状态经常会由于服务器上的损坏文件或目录许可而引起。\n  404 (Not Found/未找到)\n404 (SC_NOT_FOUND)状态每个网络程序员可能都遇到过，他告诉客户端所给的地址无法找到任何资源。它是表示“没有所访问页面”的标准方式。这个状态码是常用的响应并且在HttpServletResponse类中有专门的方法实现它：sendError(\"message\")。相对于setStatus使用sendError得好处是：服务器会自动生成一个错误页来显示错误信息。但是，Internet Explorer 5浏览器却默认忽略你发挥的错误页面并显示其自定义的错误提示页面，虽然微软这么做违反了 HTTP 规范。要关闭此功能，在工具菜单里，选择Internet选项，进入高级标签页，并确认“显示友好的 HTTP 错误信息”选项（在我的浏览器中是倒数第8各选项）没有被选。但是很少有用户知道此选项，因此这个特性被IE5隐藏了起来使用户无法看到你所返回给用户的信息。而其他主流浏览器及IE4都完全的显示服务器生成的错误提示页面。可以参考图6-3及6-4中的例子。\n 核心警告\n默认情况下，IE5忽略服务端生成的错误提示页面。\n   405 (Method Not Allowed/方法未允许)\n405 (SC_METHOD_NOT_ALLOWED)指出请求方法(GET, POST, HEAD, PUT, DELETE, 等)对某些特定的资源不允许使用。该状态码是新加入 HTTP 1.1中的。\n  406 (Not Acceptable/无法访问)\n406 (SC_NOT_ACCEPTABLE)表示请求资源的MIME类型与客户端中Accept头信息中指定的类型不一致。见本书7.2部分中的表7.1(HTTP 1.1 Response Headers and Their Meaning/HTTP 1.1响应头信息以及他们的意义)中对MIME类型的介绍。406是新加入 HTTP 1.1中的。\n  407 (Proxy Authentication Required/代理服务器认证要求)\n407 (SC_PROXY_AUTHENTICATION_REQUIRED)与401状态有些相似，只是这个状态用于代理服务器。该状态指出客户端必须通过代理服务器的认证。代理服务器返回一个Proxy-Authenticate响应头信息给客户端，这会引起客户端使用带有Proxy-Authorization请求的头信息重新连接。该状态码是新加入 HTTP 1.1中的。\n  408 (Request Timeout/请求超时)\n408 (SC_REQUEST_TIMEOUT)是指服务端等待客户端发送请求的时间过长。该状态码是新加入 HTTP 1.1中的。\n  409 (Conflict/冲突)\n该状态通常与PUT请求一同使用，409 (SC_CONFLICT)状态常被用于试图上传版本不正确的文件时。该状态码是新加入 HTTP 1.1中的。\n  410 (Gone/已经不存在)\n410 (SC_GONE)告诉客户端所请求的文档已经不存在并且没有更新的地址。410状态不同于404，410是在指导文档已被移走的情况下使用，而404则用于未知原因的无法访问。该状态码是新加入 HTTP 1.1中的。\n  411 (Length Required/需要数据长度)\n411 (SC_LENGTH_REQUIRED)表示服务器不能处理请求（假设为带有附件的POST请求），除非客户端发送Content-Length头信息指出发送给服务器的数据的大小。该状态是新加入 HTTP 1.1的。\n  412 (Precondition Failed/先决条件错误)\n412 (SC_PRECONDITION_FAILED)状态指出请求头信息中的某些先决条件是错误的。该状态是新加入 HTTP 1.1的。\n  413 (Request Entity Too Large/请求实体过大)\n413 (SC_REQUEST_ENTITY_TOO_LARGE)告诉客户端现在所请求的文档比服务器现在想要处理的要大。如果服务器认为能够过一段时间处理，则会包含一个Retry-After的响应头信息。该状态是新加入 HTTP 1.1的。\n  414 (Request URI Too Long/请求URI过长)\n414 (SC_REQUEST_URI_TOO_LONG)状态用于在URI过长的情况时。这里所指的“URI”是指URL中主机、域名及端口号之后的内容。例如：在URL--http://www.y2k-disaster.com:8080/we/look/silly/now/中URI是指/we/look/silly/now/。该状态是新加入 HTTP 1.1的。\n  415 (Unsupported Media Type/不支持的媒体格式)\n415 (SC_UNSUPPORTED_MEDIA_TYPE)意味着请求所带的附件的格式类型服务器不知道如何处理。该状态是新加入 HTTP 1.1的。\n  416 (Requested Range Not Satisfiable/请求范围无法满足)\n416表示客户端包含了一个服务器无法满足的Range头信息的请求。该状态是新加入 HTTP 1.1的。奇怪的是，在servlet 2.1版本API的HttpServletResponse中并没有相应的常量代表该状态。\n 注意\n在servlet 2.1的规范中，类HttpServletResponse并没有SC_REQUESTED_RANGE_NOT_SATISFIABLE 这样的常量，所以你只能直接使用416。在servlet 2.2版本之后都包含了此常量。\n   417 (Expectation Failed/期望失败)\n如果服务器得到一个带有100-continue值的Expect请求头信息，这是指客户端正在询问是否可以在后面的请求中发送附件。在这种情况下，服务器也会用该状态(417)告诉浏览器服务器不接收该附件或用100 (SC_CONTINUE)状态告诉客户端可以继续发送附件。该状态是新加入 HTTP 1.1的。\n  500 (Internal Server Error/内部服务器错误)\n500 (SC_INTERNAL_SERVER_ERROR) 是常用的“服务器错误”状态。该状态经常由CGI程序引起也可能（但愿不会如此！）由无法正常运行的或返回头信息格式不正确的servlet引起。\n  501 (Not Implemented/未实现)\n501 (SC_NOT_IMPLEMENTED)状态告诉客户端服务器不支持请求中要求的功能。例如，客户端执行了如PUT这样的服务器并不支持的命令。\n  502 (Bad Gateway/错误的网关)\n502 (SC_BAD_GATEWAY)被用于充当代理或网关的服务器；该状态指出接收服务器接收到远端服务器的错误响应。\n  503 (Service Unavailable/服务无法获得)\n状态码503 (SC_SERVICE_UNAVAILABLE)表示服务器由于在维护或已经超载而无法响应。例如，如果某些线程或数据库连接池已经没有空闲则servlet会返回这个头信息。服务器可提供一个Retry-After头信息告诉客户端什么时候可以在试一次。\n  504 (Gateway Timeout/网关超时)\n该状态也用于充当代理或网关的服务器；它指出接收服务器没有从远端服务器得到及时的响应。该状态是新加入 HTTP 1.1的。\n  505 (HTTP Version Not Supported/不支持的 HTTP 版本)\n505 (SC_HTTP_VERSION_NOT_SUPPORTED)状态码是说服务器并不支持在请求中所标明 HTTP 版本。该状态是新加入 HTTP 1.1的。\n  ","description":"","tags":["http"],"title":"HTTP 协议状态码分类及解释","uri":"/blog/posts/classification-and-interpretation-of-http-protocol-status-codes/"},{"categories":null,"content":"入门 VSCode 插件开发 [toc]\n核心组件  Electron Monaco Editor Language Server Protocol Debug Adapter Protocol  Electorn (formerly Atom Shell)   基于 Node.js（作为后端）和 Chromium（作为前端)\n  使用 HTML, CSS 和 JavaScript 开发跨平台桌面GUI应用程序\n  使用者：Atom, Skype, GitHub Desktop, Slack, Microsoft Teams …\n  Github传送门\nMonaca Editor   基于浏览器的代码编辑器：IntelliSense，代码验证，语法高亮，文件比较 …\n  支持主流浏览器：IE 11, Edge, Chrome, Firefox, Safari 和 Opera\n  使用者：Gitee Web IDE, Cloud Studio, Eclipse Che, Eclipse Theia, Azure DevOps (原为 Visual Studio Team Services), OneDrive, Edge Dev Tools\n  GitHub传送门\nLanguage Server Protocol (LSP)   它是 Editor/IDE 与语言服务器之间的一种协议，可以让不同的 Editor/IDE 方便嵌入各种程序语言，允许开发人员在最喜爱的工具中使用各种语言来撰写程序。\n  支持 LSP 的开发工具: Eclipse IDE, Eclipse Theia, Atom, Sublime Text, Emacs\n  GitHub传送门\nDebug Adapter Protocol (DAP)   DAP 与 LSP 的目的类似，DAP 把 Editor/IDE 与 不同语言的 debugger 解耦，极大地方便了 Editor/IDE 与其他 Debugger 的集成。\n  支持 DAP 的开发工具: Eclipse IDE, Eclipse Theia, Emacs, Vim\n  GitHub传送门\n插件开发流程 开发环境   Visual Studio Code\n  Node.js\nnpm -v 查看是否安装成功\n  Yeoman and VS Code Extension generator:\nnpm install -g yo generator-code\n  插件类型   Themes\n  Snippets\n  Formatters\n  Linters\n  Debuggers\n  Programming Languages\n  Keymaps\n  SCM Provides\n  Extensions Packs\n  Others\n  如何搭建工程  yo code 选择你搭建项目的类型 是否导入相关资源 选择名字  e.g. Color Thems e.g. Code Snippet VSCode 界面功能拓展  Workbench Editor area  Workbench Editor Area  Codelens Decoration Gutter Hover Context Menu  e.g. Translator Extension ","description":"","tags":["vscode"],"title":"VSCode 插件开发入门","uri":"/blog/posts/getting-started-with-vscode-plugin-development/"},{"categories":["Java"],"content":"ArrayList简介 　ArrayList 的底层是数组队列，相当于动态数组。与 Java 中的数组相比，它的容量能动态增长。在添加大量元素前，应用程序可以使用 ensureCapacity 操作来增加 ArrayList 实例的容量。这可以减少递增式再分配的数量。 它继承于 AbstractList，实现了 List, RandomAccess, Cloneable, java.io.Serializable 这些接口。 - ArrayList 继承了AbstractList，实现了List。它是一个数组队列，提供了相关的添加、删除、修改、遍历等功能。 - ArrayList 实现了RandomAccess 接口。 RandomAccess 是一个标志接口，表明实现这个这个接口的 List 集合是支持快速随机访问的。在 ArrayList 中，我们即可以通过元素的序号快速获取元素对象，这就是快速随机访问。 - ArrayList 实现了Cloneable 接口。即覆盖了函数 clone()，能被克隆。 - ArrayList 实现java.io.Serializable 接口。这意味着ArrayList支持序列化，能通过序列化去传输。\n　和 Vector 不同，**ArrayList 中的操作不是线程安全的！**所以，建议在单线程中才使用 ArrayList，而在多线程中可以选择 Vector 或者  CopyOnWriteArrayList。 ArrayList核心源码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500  package java.util; import java.util.function.Consumer; import java.util.function.Predicate; import java.util.function.UnaryOperator; public class ArrayList\u003cE\u003e extends AbstractList\u003cE\u003e implements List\u003cE\u003e, RandomAccess, Cloneable, java.io.Serializable { private static final long serialVersionUID = 8683452581122892189L; /** * 默认初始容量大小 */ private static final int DEFAULT_CAPACITY = 10; /** * 空数组（用于空实例）。 */ private static final Object[] EMPTY_ELEMENTDATA = {}; //用于默认大小空实例的共享空数组实例。  //我们把它从EMPTY_ELEMENTDATA数组中区分出来，以知道在添加第一个元素时容量需要增加多少。  private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {}; /** * 保存ArrayList数据的数组 */ transient Object[] elementData; // non-private to simplify nested class access  /** * ArrayList 所包含的元素个数 */ private int size; /** * 带初始容量参数的构造函数。（用户自己指定容量） */ public ArrayList(int initialCapacity) { if (initialCapacity \u003e 0) { //创建initialCapacity大小的数组  this.elementData = new Object[initialCapacity]; } else if (initialCapacity == 0) { //创建空数组  this.elementData = EMPTY_ELEMENTDATA; } else { throw new IllegalArgumentException(\"Illegal Capacity: \"+ initialCapacity); } } /** *默认构造函数，DEFAULTCAPACITY_EMPTY_ELEMENTDATA 为0.初始化为10，也就是说初始其实是空数组 当添加第一个元素的时候数组容量才变成10 */ public ArrayList() { this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; } /** * 构造一个包含指定集合的元素的列表，按照它们由集合的迭代器返回的顺序。 */ public ArrayList(Collection\u003c? extends E\u003e c) { //  elementData = c.toArray(); //如果指定集合元素个数不为0  if ((size = elementData.length) != 0) { // c.toArray 可能返回的不是Object类型的数组所以加上下面的语句用于判断，  //这里用到了反射里面的getClass()方法  if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); } else { // 用空数组代替  this.elementData = EMPTY_ELEMENTDATA; } } /** * 修改这个ArrayList实例的容量是列表的当前大小。 应用程序可以使用此操作来最小化ArrayList实例的存储。 */ public void trimToSize() { modCount++; if (size \u003c elementData.length) { elementData = (size == 0) ? EMPTY_ELEMENTDATA : Arrays.copyOf(elementData, size); } } //下面是ArrayList的扩容机制 //ArrayList的扩容机制提高了性能，如果每次只扩充一个， //那么频繁的插入会导致频繁的拷贝，降低性能，而ArrayList的扩容机制避免了这种情况。  /** * 如有必要，增加此ArrayList实例的容量，以确保它至少能容纳元素的数量 * @param minCapacity 所需的最小容量 */ public void ensureCapacity(int minCapacity) { int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) // any size if not default element table  ? 0 // larger than default for default empty table. It's already  // supposed to be at default size.  : DEFAULT_CAPACITY; if (minCapacity \u003e minExpand) { ensureExplicitCapacity(minCapacity); } } //得到最小扩容量  private void ensureCapacityInternal(int minCapacity) { if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) { // 获取默认的容量和传入参数的较大值  minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); } ensureExplicitCapacity(minCapacity); } //判断是否需要扩容  private void ensureExplicitCapacity(int minCapacity) { modCount++; // overflow-conscious code  if (minCapacity - elementData.length \u003e 0) //调用grow方法进行扩容，调用此方法代表已经开始扩容了  grow(minCapacity); } /** * 要分配的最大数组大小 */ private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; /** * ArrayList扩容的核心方法。 */ private void grow(int minCapacity) { // oldCapacity为旧容量，newCapacity为新容量  int oldCapacity = elementData.length; //将oldCapacity 右移一位，其效果相当于oldCapacity /2，  //我们知道位运算的速度远远快于整除运算，整句运算式的结果就是将新容量更新为旧容量的1.5倍，  int newCapacity = oldCapacity + (oldCapacity \u003e\u003e 1); //然后检查新容量是否大于最小需要容量，若还是小于最小需要容量，那么就把最小需要容量当作数组的新容量，  if (newCapacity - minCapacity \u003c 0) newCapacity = minCapacity; //再检查新容量是否超出了ArrayList所定义的最大容量，  //若超出了，则调用hugeCapacity()来比较minCapacity和 MAX_ARRAY_SIZE，  //如果minCapacity大于MAX_ARRAY_SIZE，则新容量则为Interger.MAX_VALUE，否则，新容量大小则为 MAX_ARRAY_SIZE。  if (newCapacity - MAX_ARRAY_SIZE \u003e 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win:  elementData = Arrays.copyOf(elementData, newCapacity); } //比较minCapacity和 MAX_ARRAY_SIZE  private static int hugeCapacity(int minCapacity) { if (minCapacity \u003c 0) // overflow  throw new OutOfMemoryError(); return (minCapacity \u003e MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; } /** *返回此列表中的元素数。 */ public int size() { return size; } /** * 如果此列表不包含元素，则返回 true 。 */ public boolean isEmpty() { //注意=和==的区别  return size == 0; } /** * 如果此列表包含指定的元素，则返回true 。 */ public boolean contains(Object o) { //indexOf()方法：返回此列表中指定元素的首次出现的索引，如果此列表不包含此元素，则为-1  return indexOf(o) \u003e= 0; } /** *返回此列表中指定元素的首次出现的索引，如果此列表不包含此元素，则为-1 */ public int indexOf(Object o) { if (o == null) { for (int i = 0; i \u003c size; i++) if (elementData[i]==null) return i; } else { for (int i = 0; i \u003c size; i++) //equals()方法比较  if (o.equals(elementData[i])) return i; } return -1; } /** * 返回此列表中指定元素的最后一次出现的索引，如果此列表不包含元素，则返回-1。. */ public int lastIndexOf(Object o) { if (o == null) { for (int i = size-1; i \u003e= 0; i--) if (elementData[i]==null) return i; } else { for (int i = size-1; i \u003e= 0; i--) if (o.equals(elementData[i])) return i; } return -1; } /** * 返回此ArrayList实例的浅拷贝。 （元素本身不被复制。） */ public Object clone() { try { ArrayList\u003c?\u003e v = (ArrayList\u003c?\u003e) super.clone(); //Arrays.copyOf功能是实现数组的复制，返回复制后的数组。参数是被复制的数组和复制的长度  v.elementData = Arrays.copyOf(elementData, size); v.modCount = 0; return v; } catch (CloneNotSupportedException e) { // 这不应该发生，因为我们是可以克隆的  throw new InternalError(e); } } /** *以正确的顺序（从第一个到最后一个元素）返回一个包含此列表中所有元素的数组。 *返回的数组将是“安全的”，因为该列表不保留对它的引用。 （换句话说，这个方法必须分配一个新的数组）。 *因此，调用者可以自由地修改返回的数组。 此方法充当基于阵列和基于集合的API之间的桥梁。 */ public Object[] toArray() { return Arrays.copyOf(elementData, size); } /** * 以正确的顺序返回一个包含此列表中所有元素的数组（从第一个到最后一个元素）; *返回的数组的运行时类型是指定数组的运行时类型。 如果列表适合指定的数组，则返回其中。 *否则，将为指定数组的运行时类型和此列表的大小分配一个新数组。 *如果列表适用于指定的数组，其余空间（即数组的列表数量多于此元素），则紧跟在集合结束后的数组中的元素设置为null 。 *（这仅在调用者知道列表不包含任何空元素的情况下才能确定列表的长度。） */ @SuppressWarnings(\"unchecked\") public \u003cT\u003e T[] toArray(T[] a) { if (a.length \u003c size) // 新建一个运行时类型的数组，但是ArrayList数组的内容  return (T[]) Arrays.copyOf(elementData, size, a.getClass()); //调用System提供的arraycopy()方法实现数组之间的复制  System.arraycopy(elementData, 0, a, 0, size); if (a.length \u003e size) a[size] = null; return a; } // Positional Access Operations  @SuppressWarnings(\"unchecked\") E elementData(int index) { return (E) elementData[index]; } /** * 返回此列表中指定位置的元素。 */ public E get(int index) { rangeCheck(index); return elementData(index); } /** * 用指定的元素替换此列表中指定位置的元素。 */ public E set(int index, E element) { //对index进行界限检查  rangeCheck(index); E oldValue = elementData(index); elementData[index] = element; //返回原来在这个位置的元素  return oldValue; } /** * 将指定的元素追加到此列表的末尾。 */ public boolean add(E e) { ensureCapacityInternal(size + 1); // Increments modCount!!  //这里看到ArrayList添加元素的实质就相当于为数组赋值  elementData[size++] = e; return true; } /** * 在此列表中的指定位置插入指定的元素。 *先调用 rangeCheckForAdd 对index进行界限检查；然后调用 ensureCapacityInternal 方法保证capacity足够大； *再将从index开始之后的所有成员后移一个位置；将element插入index位置；最后size加1。 */ public void add(int index, E element) { rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!!  //arraycopy()这个实现数组之间复制的方法一定要看一下，下面就用到了arraycopy()方法实现数组自己复制自己  System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++; } /** * 删除该列表中指定位置的元素。 将任何后续元素移动到左侧（从其索引中减去一个元素）。 */ public E remove(int index) { rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved \u003e 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work  //从列表中删除的元素  return oldValue; } /** * 从列表中删除指定元素的第一个出现（如果存在）。 如果列表不包含该元素，则它不会更改。 *返回true，如果此列表包含指定的元素 */ public boolean remove(Object o) { if (o == null) { for (int index = 0; index \u003c size; index++) if (elementData[index] == null) { fastRemove(index); return true; } } else { for (int index = 0; index \u003c size; index++) if (o.equals(elementData[index])) { fastRemove(index); return true; } } return false; } /* * Private remove method that skips bounds checking and does not * return the value removed. */ private void fastRemove(int index) { modCount++; int numMoved = size - index - 1; if (numMoved \u003e 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work  } /** * 从列表中删除所有元素。 */ public void clear() { modCount++; // 把数组中所有的元素的值设为null  for (int i = 0; i \u003c size; i++) elementData[i] = null; size = 0; } /** * 按指定集合的Iterator返回的顺序将指定集合中的所有元素追加到此列表的末尾。 */ public boolean addAll(Collection\u003c? extends E\u003e c) { Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount  System.arraycopy(a, 0, elementData, size, numNew); size += numNew; return numNew != 0; } /** * 将指定集合中的所有元素插入到此列表中，从指定的位置开始。 */ public boolean addAll(int index, Collection\u003c? extends E\u003e c) { rangeCheckForAdd(index); Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount  int numMoved = size - index; if (numMoved \u003e 0) System.arraycopy(elementData, index, elementData, index + numNew, numMoved); System.arraycopy(a, 0, elementData, index, numNew); size += numNew; return numNew != 0; } /** * 从此列表中删除所有索引为fromIndex （含）和toIndex之间的元素。 *将任何后续元素移动到左侧（减少其索引）。 */ protected void removeRange(int fromIndex, int toIndex) { modCount++; int numMoved = size - toIndex; System.arraycopy(elementData, toIndex, elementData, fromIndex, numMoved); // clear to let GC do its work  int newSize = size - (toIndex-fromIndex); for (int i = newSize; i \u003c size; i++) { elementData[i] = null; } size = newSize; } /** * 检查给定的索引是否在范围内。 */ private void rangeCheck(int index) { if (index \u003e= size) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); } /** * add和addAll使用的rangeCheck的一个版本 */ private void rangeCheckForAdd(int index) { if (index \u003e size || index \u003c 0) throw new IndexOutOfBoundsException(outOfBoundsMsg(index)); } /** * 返回IndexOutOfBoundsException细节信息 */ private String outOfBoundsMsg(int index) { return \"Index: \"+index+\", Size: \"+size; } /** * 从此列表中删除指定集合中包含的所有元素。 */ public boolean removeAll(Collection\u003c?\u003e c) { Objects.requireNonNull(c); //如果此列表被修改则返回true  return batchRemove(c, false); } /** * 仅保留此列表中包含在指定集合中的元素。 *换句话说，从此列表中删除其中不包含在指定集合中的所有元素。 */ public boolean retainAll(Collection\u003c?\u003e c) { Objects.requireNonNull(c); return batchRemove(c, true); } /** * 从列表中的指定位置开始，返回列表中的元素（按正确顺序）的列表迭代器。 *指定的索引表示初始调用将返回的第一个元素为next 。 初始调用previous将返回指定索引减1的元素。 *返回的列表迭代器是fail-fast 。 */ public ListIterator\u003cE\u003e listIterator(int index) { if (index \u003c 0 || index \u003e size) throw new IndexOutOfBoundsException(\"Index: \"+index); return new ListItr(index); } /** *返回列表中的列表迭代器（按适当的顺序）。 *返回的列表迭代器是fail-fast 。 */ public ListIterator\u003cE\u003e listIterator() { return new ListItr(0); } /** *以正确的顺序返回该列表中的元素的迭代器。 *返回的迭代器是fail-fast 。 */ public Iterator\u003cE\u003e iterator() { return new Itr(); }   ArrayList源码分析 System.arraycopy()和Arrays.copyOf()方法 　通过上面源码我们发现这两个实现数组复制的方法被广泛使用而且很多地方都特别巧妙。比如下面add(int index, E element)方法就很巧妙的用到了arraycopy()方法让数组自己复制自己实现让index开始之后的所有成员后移一个位置:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  /** * 在此列表中的指定位置插入指定的元素。 *先调用 rangeCheckForAdd 对index进行界限检查；然后调用 ensureCapacityInternal 方法保证capacity足够大； *再将从index开始之后的所有成员后移一个位置；将element插入index位置；最后size加1。 */ public void add(int index, E element) { rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!!  //arraycopy()方法实现数组自己复制自己  //elementData:源数组;index:源数组中的起始位置;elementData：目标数组；index + 1：目标数组中的起始位置； size - index：要复制的数组元素的数量；  System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++; }   又如toArray()方法中用到了copyOf()方法\n1 2 3 4 5 6 7 8 9 10  /** *以正确的顺序（从第一个到最后一个元素）返回一个包含此列表中所有元素的数组。 *返回的数组将是“安全的”，因为该列表不保留对它的引用。 （换句话说，这个方法必须分配一个新的数组）。 *因此，调用者可以自由地修改返回的数组。 此方法充当基于阵列和基于集合的API之间的桥梁。 */ public Object[] toArray() { //elementData：要复制的数组；size：要复制的长度  return Arrays.copyOf(elementData, size); }   两者联系与区别 联系： 看两者源代码可以发现copyOf()内部调用了System.arraycopy()方法 区别：\n arraycopy()需要目标数组，将原数组拷贝到你自己定义的数组里，而且可以选择拷贝的起点和长度以及放入新数组中的位置 copyOf()是系统自动在内部新建一个数组，并返回该数组。  ArrayList 核心扩容技术 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  //下面是ArrayList的扩容机制 //ArrayList的扩容机制提高了性能，如果每次只扩充一个， //那么频繁的插入会导致频繁的拷贝，降低性能，而ArrayList的扩容机制避免了这种情况。  /** * 如有必要，增加此ArrayList实例的容量，以确保它至少能容纳元素的数量 * @param minCapacity 所需的最小容量 */ public void ensureCapacity(int minCapacity) { int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) // any size if not default element table  ? 0 // larger than default for default empty table. It's already  // supposed to be at default size.  : DEFAULT_CAPACITY; if (minCapacity \u003e minExpand) { ensureExplicitCapacity(minCapacity); } } //得到最小扩容量  private void ensureCapacityInternal(int minCapacity) { if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) { // 获取默认的容量和传入参数的较大值  minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); } ensureExplicitCapacity(minCapacity); } //判断是否需要扩容,上面两个方法都要调用  private void ensureExplicitCapacity(int minCapacity) { modCount++; // 如果说minCapacity也就是所需的最小容量大于保存ArrayList数据的数组的长度的话，就需要调用grow(minCapacity)方法扩容。  //这个minCapacity到底为多少呢？举个例子在添加元素(add)方法中这个minCapacity的大小就为现在数组的长度加1  if (minCapacity - elementData.length \u003e 0) //调用grow方法进行扩容，调用此方法代表已经开始扩容了  grow(minCapacity); }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  /** * ArrayList扩容的核心方法。 */ private void grow(int minCapacity) { //elementData为保存ArrayList数据的数组  ///elementData.length求数组长度elementData.size是求数组中的元素个数  // oldCapacity为旧容量，newCapacity为新容量  int oldCapacity = elementData.length; //将oldCapacity 右移一位，其效果相当于oldCapacity /2，  //我们知道位运算的速度远远快于整除运算，整句运算式的结果就是将新容量更新为旧容量的1.5倍，  int newCapacity = oldCapacity + (oldCapacity \u003e\u003e 1); //然后检查新容量是否大于最小需要容量，若还是小于最小需要容量，那么就把最小需要容量当作数组的新容量，  if (newCapacity - minCapacity \u003c 0) newCapacity = minCapacity; //再检查新容量是否超出了ArrayList所定义的最大容量，  //若超出了，则调用hugeCapacity()来比较minCapacity和 MAX_ARRAY_SIZE，  //如果minCapacity大于MAX_ARRAY_SIZE，则新容量则为Interger.MAX_VALUE，否则，新容量大小则为 MAX_ARRAY_SIZE。  if (newCapacity - MAX_ARRAY_SIZE \u003e 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win:  elementData = Arrays.copyOf(elementData, newCapacity); }   　扩容机制代码已经做了详细的解释。另外值得注意的是大家很容易忽略的一个运算符：移位运算符 简介：移位运算符就是在二进制的基础上对数字进行平移。按照平移的方向和填充数字的规则分为三种:\u003c\u003c(左移)、\u003e\u003e(带符号右移)和\u003e\u003e\u003e(无符号右移)。 作用：对于大数据的2进制运算,位移运算符比那些普通运算符的运算要快很多,因为程序仅仅移动一下而已,不去计算,这样提高了效率,节省了资源 比如这里：int newCapacity = oldCapacity + (oldCapacity \u003e\u003e 1); 右移一位相当于除2，右移n位相当于除以 2 的 n 次方。这里 oldCapacity 明显右移了1位所以相当于oldCapacity /2。\n另外需要注意的是：\n  java 中的length 属性是针对数组说的,比如说你声明了一个数组,想知道这个数组的长度则用到了 length 这个属性.\n  java 中的length()方法是针对字符串String说的,如果想看这个字符串的长度则用到 length()这个方法.\n  .java 中的size()方法是针对泛型集合说的,如果想看这个泛型有多少个元素,就调用此方法来查看!\n  内部类 1 2 3 4  (1)private class Itr implements Iterator\u003cE\u003e (2)private class ListItr extends Itr implements ListIterator\u003cE\u003e (3)private class SubList extends AbstractList\u003cE\u003e implements RandomAccess (4)static final class ArrayListSpliterator\u003cE\u003e implements Spliterator\u003cE\u003e   　ArrayList有四个内部类，其中的Itr是实现了Iterator接口，同时重写了里面的hasNext()，next()，remove()等方法；其中的ListItr继承Itr，实现了ListIterator接口，同时重写了hasPrevious()，nextIndex()，previousIndex()，previous()，set(E e)，**add(E e)**等方法，所以这也可以看出了 **Iterator和ListIterator的区别:**ListIterator在Iterator的基础上增加了添加对象，修改对象，逆向遍历等方法，这些是Iterator不能实现的。\nArrayList经典Demo 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69  package list; import java.util.ArrayList; import java.util.Iterator; public class ArrayListDemo { public static void main(String[] srgs){ ArrayList\u003cInteger\u003e arrayList = new ArrayList\u003cInteger\u003e(); System.out.printf(\"Before add:arrayList.size() = %d\\n\",arrayList.size()); arrayList.add(1); arrayList.add(3); arrayList.add(5); arrayList.add(7); arrayList.add(9); System.out.printf(\"After add:arrayList.size() = %d\\n\",arrayList.size()); System.out.println(\"Printing elements of arrayList\"); // 三种遍历方式打印元素  // 第一种：通过迭代器遍历  System.out.print(\"通过迭代器遍历:\"); Iterator\u003cInteger\u003e it = arrayList.iterator(); while(it.hasNext()){ System.out.print(it.next() + \" \"); } System.out.println(); // 第二种：通过索引值遍历  System.out.print(\"通过索引值遍历:\"); for(int i = 0; i \u003c arrayList.size(); i++){ System.out.print(arrayList.get(i) + \" \"); } System.out.println(); // 第三种：for循环遍历  System.out.print(\"for循环遍历:\"); for(Integer number : arrayList){ System.out.print(number + \" \"); } // toArray用法  // 第一种方式(最常用)  Integer[] integer = arrayList.toArray(new Integer[0]); // 第二种方式(容易理解)  Integer[] integer1 = new Integer[arrayList.size()]; arrayList.toArray(integer1); // 抛出异常，java不支持向下转型  //Integer[] integer2 = new Integer[arrayList.size()];  //integer2 = arrayList.toArray();  System.out.println(); // 在指定位置添加元素  arrayList.add(2,2); // 删除指定位置上的元素  arrayList.remove(2); // 删除指定元素  arrayList.remove((Object)3); // 判断arrayList是否包含5  System.out.println(\"ArrayList contains 5 is: \" + arrayList.contains(5)); // 清空ArrayList  arrayList.clear(); // 判断ArrayList是否为空  System.out.println(\"ArrayList is empty: \" + arrayList.isEmpty()); } }   ","description":"","tags":["array-list"],"title":"\u003cJava容器\u003e ArrayList","uri":"/blog/posts/java/arraylist/"},{"categories":["Java"],"content":"一 先从 ArrayList 的构造函数说起 ArrayList有三种方式来初始化，构造方法源码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48  /** * 默认初始容量大小 */ private static final int DEFAULT_CAPACITY = 10; private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {}; /** *默认构造函数，使用初始容量10构造一个空列表(无参数构造) */ public ArrayList() { this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; } /** * 带初始容量参数的构造函数。（用户自己指定容量） */ public ArrayList(int initialCapacity) { if (initialCapacity \u003e 0) {//初始容量大于0  //创建initialCapacity大小的数组  this.elementData = new Object[initialCapacity]; } else if (initialCapacity == 0) {//初始容量等于0  //创建空数组  this.elementData = EMPTY_ELEMENTDATA; } else {//初始容量小于0，抛出异常  throw new IllegalArgumentException(\"Illegal Capacity: \"+ initialCapacity); } } /** *构造包含指定collection元素的列表，这些元素利用该集合的迭代器按顺序返回 *如果指定的集合为null，throws NullPointerException。 */ public ArrayList(Collection\u003c? extends E\u003e c) { elementData = c.toArray(); if ((size = elementData.length) != 0) { // c.toArray might (incorrectly) not return Object[] (see 6260652)  if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); } else { // replace with empty array.  this.elementData = EMPTY_ELEMENTDATA; } }   细心的同学一定会发现 ：以无参数构造方法创建 ArrayList 时，实际上初始化赋值的是一个空数组。当真正对数组进行添加元素操作时，才真正分配容量。即向数组中添加第一个元素时，数组容量扩为10。 下面在我们分析 ArrayList 扩容时会讲到这一点内容！\n二 一步一步分析 ArrayList 扩容机制 这里以无参构造函数创建的 ArrayList 为例分析\n1. 先来看 add 方法 1 2 3 4 5 6 7 8 9 10  /** * 将指定的元素追加到此列表的末尾。 */ public boolean add(E e) { //添加元素之前，先调用ensureCapacityInternal方法  ensureCapacityInternal(size + 1); // Increments modCount!!  //这里看到ArrayList添加元素的实质就相当于为数组赋值  elementData[size++] = e; return true; }   2. 再来看看 ensureCapacityInternal() 方法 可以看到 add 方法 首先调用了ensureCapacityInternal(size + 1)\n1 2 3 4 5 6 7 8 9  //得到最小扩容量  private void ensureCapacityInternal(int minCapacity) { if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) { // 获取默认的容量和传入参数的较大值  minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); } ensureExplicitCapacity(minCapacity); }   当 要 add 进第1个元素时，minCapacity为1，在Math.max()方法比较后，minCapacity 为10。\n3. ensureExplicitCapacity() 方法 如果调用 ensureCapacityInternal() 方法就一定会进过（执行）这个方法，下面我们来研究一下这个方法的源码！\n1 2 3 4 5 6 7 8 9 10  //判断是否需要扩容  private void ensureExplicitCapacity(int minCapacity) { modCount++; // overflow-conscious code  if (minCapacity - elementData.length \u003e 0) //调用grow方法进行扩容，调用此方法代表已经开始扩容了  grow(minCapacity); }   我们来仔细分析一下：\n 当我们要 add 进第1个元素到 ArrayList 时，elementData.length 为0 （因为还是一个空的 list），因为执行了 ensureCapacityInternal() 方法 ，所以 minCapacity 此时为10。此时，minCapacity - elementData.length \u003e 0 成立，所以会进入 grow(minCapacity) 方法。 当add第2个元素时，minCapacity 为2，此时e lementData.length(容量)在添加第一个元素后扩容成 10 了。此时，minCapacity - elementData.length \u003e 0  不成立，所以不会进入 （执行）grow(minCapacity) 方法。 添加第3、4···到第10个元素时，依然不会执行grow方法，数组容量都为10。  直到添加第11个元素，minCapacity(为11)比elementData.length（为10）要大。进入grow方法进行扩容。\n4. grow() 方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  /** * 要分配的最大数组大小 */ private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; /** * ArrayList扩容的核心方法。 */ private void grow(int minCapacity) { // oldCapacity为旧容量，newCapacity为新容量  int oldCapacity = elementData.length; //将oldCapacity 右移一位，其效果相当于oldCapacity /2，  //我们知道位运算的速度远远快于整除运算，整句运算式的结果就是将新容量更新为旧容量的1.5倍，  int newCapacity = oldCapacity + (oldCapacity \u003e\u003e 1); //然后检查新容量是否大于最小需要容量，若还是小于最小需要容量，那么就把最小需要容量当作数组的新容量，  if (newCapacity - minCapacity \u003c 0) newCapacity = minCapacity; // 如果新容量大于 MAX_ARRAY_SIZE,进入(执行) `hugeCapacity()` 方法来比较 minCapacity 和 MAX_ARRAY_SIZE，  //如果minCapacity大于最大容量，则新容量则为`Integer.MAX_VALUE`，否则，新容量大小则为 MAX_ARRAY_SIZE 即为 `Integer.MAX_VALUE - 8`。  if (newCapacity - MAX_ARRAY_SIZE \u003e 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win:  elementData = Arrays.copyOf(elementData, newCapacity); }   int newCapacity = oldCapacity + (oldCapacity \u003e\u003e 1),所以 ArrayList 每次扩容之后容量都会变为原来的 1.5 倍！（JDK1.6版本以后） JDk1.6版本时，扩容之后容量为 1.5 倍+1！详情请参考源码\n \"\u003e\u003e\"（移位运算符）：\u003e\u003e1 右移一位相当于除2，右移n位相当于除以 2 的 n 次方。这里 oldCapacity 明显右移了1位所以相当于oldCapacity /2。对于大数据的2进制运算,位移运算符比那些普通运算符的运算要快很多,因为程序仅仅移动一下而已,不去计算,这样提高了效率,节省了资源  我们再来通过例子探究一下grow() 方法 ：\n 当add第1个元素时，oldCapacity 为0，经比较后第一个if判断成立，newCapacity = minCapacity(为10)。但是第二个if判断不会成立，即newCapacity 不比 MAX_ARRAY_SIZE大，则不会进入 hugeCapacity 方法。数组容量为10，add方法中 return true,size增为1。 当add第11个元素进入grow方法时，newCapacity为15，比minCapacity（为11）大，第一个if判断不成立。新容量没有大于数组最大size，不会进入hugeCapacity方法。数组容量扩为15，add方法中return true,size增为11。 以此类推······  这里补充一点比较重要，但是容易被忽视掉的知识点：\n java 中的 length 属性是针对数组说的,比如说你声明了一个数组,想知道这个数组的长度则用到了 length 这个属性. java 中的 length() 方法是针对字符串说的,如果想看这个字符串的长度则用到 length() 这个方法. java 中的 size() 方法是针对泛型集合说的,如果想看这个泛型有多少个元素,就调用此方法来查看!  5. hugeCapacity() 方法。 从上面 grow() 方法源码我们知道： 如果新容量大于 MAX_ARRAY_SIZE,进入(执行) hugeCapacity() 方法来比较 minCapacity 和 MAX_ARRAY_SIZE，如果minCapacity大于最大容量，则新容量则为Integer.MAX_VALUE，否则，新容量大小则为 MAX_ARRAY_SIZE 即为 Integer.MAX_VALUE - 8。\n1 2 3 4 5 6 7 8 9 10 11  private static int hugeCapacity(int minCapacity) { if (minCapacity \u003c 0) // overflow  throw new OutOfMemoryError(); //对minCapacity和MAX_ARRAY_SIZE进行比较  //若minCapacity大，将Integer.MAX_VALUE作为新数组的大小  //若MAX_ARRAY_SIZE大，将MAX_ARRAY_SIZE作为新数组的大小  //MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;  return (minCapacity \u003e MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; }   三 System.arraycopy() 和 Arrays.copyOf()方法 阅读源码的话，我们就会发现 ArrayList 中大量调用了这两个方法。比如：我们上面讲的扩容操作以及add(int index, E element)、toArray() 等方法中都用到了该方法！\n3.1 System.arraycopy() 方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  /** * 在此列表中的指定位置插入指定的元素。 *先调用 rangeCheckForAdd 对index进行界限检查；然后调用 ensureCapacityInternal 方法保证capacity足够大； *再将从index开始之后的所有成员后移一个位置；将element插入index位置；最后size加1。 */ public void add(int index, E element) { rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!!  //arraycopy()方法实现数组自己复制自己  //elementData:源数组;index:源数组中的起始位置;elementData：目标数组；index + 1：目标数组中的起始位置； size - index：要复制的数组元素的数量；  System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++; }   我们写一个简单的方法测试以下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  public class ArraycopyTest { public static void main(String[] args) { // TODO Auto-generated method stub \tint[] a = new int[10]; a[0] = 0; a[1] = 1; a[2] = 2; a[3] = 3; System.arraycopy(a, 2, a, 3, 3); a[2]=99; for (int i = 0; i \u003c a.length; i++) { System.out.println(a[i]); } } }   结果：\n0 1 99 2 3 0 0 0 0 0 3.2 Arrays.copyOf()方法 1 2 3 4 5 6 7  /** 以正确的顺序返回一个包含此列表中所有元素的数组（从第一个到最后一个元素）; 返回的数组的运行时类型是指定数组的运行时类型。 */ public Object[] toArray() { //elementData：要复制的数组；size：要复制的长度  return Arrays.copyOf(elementData, size); }   个人觉得使用 Arrays.copyOf()方法主要是为了给原有数组扩容，测试代码如下：\n1 2 3 4 5 6 7 8 9 10 11  public class ArrayscopyOfTest { public static void main(String[] args) { int[] a = new int[3]; a[0] = 0; a[1] = 1; a[2] = 2; int[] b = Arrays.copyOf(a, 10); System.out.println(\"b.length\"+b.length); } }   结果：\n10 3.3 两者联系和区别 联系：\n看两者源代码可以发现 copyOf() 内部实际调用了 System.arraycopy() 方法\n区别：\narraycopy() 需要目标数组，将原数组拷贝到你自己定义的数组里或者原数组，而且可以选择拷贝的起点和长度以及放入新数组中的位置 copyOf() 是系统自动在内部新建一个数组，并返回该数组。\n四 ensureCapacity方法 ArrayList 源码中有一个 ensureCapacity 方法不知道大家注意到没有，这个方法 ArrayList 内部没有被调用过，所以很显然是提供给用户调用的，那么这个方法有什么作用呢？\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  /** 如有必要，增加此 ArrayList 实例的容量，以确保它至少可以容纳由minimum capacity参数指定的元素数。 * * @param minCapacity 所需的最小容量 */ public void ensureCapacity(int minCapacity) { int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) // any size if not default element table  ? 0 // larger than default for default empty table. It's already  // supposed to be at default size.  : DEFAULT_CAPACITY; if (minCapacity \u003e minExpand) { ensureExplicitCapacity(minCapacity); } }   最好在 add 大量元素之前用 ensureCapacity 方法，以减少增量重新分配的次数\n我们通过下面的代码实际测试以下这个方法的效果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  public class EnsureCapacityTest { public static void main(String[] args) { ArrayList\u003cObject\u003e list = new ArrayList\u003cObject\u003e(); final int N = 10000000; long startTime = System.currentTimeMillis(); for (int i = 0; i \u003c N; i++) { list.add(i); } long endTime = System.currentTimeMillis(); System.out.println(\"使用ensureCapacity方法前：\"+(endTime - startTime)); list = new ArrayList\u003cObject\u003e(); long startTime1 = System.currentTimeMillis(); list.ensureCapacity(N); for (int i = 0; i \u003c N; i++) { list.add(i); } long endTime1 = System.currentTimeMillis(); System.out.println(\"使用ensureCapacity方法后：\"+(endTime1 - startTime1)); } }   运行结果：\n使用ensureCapacity方法前：4637 使用ensureCapacity方法后：241 通过运行结果，我们可以很明显的看出向 ArrayList 添加大量元素之前最好先使用ensureCapacity 方法，以减少增量重新分配的次数\n","description":"","tags":["array-list"],"title":"\u003cJava容器\u003e ArrayList扩容源码分析","uri":"/blog/posts/java/arraylist-grow/"},{"categories":["Java"],"content":" HashMap 简介 底层数据结构分析  JDK1.8之前 JDK1.8之后   HashMap源码分析  构造方法 put方法 get方法 resize方法   HashMap常用方法测试   感谢 changfubai 对本文的改进做出的贡献！\n HashMap 简介 HashMap 主要用来存放键值对，它基于哈希表的Map接口实现，是常用的Java集合之一。\nJDK1.8 之前 HashMap 由 数组+链表 组成的，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）.JDK1.8 以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）时，将链表转化为红黑树，以减少搜索时间。\n底层数据结构分析 JDK1.8之前 JDK1.8 之前 HashMap 底层是 数组和链表 结合在一起使用也就是 链表散列。HashMap 通过 key 的 hashCode 经过扰动函数处理过后得到 hash 值，然后通过 (n - 1) \u0026 hash 判断当前元素存放的位置（这里的 n 指的是数组的长度），如果当前位置存在元素的话，就判断该元素与要存入的元素的 hash 值以及 key 是否相同，如果相同的话，直接覆盖，不相同就通过拉链法解决冲突。\n所谓扰动函数指的就是 HashMap 的 hash 方法。使用 hash 方法也就是扰动函数是为了防止一些实现比较差的 hashCode() 方法 换句话说使用扰动函数之后可以减少碰撞。\nJDK 1.8 HashMap 的 hash 方法源码:\nJDK 1.8 的 hash方法 相比于 JDK 1.7 hash 方法更加简化，但是原理不变。\n1 2 3 4 5 6 7  static final int hash(Object key) { int h; // key.hashCode()：返回散列值也就是hashcode  // ^ ：按位异或  // \u003e\u003e\u003e:无符号右移，忽略符号位，空位都以0补齐  return (key == null) ? 0 : (h = key.hashCode()) ^ (h \u003e\u003e\u003e 16); }   对比一下 JDK1.7的 HashMap 的 hash 方法源码.\n1 2 3 4 5 6 7 8  static int hash(int h) { // This function ensures that hashCodes that differ only by  // constant multiples at each bit position have a bounded  // number of collisions (approximately 8 at default load factor).  h ^= (h \u003e\u003e\u003e 20) ^ (h \u003e\u003e\u003e 12); return h ^ (h \u003e\u003e\u003e 7) ^ (h \u003e\u003e\u003e 4); }   相比于 JDK1.8 的 hash 方法 ，JDK 1.7 的 hash 方法的性能会稍差一点点，因为毕竟扰动了 4 次。\n所谓 “拉链法” 就是：将链表和数组相结合。也就是说创建一个链表数组，数组中每一格就是一个链表。若遇到哈希冲突，则将冲突的值加到链表中即可。\nJDK1.8之后 相比于之前的版本，jdk1.8在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）时，将链表转化为红黑树，以减少搜索时间。\n类的属性：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  public class HashMap\u003cK,V\u003e extends AbstractMap\u003cK,V\u003e implements Map\u003cK,V\u003e, Cloneable, Serializable { // 序列号  private static final long serialVersionUID = 362498820763181265L; // 默认的初始容量是16  static final int DEFAULT_INITIAL_CAPACITY = 1 \u003c\u003c 4; // 最大容量  static final int MAXIMUM_CAPACITY = 1 \u003c\u003c 30; // 默认的填充因子  static final float DEFAULT_LOAD_FACTOR = 0.75f; // 当桶(bucket)上的结点数大于这个值时会转成红黑树  static final int TREEIFY_THRESHOLD = 8; // 当桶(bucket)上的结点数小于这个值时树转链表  static final int UNTREEIFY_THRESHOLD = 6; // 桶中结构转化为红黑树对应的table的最小大小  static final int MIN_TREEIFY_CAPACITY = 64; // 存储元素的数组，总是2的幂次倍  transient Node\u003ck,v\u003e[] table; // 存放具体元素的集  transient Set\u003cmap.entry\u003ck,v\u003e\u003e entrySet; // 存放元素的个数，注意这个不等于数组的长度。  transient int size; // 每次扩容和更改map结构的计数器  transient int modCount; // 临界值 当实际大小(容量*填充因子)超过临界值时，会进行扩容  int threshold; // 加载因子  final float loadFactor; }     loadFactor加载因子\nloadFactor加载因子是控制数组存放数据的疏密程度，loadFactor越趋近于1，那么 数组中存放的数据(entry)也就越多，也就越密，也就是会让链表的长度增加，loadFactor越小，也就是趋近于0，数组中存放的数据(entry)也就越少，也就越稀疏。\nloadFactor太大导致查找元素效率低，太小导致数组的利用率低，存放的数据会很分散。loadFactor的默认值为0.75f是官方给出的一个比较好的临界值。\n给定的默认容量为 16，负载因子为 0.75。Map 在使用过程中不断的往里面存放数据，当数量达到了 16 * 0.75 = 12 就需要将当前 16 的容量进行扩容，而扩容这个过程涉及到 rehash、复制数据等操作，所以非常消耗性能。\n  threshold\nthreshold = capacity * loadFactor，当Size\u003e=threshold的时候，那么就要考虑对数组的扩增了，也就是说，这个的意思就是 衡量数组是否需要扩增的一个标准。\n  Node节点类源码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  // 继承自 Map.Entry\u003cK,V\u003e static class Node\u003cK,V\u003e implements Map.Entry\u003cK,V\u003e { final int hash;// 哈希值，存放元素到hashmap中时用来与其他元素hash值比较  final K key;//键  V value;//值  // 指向下一个节点  Node\u003cK,V\u003e next; Node(int hash, K key, V value, Node\u003cK,V\u003e next) { this.hash = hash; this.key = key; this.value = value; this.next = next; } public final K getKey() { return key; } public final V getValue() { return value; } public final String toString() { return key + \"=\" + value; } // 重写hashCode()方法  public final int hashCode() { return Objects.hashCode(key) ^ Objects.hashCode(value); } public final V setValue(V newValue) { V oldValue = value; value = newValue; return oldValue; } // 重写 equals() 方法  public final boolean equals(Object o) { if (o == this) return true; if (o instanceof Map.Entry) { Map.Entry\u003c?,?\u003e e = (Map.Entry\u003c?,?\u003e)o; if (Objects.equals(key, e.getKey()) \u0026\u0026 Objects.equals(value, e.getValue())) return true; } return false; } }   树节点类源码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  static final class TreeNode\u003cK,V\u003e extends LinkedHashMap.Entry\u003cK,V\u003e { TreeNode\u003cK,V\u003e parent; // 父  TreeNode\u003cK,V\u003e left; // 左  TreeNode\u003cK,V\u003e right; // 右  TreeNode\u003cK,V\u003e prev; // needed to unlink next upon deletion  boolean red; // 判断颜色  TreeNode(int hash, K key, V val, Node\u003cK,V\u003e next) { super(hash, key, val, next); } // 返回根节点  final TreeNode\u003cK,V\u003e root() { for (TreeNode\u003cK,V\u003e r = this, p;;) { if ((p = r.parent) == null) return r; r = p; }   HashMap源码分析 构造方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  // 默认构造函数。  public HashMap() { this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted  } // 包含另一个“Map”的构造函数  public HashMap(Map\u003c? extends K, ? extends V\u003e m) { this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false);//下面会分析到这个方法  } // 指定“容量大小”的构造函数  public HashMap(int initialCapacity) { this(initialCapacity, DEFAULT_LOAD_FACTOR); } // 指定“容量大小”和“加载因子”的构造函数  public HashMap(int initialCapacity, float loadFactor) { if (initialCapacity \u003c 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); if (initialCapacity \u003e MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor \u003c= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity); }   putMapEntries方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  final void putMapEntries(Map\u003c? extends K, ? extends V\u003e m, boolean evict) { int s = m.size(); if (s \u003e 0) { // 判断table是否已经初始化  if (table == null) { // pre-size  // 未初始化，s为m的实际元素个数  float ft = ((float)s / loadFactor) + 1.0F; int t = ((ft \u003c (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); // 计算得到的t大于阈值，则初始化阈值  if (t \u003e threshold) threshold = tableSizeFor(t); } // 已初始化，并且m元素个数大于阈值，进行扩容处理  else if (s \u003e threshold) resize(); // 将m中的所有元素添加至HashMap中  for (Map.Entry\u003c? extends K, ? extends V\u003e e : m.entrySet()) { K key = e.getKey(); V value = e.getValue(); putVal(hash(key), key, value, false, evict); } } }   put方法 HashMap只提供了put用于添加元素，putVal方法只是给put方法调用的一个方法，并没有提供给用户使用。\n对putVal方法添加元素的分析如下：\n ①如果定位到的数组位置没有元素 就直接插入。 ②如果定位到的数组位置有元素就和要插入的key比较，如果key相同就直接覆盖，如果key不相同，就判断p是否是一个树节点，如果是就调用e = ((TreeNode\u003cK,V\u003e)p).putTreeVal(this, tab, hash, key, value)将元素添加进入。如果不是就遍历链表插入。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71  public V put(K key, V value) { return putVal(hash(key), key, value, false, true); } final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node\u003cK,V\u003e[] tab; Node\u003cK,V\u003e p; int n, i; // table未初始化或者长度为0，进行扩容  if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // (n - 1) \u0026 hash 确定元素存放在哪个桶中，桶为空，新生成结点放入桶中(此时，这个结点是放在数组中)  if ((p = tab[i = (n - 1) \u0026 hash]) == null) tab[i] = newNode(hash, key, value, null); // 桶中已经存在元素  else { Node\u003cK,V\u003e e; K k; // 比较桶中第一个元素(数组中的结点)的hash值相等，key相等  if (p.hash == hash \u0026\u0026 ((k = p.key) == key || (key != null \u0026\u0026 key.equals(k)))) // 将第一个元素赋值给e，用e来记录  e = p; // hash值不相等，即key不相等；为红黑树结点  else if (p instanceof TreeNode) // 放入树中  e = ((TreeNode\u003cK,V\u003e)p).putTreeVal(this, tab, hash, key, value); // 为链表结点  else { // 在链表最末插入结点  for (int binCount = 0; ; ++binCount) { // 到达链表的尾部  if ((e = p.next) == null) { // 在尾部插入新结点  p.next = newNode(hash, key, value, null); // 结点数量达到阈值，转化为红黑树  if (binCount \u003e= TREEIFY_THRESHOLD - 1) // -1 for 1st  treeifyBin(tab, hash); // 跳出循环  break; } // 判断链表中结点的key值与插入的元素的key值是否相等  if (e.hash == hash \u0026\u0026 ((k = e.key) == key || (key != null \u0026\u0026 key.equals(k)))) // 相等，跳出循环  break; // 用于遍历桶中的链表，与前面的e = p.next组合，可以遍历链表  p = e; } } // 表示在桶中找到key值、hash值与插入元素相等的结点  if (e != null) { // 记录e的value  V oldValue = e.value; // onlyIfAbsent为false或者旧值为null  if (!onlyIfAbsent || oldValue == null) //用新值替换旧值  e.value = value; // 访问后回调  afterNodeAccess(e); // 返回旧值  return oldValue; } } // 结构性修改  ++modCount; // 实际大小大于阈值则扩容  if (++size \u003e threshold) resize(); // 插入后回调  afterNodeInsertion(evict); return null; }   我们再来对比一下 JDK1.7 put方法的代码\n对于put方法的分析如下：\n ①如果定位到的数组位置没有元素 就直接插入。 ②如果定位到的数组位置有元素，遍历以这个元素为头结点的链表，依次和插入的key比较，如果key相同就直接覆盖，不同就采用头插法插入元素。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  public V put(K key, V value) if (table == EMPTY_TABLE) { inflateTable(threshold); } if (key == null) return putForNullKey(value); int hash = hash(key); int i = indexFor(hash, table.length); for (Entry\u003cK,V\u003e e = table[i]; e != null; e = e.next) { // 先遍历  Object k; if (e.hash == hash \u0026\u0026 ((k = e.key) == key || key.equals(k))) { V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; } } modCount++; addEntry(hash, key, value, i); // 再插入  return null; }   get方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  public V get(Object key) { Node\u003cK,V\u003e e; return (e = getNode(hash(key), key)) == null ? null : e.value; } final Node\u003cK,V\u003e getNode(int hash, Object key) { Node\u003cK,V\u003e[] tab; Node\u003cK,V\u003e first, e; int n; K k; if ((tab = table) != null \u0026\u0026 (n = tab.length) \u003e 0 \u0026\u0026 (first = tab[(n - 1) \u0026 hash]) != null) { // 数组元素相等  if (first.hash == hash \u0026\u0026 // always check first node  ((k = first.key) == key || (key != null \u0026\u0026 key.equals(k)))) return first; // 桶中不止一个节点  if ((e = first.next) != null) { // 在树中get  if (first instanceof TreeNode) return ((TreeNode\u003cK,V\u003e)first).getTreeNode(hash, key); // 在链表中get  do { if (e.hash == hash \u0026\u0026 ((k = e.key) == key || (key != null \u0026\u0026 key.equals(k)))) return e; } while ((e = e.next) != null); } } return null; }   resize方法 进行扩容，会伴随着一次重新hash分配，并且会遍历hash表中所有的元素，是非常耗时的。在编写程序中，要尽量避免resize。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80  final Node\u003cK,V\u003e[] resize() { Node\u003cK,V\u003e[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap \u003e 0) { // 超过最大值就不再扩充了，就只好随你碰撞去吧  if (oldCap \u003e= MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return oldTab; } // 没超过最大值，就扩充为原来的2倍  else if ((newCap = oldCap \u003c\u003c 1) \u003c MAXIMUM_CAPACITY \u0026\u0026 oldCap \u003e= DEFAULT_INITIAL_CAPACITY) newThr = oldThr \u003c\u003c 1; // double threshold  } else if (oldThr \u003e 0) // initial capacity was placed in threshold  newCap = oldThr; else { // signifies using defaults  newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } // 计算新的resize上限  if (newThr == 0) { float ft = (float)newCap * loadFactor; newThr = (newCap \u003c MAXIMUM_CAPACITY \u0026\u0026 ft \u003c (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } threshold = newThr; @SuppressWarnings({\"rawtypes\",\"unchecked\"}) Node\u003cK,V\u003e[] newTab = (Node\u003cK,V\u003e[])new Node[newCap]; table = newTab; if (oldTab != null) { // 把每个bucket都移动到新的buckets中  for (int j = 0; j \u003c oldCap; ++j) { Node\u003cK,V\u003e e; if ((e = oldTab[j]) != null) { oldTab[j] = null; if (e.next == null) newTab[e.hash \u0026 (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode\u003cK,V\u003e)e).split(this, newTab, j, oldCap); else { Node\u003cK,V\u003e loHead = null, loTail = null; Node\u003cK,V\u003e hiHead = null, hiTail = null; Node\u003cK,V\u003e next; do { next = e.next; // 原索引  if ((e.hash \u0026 oldCap) == 0) { if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } // 原索引+oldCap  else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); // 原索引放到bucket里  if (loTail != null) { loTail.next = null; newTab[j] = loHead; } // 原索引+oldCap放到bucket里  if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab; }   HashMap常用方法测试 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71  package map; import java.util.Collection; import java.util.HashMap; import java.util.Set; public class HashMapDemo { public static void main(String[] args) { HashMap\u003cString, String\u003e map = new HashMap\u003cString, String\u003e(); // 键不能重复，值可以重复  map.put(\"san\", \"张三\"); map.put(\"si\", \"李四\"); map.put(\"wu\", \"王五\"); map.put(\"wang\", \"老王\"); map.put(\"wang\", \"老王2\");// 老王被覆盖  map.put(\"lao\", \"老王\"); System.out.println(\"-------直接输出hashmap:-------\"); System.out.println(map); /** * 遍历HashMap */ // 1.获取Map中的所有键  System.out.println(\"-------foreach获取Map中所有的键:------\"); Set\u003cString\u003e keys = map.keySet(); for (String key : keys) { System.out.print(key+\" \"); } System.out.println();//换行  // 2.获取Map中所有值  System.out.println(\"-------foreach获取Map中所有的值:------\"); Collection\u003cString\u003e values = map.values(); for (String value : values) { System.out.print(value+\" \"); } System.out.println();//换行  // 3.得到key的值的同时得到key所对应的值  System.out.println(\"-------得到key的值的同时得到key所对应的值:-------\"); Set\u003cString\u003e keys2 = map.keySet(); for (String key : keys2) { System.out.print(key + \"：\" + map.get(key)+\" \"); } /** * 另外一种不常用的遍历方式 */ // 当我调用put(key,value)方法的时候，首先会把key和value封装到  // Entry这个静态内部类对象中，把Entry对象再添加到数组中，所以我们想获取  // map中的所有键值对，我们只要获取数组中的所有Entry对象，接下来  // 调用Entry对象中的getKey()和getValue()方法就能获取键值对了  Set\u003cjava.util.Map.Entry\u003cString, String\u003e\u003e entrys = map.entrySet(); for (java.util.Map.Entry\u003cString, String\u003e entry : entrys) { System.out.println(entry.getKey() + \"--\" + entry.getValue()); } /** * HashMap其他常用方法 */ System.out.println(\"after map.size()：\"+map.size()); System.out.println(\"after map.isEmpty()：\"+map.isEmpty()); System.out.println(map.remove(\"san\")); System.out.println(\"after map.remove()：\"+map); System.out.println(\"after map.get(si)：\"+map.get(\"si\")); System.out.println(\"after map.containsKey(si)：\"+map.containsKey(\"si\")); System.out.println(\"after containsValue(李四)：\"+map.containsValue(\"李四\")); System.out.println(map.replace(\"si\", \"李四2\")); System.out.println(\"after map.replace(si, 李四2):\"+map); } }   ","description":"","tags":["map","hashmap"],"title":"\u003cJava容器\u003e HashMap","uri":"/blog/posts/java/hashmap/"},{"categories":["Java"],"content":" 简介 内部结构分析 LinkedList源码分析  构造方法 添加（add）方法 根据位置取数据的方法 根据对象得到索引的方法 检查链表是否包含某对象的方法： 删除（remove/pop）方法   LinkedList类常用方法测试：  简介 LinkedList是一个实现了List接口和Deque接口的双端链表。 LinkedList底层的链表结构使它支持高效的插入和删除操作，另外它实现了Deque接口，使得LinkedList类也具有队列的特性; LinkedList不是线程安全的，如果想使LinkedList变成线程安全的，可以调用静态类Collections类中的synchronizedList方法：\n1  List list=Collections.synchronizedList(new LinkedList(...));   内部结构分析 如下图所示： 看完了图之后，我们再看LinkedList类中的一个内部私有类Node就很好理解了：\n1 2 3 4 5 6 7 8 9 10 11  private static class Node\u003cE\u003e { E item;//节点值  Node\u003cE\u003e next;//后继节点  Node\u003cE\u003e prev;//前驱节点  Node(Node\u003cE\u003e prev, E element, Node\u003cE\u003e next) { this.item = element; this.next = next; this.prev = prev; } }   这个类就代表双端链表的节点Node。这个类有三个属性，分别是前驱节点，本节点的值，后继结点。\nLinkedList源码分析 构造方法 空构造方法：\n1 2  public LinkedList() { }   用已有的集合创建链表的构造方法：\n1 2 3 4  public LinkedList(Collection\u003c? extends E\u003e c) { this(); addAll(c); }   add方法 add(E e) 方法：将元素添加到链表尾部\n1 2 3 4  public boolean add(E e) { linkLast(e);//这里就只调用了这一个方法  return true; }   1 2 3 4 5 6 7 8 9 10 11 12 13 14  /** * 链接使e作为最后一个元素。 */ void linkLast(E e) { final Node\u003cE\u003e l = last; final Node\u003cE\u003e newNode = new Node\u003c\u003e(l, e, null); last = newNode;//新建节点  if (l == null) first = newNode; else l.next = newNode;//指向后继元素也就是指向下一个元素  size++; modCount++; }   add(int index,E e)：在指定位置添加元素\n1 2 3 4 5 6 7 8  public void add(int index, E element) { checkPositionIndex(index); //检查索引是否处于[0-size]之间  if (index == size)//添加在链表尾部  linkLast(element); else//添加在链表中间  linkBefore(element, node(index)); }   linkBefore方法需要给定两个参数，一个插入节点的值，一个指定的node，所以我们又调用了Node(index)去找到index对应的node\naddAll(Collection c )：将集合插入到链表尾部\n1 2 3  public boolean addAll(Collection\u003c? extends E\u003e c) { return addAll(size, c); }   addAll(int index, Collection c)： 将集合从指定位置开始插入\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50  public boolean addAll(int index, Collection\u003c? extends E\u003e c) { //1:检查index范围是否在size之内  checkPositionIndex(index); //2:toArray()方法把集合的数据存到对象数组中  Object[] a = c.toArray(); int numNew = a.length; if (numNew == 0) return false; //3：得到插入位置的前驱节点和后继节点  Node\u003cE\u003e pred, succ; //如果插入位置为尾部，前驱节点为last，后继节点为null  if (index == size) { succ = null; pred = last; } //否则，调用node()方法得到后继节点，再得到前驱节点  else { succ = node(index); pred = succ.prev; } // 4：遍历数据将数据插入  for (Object o : a) { @SuppressWarnings(\"unchecked\") E e = (E) o; //创建新节点  Node\u003cE\u003e newNode = new Node\u003c\u003e(pred, e, null); //如果插入位置在链表头部  if (pred == null) first = newNode; else pred.next = newNode; pred = newNode; } //如果插入位置在尾部，重置last节点  if (succ == null) { last = pred; } //否则，将插入的链表与先前链表连接起来  else { pred.next = succ; succ.prev = pred; } size += numNew; modCount++; return true; }   上面可以看出addAll方法通常包括下面四个步骤：\n 检查index范围是否在size之内 toArray()方法把集合的数据存到对象数组中 得到插入位置的前驱和后继节点 遍历数据，将数据插入到指定位置  addFirst(E e)： 将元素添加到链表头部\n1 2 3  public void addFirst(E e) { linkFirst(e); }   1 2 3 4 5 6 7 8 9 10 11 12 13  private void linkFirst(E e) { final Node\u003cE\u003e f = first; final Node\u003cE\u003e newNode = new Node\u003c\u003e(null, e, f);//新建节点，以头节点为后继节点  first = newNode; //如果链表为空，last节点也指向该节点  if (f == null) last = newNode; //否则，将头节点的前驱指针指向新节点，也就是指向前一个元素  else f.prev = newNode; size++; modCount++; }   addLast(E e)： 将元素添加到链表尾部，与 add(E e) 方法一样\n1 2 3  public void addLast(E e) { linkLast(e); }   根据位置取数据的方法 get(int index)： 根据指定索引返回数据\n1 2 3 4 5 6  public E get(int index) { //检查index范围是否在size之内  checkElementIndex(index); //调用Node(index)去找到index对应的node然后返回它的值  return node(index).item; }   获取头节点（index=0）数据方法:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  public E getFirst() { final Node\u003cE\u003e f = first; if (f == null) throw new NoSuchElementException(); return f.item; } public E element() { return getFirst(); } public E peek() { final Node\u003cE\u003e f = first; return (f == null) ? null : f.item; } public E peekFirst() { final Node\u003cE\u003e f = first; return (f == null) ? null : f.item; }   区别： getFirst(),element(),peek(),peekFirst() 这四个获取头结点方法的区别在于对链表为空时的处理，是抛出异常还是返回null，其中getFirst() 和element() 方法将会在链表为空时，抛出异常\nelement()方法的内部就是使用getFirst()实现的。它们会在链表为空时，抛出NoSuchElementException\n获取尾节点（index=-1）数据方法:\n1 2 3 4 5 6 7 8 9 10  public E getLast() { final Node\u003cE\u003e l = last; if (l == null) throw new NoSuchElementException(); return l.item; } public E peekLast() { final Node\u003cE\u003e l = last; return (l == null) ? null : l.item; }   两者区别： getLast() 方法在链表为空时，会抛出NoSuchElementException，而peekLast() 则不会，只是会返回 null。\n根据对象得到索引的方法 int indexOf(Object o)： 从头遍历找\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  public int indexOf(Object o) { int index = 0; if (o == null) { //从头遍历  for (Node\u003cE\u003e x = first; x != null; x = x.next) { if (x.item == null) return index; index++; } } else { //从头遍历  for (Node\u003cE\u003e x = first; x != null; x = x.next) { if (o.equals(x.item)) return index; index++; } } return -1; }   int lastIndexOf(Object o)： 从尾遍历找\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  public int lastIndexOf(Object o) { int index = size; if (o == null) { //从尾遍历  for (Node\u003cE\u003e x = last; x != null; x = x.prev) { index--; if (x.item == null) return index; } } else { //从尾遍历  for (Node\u003cE\u003e x = last; x != null; x = x.prev) { index--; if (o.equals(x.item)) return index; } } return -1; }   检查链表是否包含某对象的方法： contains(Object o)： 检查对象o是否存在于链表中\n1 2 3  public boolean contains(Object o) { return indexOf(o) != -1; }   删除方法 remove() ,removeFirst(),pop(): 删除头节点\npublic E pop() { return removeFirst(); } public E remove() { return removeFirst(); } public E removeFirst() { final Node\u003cE\u003e f = first; if (f == null) throw new NoSuchElementException(); return unlinkFirst(f); } removeLast(),pollLast(): 删除尾节点\n1 2 3 4 5 6 7 8 9 10  public E removeLast() { final Node\u003cE\u003e l = last; if (l == null) throw new NoSuchElementException(); return unlinkLast(l); } public E pollLast() { final Node\u003cE\u003e l = last; return (l == null) ? null : unlinkLast(l); }   区别： removeLast()在链表为空时将抛出NoSuchElementException，而pollLast()方法返回null。\nremove(Object o): 删除指定元素\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  public boolean remove(Object o) { //如果删除对象为null  if (o == null) { //从头开始遍历  for (Node\u003cE\u003e x = first; x != null; x = x.next) { //找到元素  if (x.item == null) { //从链表中移除找到的元素  unlink(x); return true; } } } else { //从头开始遍历  for (Node\u003cE\u003e x = first; x != null; x = x.next) { //找到元素  if (o.equals(x.item)) { //从链表中移除找到的元素  unlink(x); return true; } } } return false; }   当删除指定对象时，只需调用remove(Object o)即可，不过该方法一次只会删除一个匹配的对象，如果删除了匹配对象，返回true，否则false。\nunlink(Node x) 方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  E unlink(Node\u003cE\u003e x) { // assert x != null;  final E element = x.item; final Node\u003cE\u003e next = x.next;//得到后继节点  final Node\u003cE\u003e prev = x.prev;//得到前驱节点  //删除前驱指针  if (prev == null) { first = next;//如果删除的节点是头节点,令头节点指向该节点的后继节点  } else { prev.next = next;//将前驱节点的后继节点指向后继节点  x.prev = null; } //删除后继指针  if (next == null) { last = prev;//如果删除的节点是尾节点,令尾节点指向该节点的前驱节点  } else { next.prev = prev; x.next = null; } x.item = null; size--; modCount++; return element; }   remove(int index)：删除指定位置的元素\n1 2 3 4 5 6  public E remove(int index) { //检查index范围  checkElementIndex(index); //将节点删除  return unlink(node(index)); }   LinkedList类常用方法测试 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121  package list; import java.util.Iterator; import java.util.LinkedList; public class LinkedListDemo { public static void main(String[] srgs) { //创建存放int类型的linkedList  LinkedList\u003cInteger\u003e linkedList = new LinkedList\u003c\u003e(); /************************** linkedList的基本操作 ************************/ linkedList.addFirst(0); // 添加元素到列表开头  linkedList.add(1); // 在列表结尾添加元素  linkedList.add(2, 2); // 在指定位置添加元素  linkedList.addLast(3); // 添加元素到列表结尾  System.out.println(\"LinkedList（直接输出的）: \" + linkedList); System.out.println(\"getFirst()获得第一个元素: \" + linkedList.getFirst()); // 返回此列表的第一个元素  System.out.println(\"getLast()获得第最后一个元素: \" + linkedList.getLast()); // 返回此列表的最后一个元素  System.out.println(\"removeFirst()删除第一个元素并返回: \" + linkedList.removeFirst()); // 移除并返回此列表的第一个元素  System.out.println(\"removeLast()删除最后一个元素并返回: \" + linkedList.removeLast()); // 移除并返回此列表的最后一个元素  System.out.println(\"After remove:\" + linkedList); System.out.println(\"contains()方法判断列表是否包含1这个元素:\" + linkedList.contains(1)); // 判断此列表包含指定元素，如果是，则返回true  System.out.println(\"该linkedList的大小 : \" + linkedList.size()); // 返回此列表的元素个数  /************************** 位置访问操作 ************************/ System.out.println(\"-----------------------------------------\"); linkedList.set(1, 3); // 将此列表中指定位置的元素替换为指定的元素  System.out.println(\"After set(1, 3):\" + linkedList); System.out.println(\"get(1)获得指定位置（这里为1）的元素: \" + linkedList.get(1)); // 返回此列表中指定位置处的元素  /************************** Search操作 ************************/ System.out.println(\"-----------------------------------------\"); linkedList.add(3); System.out.println(\"indexOf(3): \" + linkedList.indexOf(3)); // 返回此列表中首次出现的指定元素的索引  System.out.println(\"lastIndexOf(3): \" + linkedList.lastIndexOf(3));// 返回此列表中最后出现的指定元素的索引  /************************** Queue操作 ************************/ System.out.println(\"-----------------------------------------\"); System.out.println(\"peek(): \" + linkedList.peek()); // 获取但不移除此列表的头  System.out.println(\"element(): \" + linkedList.element()); // 获取但不移除此列表的头  linkedList.poll(); // 获取并移除此列表的头  System.out.println(\"After poll():\" + linkedList); linkedList.remove(); System.out.println(\"After remove():\" + linkedList); // 获取并移除此列表的头  linkedList.offer(4); System.out.println(\"After offer(4):\" + linkedList); // 将指定元素添加到此列表的末尾  /************************** Deque操作 ************************/ System.out.println(\"-----------------------------------------\"); linkedList.offerFirst(2); // 在此列表的开头插入指定的元素  System.out.println(\"After offerFirst(2):\" + linkedList); linkedList.offerLast(5); // 在此列表末尾插入指定的元素  System.out.println(\"After offerLast(5):\" + linkedList); System.out.println(\"peekFirst(): \" + linkedList.peekFirst()); // 获取但不移除此列表的第一个元素  System.out.println(\"peekLast(): \" + linkedList.peekLast()); // 获取但不移除此列表的第一个元素  linkedList.pollFirst(); // 获取并移除此列表的第一个元素  System.out.println(\"After pollFirst():\" + linkedList); linkedList.pollLast(); // 获取并移除此列表的最后一个元素  System.out.println(\"After pollLast():\" + linkedList); linkedList.push(2); // 将元素推入此列表所表示的堆栈（插入到列表的头）  System.out.println(\"After push(2):\" + linkedList); linkedList.pop(); // 从此列表所表示的堆栈处弹出一个元素（获取并移除列表第一个元素）  System.out.println(\"After pop():\" + linkedList); linkedList.add(3); linkedList.removeFirstOccurrence(3); // 从此列表中移除第一次出现的指定元素（从头部到尾部遍历列表）  System.out.println(\"After removeFirstOccurrence(3):\" + linkedList); linkedList.removeLastOccurrence(3); // 从此列表中移除最后一次出现的指定元素（从头部到尾部遍历列表）  System.out.println(\"After removeFirstOccurrence(3):\" + linkedList); /************************** 遍历操作 ************************/ System.out.println(\"-----------------------------------------\"); linkedList.clear(); for (int i = 0; i \u003c 100000; i++) { linkedList.add(i); } // 迭代器遍历  long start = System.currentTimeMillis(); Iterator\u003cInteger\u003e iterator = linkedList.iterator(); while (iterator.hasNext()) { iterator.next(); } long end = System.currentTimeMillis(); System.out.println(\"Iterator：\" + (end - start) + \" ms\"); // 顺序遍历(随机遍历)  start = System.currentTimeMillis(); for (int i = 0; i \u003c linkedList.size(); i++) { linkedList.get(i); } end = System.currentTimeMillis(); System.out.println(\"for：\" + (end - start) + \" ms\"); // 另一种for循环遍历  start = System.currentTimeMillis(); for (Integer i : linkedList) ; end = System.currentTimeMillis(); System.out.println(\"for2：\" + (end - start) + \" ms\"); // 通过pollFirst()或pollLast()来遍历LinkedList  LinkedList\u003cInteger\u003e temp1 = new LinkedList\u003c\u003e(); temp1.addAll(linkedList); start = System.currentTimeMillis(); while (temp1.size() != 0) { temp1.pollFirst(); } end = System.currentTimeMillis(); System.out.println(\"pollFirst()或pollLast()：\" + (end - start) + \" ms\"); // 通过removeFirst()或removeLast()来遍历LinkedList  LinkedList\u003cInteger\u003e temp2 = new LinkedList\u003c\u003e(); temp2.addAll(linkedList); start = System.currentTimeMillis(); while (temp2.size() != 0) { temp2.removeFirst(); } end = System.currentTimeMillis(); System.out.println(\"removeFirst()或removeLast()：\" + (end - start) + \" ms\"); } }   ","description":"","tags":["linked-list"],"title":"\u003cJava容器\u003e LinkedList","uri":"/blog/posts/java/linkedlist/"},{"categories":["Java"],"content":"一 为什么 Java 中只有值传递？ 首先回顾一下在程序设计语言中有关将参数传递给方法（或函数）的一些专业术语。按值调用(call by value)表示方法接收的是调用者提供的值，而按引用调用（call by reference)表示方法接收的是调用者提供的变量地址。一个方法可以修改传递引用所对应的变量值，而不能修改传递值调用所对应的变量值。 它用来描述各种程序设计语言（不只是Java)中方法参数传递方式。\nJava程序设计语言总是采用按值调用。也就是说，方法得到的是所有参数值的一个拷贝，也就是说，方法不能修改传递给它的任何参数变量的内容。\n下面通过 3 个例子来给大家说明\nexample 1 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  public static void main(String[] args) { int num1 = 10; int num2 = 20; swap(num1, num2); System.out.println(\"num1 = \" + num1); System.out.println(\"num2 = \" + num2); } public static void swap(int a, int b) { int temp = a; a = b; b = temp; System.out.println(\"a = \" + a); System.out.println(\"b = \" + b); }   结果：\na = 20 b = 10 num1 = 10 num2 = 20 解析：\n在swap方法中，a、b的值进行交换，并不会影响到 num1、num2。因为，a、b中的值，只是从 num1、num2 的复制过来的。也就是说，a、b相当于num1、num2 的副本，副本的内容无论怎么修改，都不会影响到原件本身。\n通过上面例子，我们已经知道了一个方法不能修改一个基本数据类型的参数，而对象引用作为参数就不一样，请看 example2.\nexample 2 1 2 3 4 5 6 7 8 9 10 11  public static void main(String[] args) { int[] arr = { 1, 2, 3, 4, 5 }; System.out.println(arr[0]); change(arr); System.out.println(arr[0]); } public static void change(int[] array) { // 将数组的第一个元素变为0 \tarray[0] = 0; }   结果：\n1 0 解析：\narray 被初始化 arr 的拷贝也就是一个对象的引用，也就是说 array 和 arr 指向的时同一个数组对象。 因此，外部对引用对象的改变会反映到所对应的对象上。\n通过 example2 我们已经看到，实现一个改变对象参数状态的方法并不是一件难事。理由很简单，方法得到的是对象引用的拷贝，对象引用及其他的拷贝同时引用同一个对象。\n很多程序设计语言（特别是，C++和Pascal)提供了两种参数传递的方式：值调用和引用调用。有些程序员（甚至本书的作者）认为Java程序设计语言对对象采用的是引用调用，实际上，这种理解是不对的。由于这种误解具有一定的普遍性，所以下面给出一个反例来详细地阐述一下这个问题。\nexample 3 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  public class Test { public static void main(String[] args) { // TODO Auto-generated method stub \tStudent s1 = new Student(\"小张\"); Student s2 = new Student(\"小李\"); Test.swap(s1, s2); System.out.println(\"s1:\" + s1.getName()); System.out.println(\"s2:\" + s2.getName()); } public static void swap(Student x, Student y) { Student temp = x; x = y; y = temp; System.out.println(\"x:\" + x.getName()); System.out.println(\"y:\" + y.getName()); } }   结果：\nx:小李 y:小张 s1:小张 s2:小李 解析：\n交换之前：\n交换之后：\n通过上面两张图可以很清晰的看出： 方法并没有改变存储在变量 s1 和 s2 中的对象引用。swap方法的参数x和y被初始化为两个对象引用的拷贝，这个方法交换的是这两个拷贝\n总结 Java程序设计语言对对象采用的不是引用调用，实际上，对象引用是按 值传递的。\n下面再总结一下Java中方法参数的使用情况：\n 一个方法不能修改一个基本数据类型的参数（即数值型或布尔型》 一个方法可以改变一个对象参数的状态。 一个方法不能让对象参数引用一个新的对象。  参考： 《Java核心技术卷Ⅰ》基础知识第十版第四章4.5小节\n二 ==与equals(重要) == : 它的作用是判断两个对象的地址是不是相等。即，判断两个对象是不是同一个对象。(基本数据类型==比较的是值，引用数据类型==比较的是内存地址)\nequals() : 它的作用也是判断两个对象是否相等。但它一般有两种使用情况：\n 情况1：类没有覆盖equals()方法。则通过equals()比较该类的两个对象时，等价于通过“==”比较这两个对象。 情况2：类覆盖了equals()方法。一般，我们都覆盖equals()方法来两个对象的内容相等；若它们的内容相等，则返回true(即，认为这两个对象相等)。  举个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  public class test1 { public static void main(String[] args) { String a = new String(\"ab\"); // a 为一个引用  String b = new String(\"ab\"); // b为另一个引用,对象的内容一样  String aa = \"ab\"; // 放在常量池中  String bb = \"ab\"; // 从常量池中查找  if (aa == bb) // true  System.out.println(\"aa==bb\"); if (a == b) // false，非同一对象  System.out.println(\"a==b\"); if (a.equals(b)) // true  System.out.println(\"aEQb\"); if (42 == 42.0) { // true  System.out.println(\"true\"); } } }   说明：\n String中的equals方法是被重写过的，因为object的equals方法是比较的对象的内存地址，而String的equals方法比较的是对象的值。 当创建String类型的对象时，虚拟机会在常量池中查找有没有已经存在的值和要创建的值相同的对象，如果有就把它赋给当前引用。如果没有就在常量池中重新创建一个String对象。  三 hashCode与equals（重要） 面试官可能会问你：“你重写过 hashcode 和 equals 么，为什么重写equals时必须重写hashCode方法？”\nhashCode（）介绍 hashCode() 的作用是获取哈希码，也称为散列码；它实际上是返回一个int整数。这个哈希码的作用是确定该对象在哈希表中的索引位置。hashCode() 定义在JDK的Object.java中，这就意味着Java中的任何类都包含有hashCode() 函数。另外需要注意的是： Object 的 hashcode 方法是本地方法，也就是用 c 语言或 c++ 实现的，该方法通常用来将对象的 内存地址 转换为整数之后返回。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  /** * Returns a hash code value for the object. This method is * supported for the benefit of hash tables such as those provided by * {@link java.util.HashMap}. * \u003cp\u003e * As much as is reasonably practical, the hashCode method defined by * class {@code Object} does return distinct integers for distinct * objects. (This is typically implemented by converting the internal * address of the object into an integer, but this implementation * technique is not required by the * Java\u0026trade; programming language.) * * @return a hash code value for this object. * @see java.lang.Object#equals(java.lang.Object) * @see java.lang.System#identityHashCode */ public native int hashCode();   散列表存储的是键值对(key-value)，它的特点是：能根据“键”快速的检索出对应的“值”。这其中就利用到了散列码！（可以快速找到所需要的对象）\n为什么要有hashCode 我们以“HashSet如何检查重复”为例子来说明为什么要有hashCode：\n当你把对象加入HashSet时，HashSet会先计算对象的hashcode值来判断对象加入的位置，同时也会与其他已经加入的对象的hashcode值作比较，如果没有相符的hashcode，HashSet会假设对象没有重复出现。但是如果发现有相同hashcode值的对象，这时会调用equals（）方法来检查hashcode相等的对象是否真的相同。如果两者相同，HashSet就不会让其加入操作成功。如果不同的话，就会重新散列到其他位置。（摘自我的Java启蒙书《Head fist java》第二版）。这样我们就大大减少了equals的次数，相应就大大提高了执行速度。\nhashCode（）与equals（）的相关规定  如果两个对象相等，则hashcode一定也是相同的 两个对象相等,对两个对象分别调用equals方法都返回true 两个对象有相同的hashcode值，它们也不一定是相等的 因此，equals方法被覆盖过，则hashCode方法也必须被覆盖 hashCode()的默认行为是对堆上的对象产生独特值。如果没有重写hashCode()，则该class的两个对象无论如何都不会相等（即使这两个对象指向相同的数据）  为什么两个对象有相同的hashcode值，它们也不一定是相等的？ 在这里解释一位小伙伴的问题。以下内容摘自《Head Fisrt Java》。\n因为hashCode() 所使用的杂凑算法也许刚好会让多个对象传回相同的杂凑值。越糟糕的杂凑算法越容易碰撞，但这也与数据值域分布的特性有关（所谓碰撞也就是指的是不同的对象得到相同的 hashCode）。\n我们刚刚也提到了 HashSet,如果 HashSet 在对比的时候，同样的 hashcode 有多个对象，它会使用 equals() 来判断是否真的相同。也就是说 hashcode 只是用来缩小查找成本。\n参考：\nhttps://blog.csdn.net/zhzhao999/article/details/53449504\nhttps://www.cnblogs.com/skywang12345/p/3324958.html\nhttps://www.cnblogs.com/skywang12345/p/3324958.html\nhttps://www.cnblogs.com/Eason-S/p/5524837.html\n","description":"","tags":["interview-questions"],"title":"Java常见问题汇总-1","uri":"/blog/posts/java/common-questions/"},{"categories":["Java"],"content":"String和StringBuffer、StringBuilder的区别是什么？String为什么是不可变的？ String和StringBuffer、StringBuilder的区别 可变性 简单的来说：String 类中使用 final 关键字字符数组保存字符串，private　final　char　value[]，所以 String 对象是不可变的。而StringBuilder 与 StringBuffer 都继承自 AbstractStringBuilder 类，在 AbstractStringBuilder 中也是使用字符数组保存字符串char[]value 但是没有用 final 关键字修饰，所以这两种对象都是可变的。\nStringBuilder 与 StringBuffer 的构造方法都是调用父类构造方法也就是 AbstractStringBuilder 实现的，大家可以自行查阅源码。\nAbstractStringBuilder.java\n1 2 3 4 5 6 7 8  abstract class AbstractStringBuilder implements Appendable, CharSequence { char[] value; int count; AbstractStringBuilder() { } AbstractStringBuilder(int capacity) { value = new char[capacity]; }   线程安全性\nString 中的对象是不可变的，也就可以理解为常量，线程安全。AbstractStringBuilder 是 StringBuilder 与 StringBuffer 的公共父类，定义了一些字符串的基本操作，如 expandCapacity、append、insert、indexOf 等公共方法。StringBuffer 对方法加了同步锁或者对调用的方法加了同步锁，所以是线程安全的。StringBuilder 并没有对方法进行加同步锁，所以是非线程安全的。 性能\n每次对 String 类型进行改变的时候，都会生成一个新的 String 对象，然后将指针指向新的 String 对象。StringBuffer 每次都会对 StringBuffer 对象本身进行操作，而不是生成新的对象并改变对象引用。相同情况下使用 StirngBuilder 相比使用 StringBuffer 仅能获得 10%~15% 左右的性能提升，但却要冒多线程不安全的风险。\n对于三者使用的总结：\n 操作少量的数据 = String 单线程操作字符串缓冲区下操作大量数据 = StringBuilder 多线程操作字符串缓冲区下操作大量数据 = StringBuffer  String为什么是不可变的吗？ 简单来说就是String类利用了final修饰的char类型数组存储字符，源码如下图所以：\n1 2  /** The value is used for character storage. */ private final char value[];   String真的是不可变的吗？ 我觉得如果别人问这个问题的话，回答不可变就可以了。 下面只是给大家看两个有代表性的例子：\n1) String不可变但不代表引用不可以变\n1 2 3  String str = \"Hello\"; str = str + \" World\"; System.out.println(\"str=\" + str);   结果：\nstr=Hello World 解析：\n实际上，原来String的内容是不变的，只是str由原来指向\"Hello\"的内存地址转为指向\"Hello World\"的内存地址而已，也就是说多开辟了一块内存区域给\"Hello World\"字符串。\n2) 通过反射是可以修改所谓的“不可变”对象\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  // 创建字符串\"Hello World\"， 并赋给引用s \tString s = \"Hello World\"; System.out.println(\"s = \" + s); // Hello World  // 获取String类中的value字段 \tField valueFieldOfString = String.class.getDeclaredField(\"value\"); // 改变value属性的访问权限 \tvalueFieldOfString.setAccessible(true); // 获取s对象上的value属性的值 \tchar[] value = (char[]) valueFieldOfString.get(s); // 改变value所引用的数组中的第5个字符 \tvalue[5] = '_'; System.out.println(\"s = \" + s); // Hello_World   结果：\ns = Hello World s = Hello_World 解析：\n用反射可以访问私有成员， 然后反射出String对象中的value属性， 进而改变通过获得的value引用改变数组的结构。但是一般我们不会这么做，这里只是简单提一下有这个东西。\n什么是反射机制？反射机制的应用场景有哪些？ 反射机制介绍 JAVA反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为java语言的反射机制。\n静态编译和动态编译  **静态编译：**在编译时确定类型，绑定对象 **动态编译：**运行时确定类型，绑定对象  反射机制优缺点  优点： 运行期类型的判断，动态加载类，提高代码灵活度。 缺点： 性能瓶颈：反射相当于一系列解释操作，通知 JVM 要做的事情，性能比直接的java代码要慢很多。  反射的应用场景 反射是框架设计的灵魂。\n在我们平时的项目开发过程中，基本上很少会直接使用到反射机制，但这不能说明反射机制没有用，实际上有很多设计、开发都与反射机制有关，例如模块化的开发，通过反射去调用对应的字节码；动态代理设计模式也采用了反射机制，还有我们日常使用的 Spring／Hibernate 等框架也大量使用到了反射机制。\n举例：①我们在使用JDBC连接数据库时使用Class.forName()通过反射加载数据库的驱动程序；②Spring框架也用到很多反射机制，最经典的就是xml的配置模式。Spring 通过 XML 配置模式装载 Bean 的过程：1) 将程序内所有 XML 或 Properties 配置文件加载入内存中; 2)Java类里面解析xml或properties里面的内容，得到对应实体类的字节码字符串以及相关的属性信息; 3)使用反射机制，根据这个字符串获得某个类的Class实例; 4)动态配置实例的属性\n推荐阅读：\n Reflection：Java反射机制的应用场景 Java基础之—反射（非常重要）  什么是JDK?什么是JRE？什么是JVM？三者之间的联系与区别 这几个是Java中很基本很基本的东西，但是我相信一定还有很多人搞不清楚！为什么呢？因为我们大多数时候在使用现成的编译工具以及环境的时候，并没有去考虑这些东西。\nJDK: 顾名思义它是给开发者提供的开发工具箱,是给程序开发者用的。它除了包括完整的JRE（Java Runtime Environment），Java运行环境，还包含了其他供开发者使用的工具包。\nJRE: 普通用户而只需要安装JRE（Java Runtime Environment）来运行Java程序。而程序开发者必须安装JDK来编译、调试程序。\nJVM： 当我们运行一个程序时，JVM负责将字节码转换为特定机器代码，JVM提供了内存管理/垃圾回收和安全机制等。这种独立于硬件和操作系统，正是java程序可以一次编写多处执行的原因。\n区别与联系：\n JDK用于开发，JRE用于运行java程序 ； JDK和JRE中都包含JVM ； JVM是java编程语言的核心并且具有平台独立性。  什么是字节码？采用字节码的最大好处是什么？ 先看下java中的编译器和解释器： Java中引入了虚拟机的概念，即在机器和编译程序之间加入了一层抽象的虚拟的机器。这台虚拟的机器在任何平台上都提供给编译程序一个的共同的接口。编译程序只需要面向虚拟机，生成虚拟机能够理解的代码，然后由解释器来将虚拟机代码转换为特定系统的机器码执行。在Java中，这种供虚拟机理解的代码叫做字节码（即扩展名为.class的文件），它不面向任何特定的处理器，只面向虚拟机。每一种平台的解释器是不同的，但是实现的虚拟机是相同的。Java源程序经过编译器编译后变成字节码，字节码由虚拟机解释执行，虚拟机将每一条要执行的字节码送给解释器，解释器将其翻译成特定机器上的机器码，然后在特定的机器上运行。这也就是解释了Java的编译与解释并存的特点。\nJava源代码----\u003e编译器----\u003ejvm可执行的Java字节码(即虚拟指令)----\u003ejvm----\u003ejvm中解释器-----\u003e机器可执行的二进制机器码----\u003e程序运行。\n采用字节码的好处： Java语言通过字节码的方式，在一定程度上解决了传统解释型语言执行效率低的问题，同时又保留了解释型语言可移植的特点。所以Java程序运行时比较高效，而且，由于字节码并不专对一种特定的机器，因此，Java程序无须重新编译便可在多种不同的计算机上运行。\nJava和C++的区别 我知道很多人没学过C++，但是面试官就是没事喜欢拿咱们Java和C++比呀！没办法！！！就算没学过C++，也要记下来！\n 都是面向对象的语言，都支持封装、继承和多态 Java不提供指针来直接访问内存，程序内存更加安全 Java的类是单继承的，C++支持多重继承；虽然Java的类不可以多继承，但是接口可以多继承。 Java有自动内存管理机制，不需要程序员手动释放无用内存  接口和抽象类的区别是什么？  接口的方法默认是public，所有方法在接口中不能有实现，抽象类可以有非抽象的方法 接口中的实例变量默认是final类型的，而抽象类中则不一定 一个类可以实现多个接口，但最多只能实现一个抽象类 一个类实现接口的话要实现接口的所有方法，而抽象类不一定 接口不能用new实例化，但可以声明，但是必须引用一个实现该接口的对象 从设计层面来说，抽象是对类的抽象，是一种模板设计，接口是行为的抽象，是一种行为的规范。  注意：Java8 后接口可以有默认实现( default )。\n成员变量与局部变量的区别有那些？  从语法形式上，看成员变量是属于类的，而局部变量是在方法中定义的变量或是方法的参数；成员变量可以被public,private,static等修饰符所修饰，而局部变量不能被访问控制修饰符及static所修饰；但是，成员变量和局部变量都能被final所修饰； 从变量在内存中的存储方式来看，成员变量是对象的一部分，而对象存在于堆内存，局部变量存在于栈内存 从变量在内存中的生存时间上看，成员变量是对象的一部分，它随着对象的创建而存在，而局部变量随着方法的调用而自动消失。 成员变量如果没有被赋初值，则会自动以类型的默认值而赋值（一种情况例外被final修饰但没有被static修饰的成员变量必须显示地赋值）；而局部变量则不会自动赋值。  重载和重写的区别 重载： 发生在同一个类中，方法名必须相同，参数类型不同、个数不同、顺序不同，方法返回值和访问修饰符可以不同，发生在编译时。 重写： 发生在父子类中，方法名、参数列表必须相同，返回值范围小于等于父类，抛出的异常范围小于等于父类，访问修饰符范围大于等于父类；如果父类方法访问修饰符为private则子类就不能重写该方法。\n字符型常量和字符串常量的区别  形式上: 字符常量是单引号引起的一个字符 字符串常量是双引号引起的若干个字符 含义上: 字符常量相当于一个整形值(ASCII值),可以参加表达式运算 字符串常量代表一个地址值(该字符串在内存中存放位置) 占内存大小 字符常量只占一个字节 字符串常量占若干个字节(至少一个字符结束标志)  ","description":"","tags":["interview-questions"],"title":"Java常见问题汇总-2","uri":"/blog/posts/java/string/"},{"categories":["Java"],"content":"1. 简述线程，程序、进程的基本概念。以及他们之间关系是什么？ 线程与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享同一块内存空间和一组系统资源，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。\n程序是含有指令和数据的文件，被存储在磁盘或其他的数据存储设备中，也就是说程序是静态的代码。\n进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。简单来说，一个进程就是一个执行中的程序，它在计算机中一个指令接着一个指令地执行着，同时，每个进程还占有某些系统资源如CPU时间，内存空间，文件，文件，输入输出设备的使用权等等。换句话说，当程序在执行时，将会被操作系统载入内存中。\n线程 是 进程 划分成的更小的运行单位。线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。从另一角度来说，进程属于操作系统的范畴，主要是同一段时间内，可以同时执行一个以上的程序，而线程则是在同一程序内几乎同时执行一个以上的程序段。\n线程上下文的切换比进程上下文切换要快很多\n 进程切换时，涉及到当前进程的CPU环境的保存和新被调度运行进程的CPU环境的设置。 线程切换仅需要保存和设置少量的寄存器内容，不涉及存储管理方面的操作。  2. 线程有哪些基本状态？这些状态是如何定义的?  新建(new)：新创建了一个线程对象。 可运行(runnable)：线程对象创建后，其他线程(比如main线程）调用了该对象的start()方法。该状态的线程位于可运行线程池中，等待被线程调度选中，获 取cpu的使用权。 运行(running)：可运行状态(runnable)的线程获得了cpu时间片（timeslice），执行程序代码。 阻塞(block)：阻塞状态是指线程因为某种原因放弃了cpu使用权，也即让出了cpu timeslice，暂时停止运行。直到线程进入可运行(runnable)状态，才有 机会再次获得cpu timeslice转到运行(running)状态。阻塞的情况分三种：   (一). 等待阻塞：运行(running)的线程执行o.wait()方法，JVM会把该线程放 入等待队列(waiting queue)中。 (二). 同步阻塞：运行(running)的线程在获取对象的同步锁时，若该同步 锁 被别的线程占用，则JVM会把该线程放入锁池(lock pool)中。 (三). 其他阻塞: 运行(running)的线程执行Thread.sleep(long ms)或t.join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入可运行(runnable)状态。  死亡(dead)：线程run()、main()方法执行结束，或者因异常退出了run()方法，则该线程结束生命周期。死亡的线程不可再次复生。  备注： 可以用早起坐地铁来比喻这个过程（下面参考自牛客网某位同学的回答）：\n 还没起床：sleeping 起床收拾好了，随时可以坐地铁出发：Runnable 等地铁来：Waiting 地铁来了，但要排队上地铁：I/O阻塞 上了地铁，发现暂时没座位：synchronized阻塞 地铁上找到座位：Running 到达目的地：Dead  3. 何为多线程？ 多线程就是多个线程同时运行或交替运行。单核CPU的话是顺序执行，也就是交替运行。多核CPU的话，因为每个CPU有自己的运算器，所以在多个CPU中可以同时运行。\n4. 为什么多线程是必要的？  使用线程可以把占据长时间的程序中的任务放到后台去处理。 用户界面可以更加吸引人，这样比如用户点击了一个按钮去触发某些事件的处理，可以弹出一个进度条来显示处理的进度。 程序的运行速度可能加快。  5 使用多线程常见的三种方式 ①继承Thread类 MyThread.java\n1 2 3 4 5 6 7  public class MyThread extends Thread { @Override public void run() { super.run(); System.out.println(\"MyThread\"); } }   Run.java\n1 2 3 4 5 6 7 8 9 10  public class Run { public static void main(String[] args) { MyThread mythread = new MyThread(); mythread.start(); System.out.println(\"运行结束\"); } }   运行结果： 从上面的运行结果可以看出：线程是一个子任务，CPU以不确定的方式，或者说是以随机的时间来调用线程中的run方法。\n②实现Runnable接口 推荐实现Runnable接口方式开发多线程，因为Java单继承但是可以实现多个接口。\nMyRunnable.java\n1 2 3 4 5 6  public class MyRunnable implements Runnable { @Override public void run() { System.out.println(\"MyRunnable\"); } }   Run.java\n1 2 3 4 5 6 7 8 9 10  public class Run { public static void main(String[] args) { Runnable runnable=new MyRunnable(); Thread thread=new Thread(runnable); thread.start(); System.out.println(\"运行结束！\"); } }   运行结果： ③使用线程池 在《阿里巴巴Java开发手册》“并发处理”这一章节，明确指出线程资源必须通过线程池提供，不允许在应用中自行显示创建线程。\n为什么呢？\n 使用线程池的好处是减少在创建和销毁线程上所消耗的时间以及系统资源开销，解决资源不足的问题。如果不使用线程池，有可能会造成系统创建大量同类线程而导致消耗完内存或者“过度切换”的问题。\n 另外《阿里巴巴Java开发手册》中强制线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险\n Executors 返回线程池对象的弊端如下：\n FixedThreadPool 和 SingleThreadExecutor ： 允许请求的队列长度为 Integer.MAX_VALUE,可能堆积大量的请求，从而导致OOM。 CachedThreadPool 和 ScheduledThreadPool ： 允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致OOM。   对于线程池感兴趣的可以查看我的这篇文章：《Java多线程学习（八）线程池与Executor 框架》 点击阅读原文即可查看到该文章的最新版。\n6 线程的优先级 每个线程都具有各自的优先级，线程的优先级可以在程序中表明该线程的重要性，如果有很多线程处于就绪状态，系统会根据优先级来决定首先使哪个线程进入运行状态。但这个并不意味着低 优先级的线程得不到运行，而只是它运行的几率比较小，如垃圾回收机制线程的优先级就比较低。所以很多垃圾得不到及时的回收处理。\n线程优先级具有继承特性。 比如A线程启动B线程，则B线程的优先级和A是一样的。\n线程优先级具有随机性。 也就是说线程优先级高的不一定每一次都先执行完。\nThread类中包含的成员变量代表了线程的某些优先级。如Thread.MIN_PRIORITY（常数1），Thread.NORM_PRIORITY（常数5）, Thread.MAX_PRIORITY（常数10）。其中每个线程的优先级都在Thread.MIN_PRIORITY（常数1） 到Thread.MAX_PRIORITY（常数10） 之间，在默认情况下优先级都是Thread.NORM_PRIORITY（常数5）。\n学过操作系统这门课程的话，我们可以发现多线程优先级或多或少借鉴了操作系统对进程的管理。\n7 Java多线程分类 用户线程 运行在前台，执行具体的任务，如程序的主线程、连接网络的子线程等都是用户线程\n守护线程 运行在后台，为其他前台线程服务.也可以说守护线程是JVM中非守护线程的 “佣人”。\n 特点： 一旦所有用户线程都结束运行，守护线程会随JVM一起结束工作 应用： 数据库连接池中的检测线程，JVM虚拟机启动后的检测线程 最常见的守护线程： 垃圾回收线程  如何设置守护线程？\n可以通过调用 Thead 类的 setDaemon(true) 方法设置当前的线程为守护线程。\n注意事项：\n1. setDaemon(true)必须在start（）方法前执行，否则会抛出IllegalThreadStateException异常 2. 在守护线程中产生的新线程也是守护线程 3. 不是所有的任务都可以分配给守护线程来执行，比如读写操作或者计算逻辑  8 sleep()方法和wait()方法简单对比  两者最主要的区别在于：sleep方法没有释放锁，而wait方法释放了锁 。 两者都可以暂停线程的执行。 Wait通常被用于线程间交互/通信，sleep通常被用于暂停执行。 wait()方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的notify()或者notifyAll()方法。sleep()方法执行完成后，线程会自动苏醒。  9 为什么我们调用start()方法时会执行run()方法，为什么我们不能直接调用run()方法？ 这是另一个非常经典的java多线程面试问题，而且在面试中会经常被问到。很简单，但是很多人都会答不上来！\nnew一个Thread，线程进入了新建状态;调用start()方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start()会执行线程的相应准备工作，然后自动执行run()方法的内容，这是真正的多线程工作。 而直接执行run()方法，会把run方法当成一个mian线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。\n总结： 调用start方法方可启动线程并使线程进入就绪状态，而run方法只是thread的一个普通方法调用，还是在主线程里执行。\n","description":"","tags":["multithread","interview"],"title":"问题梳理-Java多线程","uri":"/blog/posts/java/questiones-multithread-in-java/"},{"categories":["Algorithm"],"content":"题目描述 在一个二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。\n算法分析 我们可以观察二维数组（m，n）中的4个顶点。\n左上角（0，0），向右和向下都是递增。右下角（m，n），向左和向上都是递增，所以我们无法确认哪一个方向能更快找到目标值。\n考虑左下角（m，0），向右是递增的，向上的递减的，所以通过比较 target 和 current value 大小，我们可以判断其所在的相对方向。同理右上角。\n代码实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  class Solution { public: bool Find(int target, vector\u003cvector\u003cint\u003e \u003e array) { int row = array.size(); int col = array[0].size(); int i, j; // 起始点在左下角  for(i = row - 1, j = 0; i \u003e= 0 \u0026\u0026 j \u003c col;) { if(target == array[i][j]) return true; if(target \u003c array[i][j]){ i--; continue; } if(target \u003e array[i][j]){ j++; continue; } } // 或者起始点在右上角 // for(i = 0, j = col - 1; i \u003c row \u0026\u0026 j \u003e= 0;) { // if(target == array[i][j]) // return true; // if(target \u003c array[i][j]){ // j--; // continue; // } // if(target \u003e array[i][j]){ // // i++; // continue; // } // }  return false; } };   ","description":"","tags":["algorithm","array"],"title":"【剑指offer】二维数组中的查找","uri":"/blog/posts/algorithm/sword-refers-to-offer-search-in-a-twodimensional-array/"},{"categories":["Algorithm"],"content":"题目描述 输入一个链表，按链表值从尾到头的顺序返回一个ArrayList。\n算法分析   使用递归的方法：\n我们可以使用递归函数，head和head-\u003enext存在的时候进入下一层，当进入最后一层的时候开始从尾部返回。\n  使用栈的方法：\n首先遍历一遍链表，将顺序的值压栈，然后利用栈的性质（后进先出）进行打印。\n  代码实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51  /** * struct ListNode { * int val; * struct ListNode *next; * ListNode(int x) : * val(x), next(NULL) { * } * }; */ // 递归 class Solution { public: vector\u003cint\u003e printListFromTailToHead(ListNode* head) { vector\u003cint\u003e result; helper(head, result); return result; } private: void helper(ListNode* head, vector\u003cint\u003e \u0026result){ if(head){ if(head -\u003e next){ helper(head -\u003e next, result); } result.push_back(head -\u003e val); } } }; // 栈 class Solution { public: vector\u003cint\u003e printListFromTailToHead(ListNode* head) { vector\u003cint\u003e res; stack\u003cint\u003e st; while (head) { st.push(head-\u003eval); head = head-\u003enext; } while (!st.empty()) { res.push_back(st.top()); st.pop(); } return res; } };   ","description":"","tags":["algorithm","linked-list"],"title":"【剑指offer】从尾到头打印链表","uri":"/blog/posts/algorithm/sword-refers-to-offer-print-the-linked-list-from-end-beginning/"},{"categories":["Algorithm"],"content":"题目描述 把一个数组最开始的若干个元素搬到数组的末尾，我们称之为数组的旋转。 输入一个非递减排序的数组的一个旋转，输出旋转数组的最小元素。 例如数组{3,4,5,1,2}为{1,2,3,4,5}的一个旋转，该数组的最小值为1。 NOTE：给出的所有元素都大于0，若数组大小为0，请返回0。\n算法分析 我觉得这道题目挺没有意思，最直接的一个做法是遍历整个数组，它举了一个递减排序的数组，这里只需要找到旋转点是可以用二分的，不确定旋转数组是否是有序的话，就只能用第一个方法了。\n代码实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  class Solution { public: int minNumberInRotateArray(vector\u003cint\u003e rotateArray) { if(rotateArray.size() == 0){ return 0; } else{ int first = rotateArray[0]; int i = 1; while(rotateArray[i] != '\\0'){ if(rotateArray[i] \u003c first){ break; //return rotateArray[i];  } i++; } return rotateArray[i]; } } }; class Solution { public: int minNumberInRotateArray(vector\u003cint\u003e rotateArray) { int n = rotateArray.size(); if (n == 0) return 0; else { int min = rotateArray[0]; for (auto i : rotateArray) { if (i \u003c min) min = i; } return min; } } };   ","description":"","tags":["algorithm","search"],"title":"【剑指offer】旋转数组的最小数字","uri":"/blog/posts/algorithm/rotate-the-smallest-number-of-array/"},{"categories":["Algorithm"],"content":"题目描述 请实现一个函数，将一个字符串中的空格替换成“%20”。例如，当字符串为We Are Happy.则经过替换之后的字符串为We%20Are%20Happy。\n算法分析 首先复制一份字符串的备份，我们需要知道字符串原始长度，空格数来计算替换后字符串的长度，之后就只需要根据字符串原始长度和新长度对字符串进行拷贝。\n代码实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  class Solution { public: void replaceSpace(char *str,int length) { char *t = str; int strLen = 0, newStrLen = 0, spaceCount = 0; int p,q; if(str == NULL || length \u003c0) return; // 首先判定进入算法的有效条件  while(*t != '\\0'){ strLen++; if(*t == ' ') spaceCount++; t++; }\t// 取字符串长度， 空格的个数  newStrLen = strLen + 2 * spaceCount; // 新的字符串的长度  if(newStrLen \u003e length) return ; for(p = strLen, q = newStrLen; p \u003e= 0; p-- ){ if(str[p] == ' '){ str[q--] = '0'; str[q--] = '2'; str[q--] = '%'; } else { str[q--] = str[p]; } } } };   ","description":"","tags":["algorithm","string"],"title":"【剑指offer】替换空格","uri":"/blog/posts/algorithm/replace-spaces/"},{"categories":["Algorithm"],"content":"题目描述 用两个栈来实现一个队列，完成队列的Push和Pop操作。 队列中的元素为int类型。\n算法分析 队列具有先进先出的性质，栈具有后进先出的性质，根据他们性质的联系，使用两个栈实现队列的思路如下：\npush操作用一个栈进行存储，pop操作用存储数据的栈向另一栈进行存放，这样数据两次倒转不变，\n第二个栈的栈顶元素作为返回值，然后在倒转回第一个栈。\n代码实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  class Solution { public: void push(int node) { stack1.push(node); } int pop() { int res; while (!stack1.empty()) { stack2.push(stack1.top()); stack1.pop(); } res = stack2.top(); stack2.pop(); while (!stack2.empty()) { stack1.push(stack2.top()); stack2.pop(); } return res; } private: stack\u003cint\u003e stack1; stack\u003cint\u003e stack2; };   ","description":"","tags":["algorithm","queue","stack"],"title":"【剑指offer】栈实现队列","uri":"/blog/posts/algorithm/%E6%A0%88%E5%AE%9E%E7%8E%B0%E9%98%9F%E5%88%97/"},{"categories":["Algorithm"],"content":"问题描述 输入某二叉树的前序遍历和中序遍历的结果，请重建出该二叉树。假设输入的前序遍历和中序遍历的结果中都不含重复的数字。例如输入前序遍历序列{1,2,4,7,3,5,6,8}和中序遍历序列{4,7,2,1,5,3,8,6}，则重建二叉树并返回。\n算法分析 算法的基本思路是分治法，divide and conquer，可以拆解这个为相似的小问题，pre的第一个元素是根节点，树或者子树，然后可以拆解为左右子树的pre和vin，进行同样的过程\n代码实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  /** * Definition for binary tree * struct TreeNode { * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) {} * }; */ class Solution { public: TreeNode* reConstructBinaryTree(vector\u003cint\u003e pre,vector\u003cint\u003e vin) { if (pre.size() == 0) return NULL; else if (pre.size() == 1){ TreeNode* root = new TreeNode(pre.back()); root -\u003e left = NULL; root -\u003e right = NULL; return root; } else { TreeNode* root = new TreeNode(pre.at(0)); vector\u003cint\u003e::iterator it = vin.begin(); while(it != vin.end() \u0026\u0026 *it != pre.at(0)) ++it; int dis = it - vin.begin(); vector\u003cint\u003e subPreLeft(pre.begin() + 1, pre.begin() + dis + 1); vector\u003cint\u003e subPreRight(pre.begin() + dis + 1, pre.end()); vector\u003cint\u003e subVinLeft(vin.begin(), it); vector\u003cint\u003e subVinRight(it + 1, vin.end() ); root -\u003e left = reConstructBinaryTree(subPreLeft, subVinLeft); root -\u003e right = reConstructBinaryTree(subPreRight, subVinRight); return root; } } };   ","description":"","tags":["algorithm","binary-tree"],"title":"【剑指offer】重建二叉树","uri":"/blog/posts/algorithm/sword-refers-to-offer-rebuild-the-binary-tree/"},{"categories":["Java"],"content":"C语言函数调用实现 通过一个简单的C语言程序分析\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  #include \u003cstdio.h\u003e int add(); int main(int argc, char const *argv[]) { int c = add(); printf(\"%d\", c); return 0; } int add() { int z = 1 + 2; return z; }   将这段C程序编译成汇编程序：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54  .file\t\".\\\\sampleAdd.c\" .section\t.rodata .LC0: .string\t\"%d\" .text .globl\tmain .type\tmain, @function main: .LFB13: .cfi_startproc pushq\t%rbp .cfi_def_cfa_offset 16 .cfi_offset 6, -16 movq\t%rsp, %rbp .cfi_def_cfa_register 6 subq\t$32, %rsp movl\t%edi, -20(%rbp) movq\t%rsi, -32(%rbp) movl\t$0, %eax call\tadd movl\t%eax, -4(%rbp) movl\t-4(%rbp), %eax movl\t%eax, %esi movl\t$.LC0, %edi movl\t$0, %eax call\tprintf movl\t$0, %eax leave .cfi_def_cfa 7, 8 ret .cfi_endproc .LFE13: .size\tmain, .-main .globl\tadd .type\tadd, @function add: .LFB14: .cfi_startproc pushq\t%rbp .cfi_def_cfa_offset 16 .cfi_offset 6, -16 movq\t%rsp, %rbp .cfi_def_cfa_register 6 movl\t$3, -4(%rbp) movl\t-4(%rbp), %eax popq\t%rbp .cfi_def_cfa 7, 8 ret .cfi_endproc .LFE14: .size\tadd, .-add .ident\t\"GCC: (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609\" .section\t.note.GNU-stack,\"\",@progbits   去除宏定义，保留主要指令如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  main: pushq\t%rbp movq\t%rsp, %rbp subq\t$32, %rsp movl\t%edi, -20(%rbp) movq\t%rsi, -32(%rbp) movl\t$0, %eax call\tadd movl\t%eax, -4(%rbp) movl\t-4(%rbp), %eax movl\t%eax, %esi movl\t$.LC0, %edi movl\t$0, %eax call\tprintf movl\t$0, %eax leave ret add: pushq\t%rbp movq\t%rsp, %rbp movl\t$3, -4(%rbp) movl\t-4(%rbp), %eax popq\t%rbp ret   汇编程序有两个标号main, add。这不是巧合，而是编译器处理的结果，编译器会把函数名处理成汇编程序中的标号。 有了标号，汇编程序就能执行函数调用，即call指令，有一条call and指令，就是汇编中执行函数调用的指令。\n接下来逐段分析：\n1 2 3 4  # 保存调用者栈基地址，并为main()函数分配新栈空间 \tpushq\t%rbp\tmovq\t%rsp, %rbp subq\t$32, %rsp\t# 分配新栈，一共32字节   在mian，add代码段的开始都包含这3条指令，add代码段第3行是movl\t$3, -4(%rbp)该指令与mian代码段的subq\t$32, %rsp作用是相同的——分配栈空间。\n这3条指令的作用为：保存段调用者基址，为新方法分配方法栈。这几乎是汇编程序执行方法调用的标准定式。\nmain() 函数的方法栈内存布局如下图所示：\n// 这里需要插入一张图片\n带入参的C程序 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  #include \u003cstdio.h\u003e int add(int a, int b); int main(int argc, char const *argv[]) { int a = 5, b = 3; int c = add(a, b); return 0; } int add(int a, int b) { int z = 1 + 2; return z; }   将这段C程序编译成汇编程序(去除宏定义，保留主要指令)：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  main: pushq\t%rbp movq\t%rsp, %rbp subq\t$32, %rsp movl\t%edi, -20(%rbp) movq\t%rsi, -32(%rbp) movl\t$5, -12(%rbp) movl\t$3, -8(%rbp) movl\t-8(%rbp), %edx movl\t-12(%rbp), %eax movl\t%edx, %esi movl\t%eax, %edi call\tadd movl\t%eax, -4(%rbp) movl\t$0, %eax leave ret add: pushq\t%rbp movq\t%rsp, %rbp movl\t%edi, -20(%rbp) movl\t%esi, -24(%rbp) movl\t$3, -4(%rbp) movl\t-4(%rbp), %eax popq\t%rbp ret   C语言函数的调用机制  压栈 main函数调用add()函数之前，会将两个入参压栈（压入调用者的栈），压栈之后add()就可以获取这两个入参。 参数传递顺序 Linux平台，调用者函数向被调用者函数传递参数，采用逆向顺序压栈，即最后一个参数第一个压栈，第一个参数最后压栈 读取入参 读取入参的方式是：通过add()函数的栈基地址rbp的相对地址，从main()函数中读取，最后一位入参在8(%rbp)，依次12(%rbp)......  真实物理机器上执行函数调用的步骤：  保存调用者栈基地址，当前IP寄存器入栈 调用函数时，在x86平台参数从右到左依次入栈 一个方法所分配的栈空间大小，取决于方法内部局部变量空间、为被调用者所传递的入参大小 被调用者在接收入参时，从8(%rbp)处开始，往上逐个获取参数 被调用者将返回结果保存在eax寄存器中，调用者从该寄存器取值  补充（关于寄存器）  %rax 作为函数返回值使用。 %rsp 栈指针寄存器，指向栈顶 %rdi，%rsi，%rdx，%rcx，%r8，%r9 用作函数参数，依次对应第1参数，第2参数。。。 %rbx，%rbp，%r12，%r13，%14，%15 用作数据存储，遵循被调用者使用规则，简单说就是随便用，调用子函数之前要备份它，以防他被修改 %r10，%r11 用作数据存储，遵循调用者使用规则，简单说就是使用之前要先保存原值  Reference   X86-64寄存器和栈帧\n  揭秘Java虚拟机\n  ","description":"","tags":["jvm"],"title":"\u003c深入理解JVM\u003e 函数调用机制","uri":"/blog/posts/java/implement-function-call-in-c/"},{"categories":["Algorithm"],"content":"简介 平衡树（AVLTree）\n 在计算机科学中，AVL树是最先发明的自平衡二叉查找树。在AVL树中任何节点的两个子树的高度最大差别为1，所以它也被称为高度平衡树。查找、插入和删除在平均和最坏情况下的时间复杂度都是。增加和删除可能需要通过一次或多次树旋转来重新平衡这个树。AVL树得名于它的发明者G. M. Adelson-Velsky和E. M. Landis，他们在1962年的论文《An algorithm for the organization of information》中发表了它。\n节点的平衡因子是它的左子树的高度减去它的右子树的高度（有时相反）。带有平衡因子1、0或 -1的节点被认为是平衡的。带有平衡因子 -2或2的节点被认为是不平衡的，并需要重新平衡这个树。平衡因子可以直接存储在每个节点中，或从可能存储在节点中的子树高度计算出来。\n 二叉查找树给我们带来了很多方便，但是由于其在有序序列插入时就会退化成单链表（时间复杂度退化成 O(n)，AVL-tree就克服了上述困难。AVL-tree是一个“加上了平衡条件的”二叉搜索树，平衡条件确保整棵树的深度为O(log n)。\nAVL树是最先发明的自平衡二叉查找树。在AVL树中任何节点的两个子树的高度最大差别为一，所以它也被称为高度平衡树。查找、插入和删除在平均和最坏情况下都是 O(log n)。增加和删除可能需要通过一次或多次树旋转来重新平衡这个树。\nAVL树的所有操作都与二叉查找树相同，不同的是，这里AVL树需要做“AVL旋转”。\nAVL旋转 AVL树最重要的核心部分就是AVL旋转了，这部分我的感触是，单做旋转还是挺好理解的，只不过写起代码来有点复杂，书中以插入节点为例，删除节点的部分折腾了好久。\n在理解AVL旋转之前，首先得知道以下几个概念：\n AVL 树节点的插入总是在叶子节点。 AVL 树在插入节点之前总是满足平衡条件的。 插入新节点后有可能满足平衡条件也有可能不满足。 当不满足平衡条件后，我们就需要对新的树进行旋转。  旋转之前，我们首先要找到一个X节点，这个X节点做如下定义：\n 假如我们在某一个叶子节点处插入一个新的节点后，此时这棵树的某些节点的平衡性会发生变化，那么我们从叶子节点向上到根节点的路径上第一个平衡性发生变化的节点。\n 基于这个X节点，考虑一件事情： 这个X节点分为左右子树，左右子树又有左右子树，1分2，2分4，所以以这个X节点为根节点的话，新插入的节点可能出现的位置有：\n X的左孩子节点的左子树上**(left-left)** X的右孩子节点的右子树上**(right-right)** X的左孩子节点的右子树上**(left-right)** X的右孩子节点的左子树上**(right-left)**\n 根据上述情况就延生出了4种旋转： 1.left-left Rotation 2.right-right Rotation 3.left-right Rotation 4.right-left Rotation\n前两种属于单旋转，后两种属于双旋转，双旋转的操作可以由两次单旋转组成。\nPS:AVL树的旋转还是得画图来理解，这里直接贴出书中的图了。\n\n图片来自 C小加的博客\n 6节点的左子树3节点高度比右子树7节点大2，左子树3节点的左子树1节点高度大于右子树4节点，这种情况成为左左（LL）。 6节点的左子树2节点高度比右子树7节点大2，左子树2节点的左子树1节点高度小于右子树4节点，这种情况成为左右（LR）。 2节点的左子树1节点高度比右子树5节点小2，右子树5节点的左子树3节点高度大于右子树6节点，这种情况成为右左（RL）。 2节点的左子树1节点高度比右子树4节点小2，右子树4节点的左子树3节点高度小于右子树6节点，这种情况成为右右（RR）。  从图2中可以可以看出，1和4两种情况是对称的，这两种情况的旋转算法是一致的，只需要经过一次旋转就可以达到目标，我们称之为单旋转。2和3两种情况也是对称的，这两种情况的旋转算法也是一致的，需要进行两次旋转，我们称之为双旋转。\n那么为什么需要双旋转呢？\n这里我做出我个人的解释，在 LL 情况中，要达到平衡，是需要将失衡节点划分到右边，失衡节点的左孩子补上失衡节点的位置。这样左子树的高度 -1， 右边的高度 +1，这样左右两边的个数就平衡了。当然根据BST的性质，如果失衡节点存在右孩子的话应该划也要分到右边。RR 情况与 LL 情况对称。\n而在 LR 情况中，我们是需要把失衡节点划到右边，失衡节点的左孩子的右孩子替补失衡节点原来的位置。但我们的节点存储结构有不能获得前驱节点的限制，我们只有后继关系，即我们只能通过失衡节点访问其他节点，所以不能直接把LR孩子放上来，而是分成两步调整。\n// 这里的描述太那啥了，得搞点图说明下\nAVL-Tree实现 AVL-Tree是一个二叉排序树，其基本操作也跟它类似，唯一需要注意的就是在插入，删除节点后，需要对树进行调整，让树的每个节点保持平衡。\n节点的平衡因子是通过计算其左子树和右子树的差得来的，这里有两种考虑方式：\n 每次都计算一次（递归求深度）。 将平衡因子作为一个成员变量保存在节点中，平衡性发生变化的时候更新。  本文采取的是第一种方式，关于两种方式利弊的比较：\n// 不想写？自己百度吧，反正就是第一种方法从上到下递归存在重复调用增加时间开销，第二种平衡性变化时候需要update 失衡位置 balanceFactor\n另外，这里我用了C++类封装，为了学习还顺便使用了模板，所以类的声明和实现都放在了一个文件中，感觉内容太多，还是分开来比较好。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  // AVLNode.h  #ifndef __AVLNODE_H__ #define __AVLNODE_H__  #include \u003ciostream\u003e#include \u003cvector\u003e#include \u003calgorithm\u003e template \u003ctypename KeyType\u003e class AVLNode{ public: KeyType key; AVLNode * left; AVLNode * right; AVLNode() : key(0), left(NULL), right(NULL) {} AVLNode(KeyType k) :key(k), left(NULL), right(NULL) {} }; #endif   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77  // AVLTree.h  #ifndef AVLTREE_AVLTREE_H #define AVLTREE_AVLTREE_H  #include \"AVLNode.h\" //AVL树的模板实现 template \u003ctypename KeyType\u003e class AVLTree { //类型定义  typedef AVLNode\u003cKeyType\u003e AVLNode; typedef AVLTree\u003cKeyType\u003e AVLTree; private: AVLNode * avlroot; //求树的高度  int __height(const AVLNode *root); //高度差（平衡因子）  int __diff(const AVLNode*root); //AVL4种旋转：左左，左右，右右，右左  //X定义为插入位置节点到根节点的路径上平衡条件被改变的节点中最深的那个节点  //X通过递归返回的方式找到  //左左：插入点位于X的左孩子节点的左子树  //左右：插入点位于X的左孩子节点的右子树  //右右：插入点位于X的右孩子节点的右子树  //右左：插入点位于X的右孩子节点的左子树  //单旋转  AVLNode * __ll_Rotation(AVLNode *root);//left-left rotation  AVLNode * __rr_Rotation(AVLNode *root);//right-right rotation  //双旋转  AVLNode * __lr_Rotation(AVLNode *root);//left-right rotation  AVLNode * __rl_Rotation(AVLNode *root);//right-left rotation  //平衡操作  AVLNode * __Balance(AVLNode *root); //插入的内部实现  AVLNode * __Insert(AVLNode *root, const KeyType \u0026k); //中序遍历的两种重载  // 1. 直接输出中序遍历节点  void __InorderTraversal(const AVLNode* root); // 2. 结果保存到vector中  void __InorderTraversal(const AVLNode*root, std::vector\u003cKeyType\u003e\u0026vec); //判断是否是叶子节点  bool __isLeaf(AVLNode* const \u0026node) {return (node-\u003eleft == nullptr \u0026\u0026 node-\u003eright == nullptr) ? true : false}; //判断是否有两个孩子  bool __isNodeWithTwoChild(AVLNode * const \u0026node); //查找的内部实现  AVLNode* __search(AVLNode *const root, const KeyType \u0026k); //删除树的所有节点  void __deleteTree(AVLNode * root); //删除节点  AVLNode* __Delete(AVLNode * root, const KeyType\u0026 k); //求当前根节点最小（一路向左）  AVLNode* __treeMin(AVLNode *root); //求当前根节点的最大（一路向右）  AVLNode* __treeMax(AVLNode *root); public: AVLTree(){ avlroot = nullptr; }//默认构造函数  ~AVLTree();//析构函数删除树中所有节点  AVLTree(const std::vector\u003cKeyType\u003e\u0026);//构造函数，容器构造  AVLTree(const KeyType * arr, size_t len);//构造函数，数组构造  void InorderTraversal();//中序遍历外部接口  void InorderTraversal(std::vector\u003cKeyType\u003e\u0026);//中序遍历外部接口重载2  bool Delete(const KeyType \u0026k);//删除节点的外部接口  void Insert(const KeyType \u0026 k);//插入节点的外部接口  bool IsEmpty(){ return avlroot == nullptr; } //树空？  bool search(const KeyType \u0026k);//查询外部接口 }; #endif //AVLTREE_AVLTREE_H    旋转操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  template \u003ctypename KeyType\u003e AVLNode * AVLTree::__ll_Rotation(AVLNode *root) { AVLNode * tmp; tmp = root-\u003eleft; root-\u003eleft = tmp-\u003eright; tmp-\u003eright = root; return tmp; } template \u003ctypename KeyType\u003e AVLNode * AVLTree::__rr_Rotation(AVLNode *root) { AVLNode* tmp; tmp = root-\u003eright; root-\u003eright = tmp-\u003eleft; tmp-\u003eleft = root; return tmp; } template \u003ctypename KeyType\u003e AVLNode * AVLTree::__lr_Rotation(AVLNode *root) { AVLNode * tmp; tmp = root-\u003eleft; root-\u003eleft = __rr_Rotation(tmp); return __ll_Rotation(root); } template \u003ctypename KeyType\u003e AVLNode * AVLTree::__rl_Rotation(AVLNode *root) { AVLNode * tmp; tmp = root-\u003eright; root-\u003eright = __ll_Rotation(tmp); return __rr_Rotation(root); }   AVLTree 插入 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  template \u003ctypename KeyType\u003e AVLNode * AVLTree::__Insert(AVLNode * root, const KeyType\u0026 k) { if (nullptr == root) { root = new AVLNode(k); return root; }//递归返回条件  else if (k \u003c root-\u003ekey) { root-\u003eleft = __Insert(root-\u003eleft, k);//递归左子树  //balance operation  root = __Balance(root);//平衡操作包含了四种旋转  } else if (k\u003eroot-\u003ekey) { root-\u003eright = __Insert(root-\u003eright, k);//递归右子树  //balance operation  root = __Balance(root);//平衡操作包含了四种旋转  } return root; }   AVLTree 删除 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69  //删除节点的私有成员实现 template \u003ctypename KeyType\u003e AVLNode * AVLTree::__Delete(AVLNode *root, const KeyType\u0026 k) { if (nullptr == root) return root; if (!search(k))//查找删除元素是否存在  { std::cerr \u003c\u003c \"Delete error , key not find\" \u003c\u003c std::endl; return root; } if (k == root-\u003ekey)//根节点  { if (__isNodeWithTwoChild(root))//左右子树都非空  { if (__diff(root) \u003e 0)//左子树更高，在左边删除  { root-\u003ekey = __treeMax(root-\u003eleft)-\u003ekey;//以左子树的最大值替换当前值  root-\u003eleft = __Delete(root-\u003eleft, root-\u003ekey);//删除左子树中已经替换上去的节点  } else//右子树更高，在右边删除  { root-\u003ekey = __treeMin(root-\u003eright)-\u003ekey; root-\u003eright = __Delete(root-\u003eright, root-\u003ekey); } } else//有一个孩子、叶子节点的情况合并  { //if (!__isLeaf(root))  AVLNode * tmp = root; root = (root-\u003eleft) ? (root-\u003eleft) :( root-\u003eright); delete tmp; tmp = nullptr; } }//end-if  else if (k \u003c root-\u003ekey)//往左边删除  { root-\u003eleft = __Delete(root-\u003eleft, k);//左子树中递归删除  //判断平衡的条件与在插入时情况类似  if (__diff(root) \u003c -1)//不满足平衡条件，删除左边的后，右子树变高  { if (__diff(root-\u003eright) \u003e 0) { root = __rl_Rotation(root); } else { root = __rr_Rotation(root); } } }//end else if  else { root-\u003eright = __Delete(root-\u003eright, k); if (__diff(root) \u003e 1)//不满足平衡条件  { if (__diff(root-\u003eleft) \u003c 0) { root = __lr_Rotation(root); } else { root = __ll_Rotation(root); } } } return root; }   附：完整代码\n参考 STL源码笔记（18）—平衡二叉树AVL（C++封装+模板）\n平衡二叉树,AVL树之图解篇\n一步一步写平衡二叉树（AVL树）\n平衡二叉树(avl)分析与实现\n","description":"","tags":["algorithm","tree"],"title":"平衡二叉树封装+模板实现","uri":"/blog/posts/algorithm/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%A0%91%E5%B0%81%E8%A3%85%E4%B8%8E%E6%A8%A1%E6%9D%BF%E5%AE%9E%E7%8E%B0/"},{"categories":["Algorithm"],"content":" All Topological Sorts，在前一章中Topological Sorting，已经讨论了拓扑排序的原理及其实现算法，但只是实现了从单一一个入度为0的节点进行的拓扑排序。本章主要来讨论一下，如何求一个有向无环图的所有拓扑排序序列。\n 问题描述 因为在一个有向无环图中，并非所有顶点间都有路径可达，而且可能有些点是孤立点，这导致了同一个有向图可能会有多个拓扑排序，因为显然孤立点在拓扑序列中的位置是任意的，各子连通子图间的先后次序也可以互换。\n那么如何来求一个有向无环图的所有拓扑排序序列呢？我们可以通过修改前一篇文章中的算法达到这个目标，即在原有拓扑排序过程的基础上，加上回溯法，并对所有入度为0的顶点应用这个带回溯的拓扑排序算法，\n算法思路  初始化所有顶点为未访问状态； 依次对所有入度为0的顶点，先把其入度降1，然后把该顶点放到排序序列中，然后递归访问它的所有邻接点，最后回溯； 在函数最终返回后，就得到了一个拓扑序列，然后重置访问状态和入度，继续寻找其它拓扑序列。  代码实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123  #include \u003cbits/stdc++.h\u003eusing namespace std; class Graph { int V; // No. of vertices  // Pointer to an array containing adjacency list  list\u003cint\u003e *adj; // Vector to store indegree of vertices  vector\u003cint\u003e indegree; // A function used by alltopologicalSort  void alltopologicalSortUtil(vector\u003cint\u003e\u0026 res, bool visited[]); public: Graph(int V); // Constructor  // function to add an edge to graph  void addEdge(int v, int w); // Prints all Topological Sorts  void alltopologicalSort(); }; // Constructor of graph Graph::Graph(int V) { this-\u003eV = V; adj = new list\u003cint\u003e[V]; // Initialising all indegree with 0  for (int i = 0; i \u003c V; i++) indegree.push_back(0); } // Utility function to add edge void Graph::addEdge(int v, int w) { adj[v].push_back(w); // Add w to v's list.  // increasing inner degree of w by 1  indegree[w]++; } // Main recursive function to print all possible // topological sorts void Graph::alltopologicalSortUtil(vector\u003cint\u003e\u0026 res, bool visited[]) { // To indicate whether all topological are found  // or not  bool flag = false; for (int i = 0; i \u003c V; i++) { // If indegree is 0 and not yet visited then  // only choose that vertex  if (indegree[i] == 0 \u0026\u0026 !visited[i]) { // reducing indegree of adjacent vertices  list\u003cint\u003e:: iterator j; for (j = adj[i].begin(); j != adj[i].end(); j++) indegree[*j]--; // including in result  res.push_back(i); visited[i] = true; alltopologicalSortUtil(res, visited); // resetting visited, res and indegree for  // backtracking  visited[i] = false; res.erase(res.end() - 1); for (j = adj[i].begin(); j != adj[i].end(); j++) indegree[*j]++; flag = true; } } // We reach here if all vertices are visited.  // So we print the solution here  if (!flag) { for (int i = 0; i \u003c res.size(); i++) cout \u003c\u003c res[i] \u003c\u003c \" \"; cout \u003c\u003c endl; } } // The function does all Topological Sort. // It uses recursive alltopologicalSortUtil() void Graph::alltopologicalSort() { // Mark all the vertices as not visited  bool *visited = new bool[V]; for (int i = 0; i \u003c V; i++) visited[i] = false; vector\u003cint\u003e res; alltopologicalSortUtil(res, visited); } int main() { // Create a graph given in the above diagram  Graph g(6); g.addEdge(5, 2); g.addEdge(5, 0); g.addEdge(4, 0); g.addEdge(4, 1); g.addEdge(2, 3); g.addEdge(3, 1); cout \u003c\u003c \"All Topological sorts\\\\n\"; g.alltopologicalSort(); return 0; }   ","description":"","tags":["algorithm","graph","topological-sort"],"title":"求有向图全部拓扑序列","uri":"/blog/posts/algorithm/%E6%B1%82%E6%9C%89%E5%90%91%E5%9B%BE%E5%85%A8%E9%83%A8%E6%8B%93%E6%89%91%E5%BA%8F%E5%88%97/"},{"categories":["Algorithm"],"content":"简介 拓扑排序 （Topological Sorting）\n 在计算机科学领域，有向图的拓扑排序或拓扑排序是其顶点的线性排序，使得对于从顶点u到顶点v的每个有向边uv，u在排序中都在v之前。例如，图形的顶点可以表示要执行的任务，并且边缘可以表示一个任务必须在另一个任务之前执行的约束；在这个应用中，拓扑排序只是一个有效的任务顺序。如果当图形没有定向循环，即如果它是有向无环图（Directed Acyclic Graph，即DAG），则拓扑排序是可能的。任何DAG具有至少一个拓扑排序，并且已知有些算法用于在线性时间内构建任何DAG的拓扑排序。 在图论中，由一个有向无环图的顶点组成的序列，当且仅当满足下列条件时，称为该图的一个拓扑排序（Topological sorting）。\n 每个顶点出现且只出现一次； 若A在序列中排在B的前面，则在图中不存在从B到A的边。  也可以定义为：拓扑排序是对有向无环图的顶点的一种排序，它使得如果存在一条从顶点A到顶点B的路径，那么在排序中B出现在A的后面。\n 问题描述 一般可以用有向图表示一个工程。在这种有向图中，用顶点表示活动，用弧 \u003ci, j\u003e 表示活动 i 必须在活动 j 开始之前完成。这种有向图叫做用顶点表示活动的网络（Activity on Vertex），记作 AOV网络。\n在AOV网络中不能存在有向回路，即有向环。因为如果出现了有向环，意味着某项活动要以自己的完成作为先决条件。显然这是不可能的。所以对给定的AOV网络，必须先判断它是否存在有向环。\n一种方法是对AOV网络构造它的拓扑有序序列。即将所有的顶点能够成一个线性有序的序列，使得AOV网络所有的前驱和后继关系得到满足，这种构造AOV网络全部顶点的拓扑有序序列的运算就叫拓扑排序。\n例如，下面有一个有向无环图，“5 4 2 3 1 0”是它的一个拓扑排序。一个有向无环图可以有多个拓扑排序，如下图的另一个拓扑排序为“4 5 2 3 1 0”，拓扑排序中的第一个顶点总是入度为0的顶点（即没有任何一条有向边以它为终点）。 算法思路  在AOV网络中选一个没有直接前驱的顶点v，并输出 从图中删除该顶点，同时删去所有从顶点v发出的弧 重复步骤1,2. 直到没有直接前驱的顶点全部输出  算法步骤 用二维list链表存储图的领接表\n 建立入度为0的顶点栈 当入度为0的顶点栈为空时，转到步骤6，否则步骤3 从入度为0的顶点栈顶元素v出栈，并输出顶点v 从AOV网络删去顶点v和所有顶点v发出的弧 \u003cv, j\u003e， 并将顶点 j 的入度 -1 如果顶点 j 的入度 = 0，则将该顶点置入入度为0的顶点栈，转到步骤2 如果输出顶点个数 \u003c AOV网络顶点数，则图中存在有向环  复杂度分析 Topological Sorting via Depth First Search(DFS) 在DFS中，我们先打印一个顶点，然后递归的对它的邻接点调用DFS。但是在拓扑排序中，任何一个顶点总要先于它的所有邻接顶点打印，如上面的图，顶点5和4必须先于顶点0打印。所以拓扑排序和DFS是不同的，例如“5 2 3 1 0 4”是上图的一个DFS序列，但是这个序列并不是拓扑排序。\n在DFS中，我们从任意一个顶点出发，打印它然后对它的所有邻接顶点递归调用DFS。而在拓扑排序中，我们同样调用DFS过程，但是在递归调用DFS的过程中，我们不直接打印顶点，而是把顶点 push 到栈里，等到递归完成后，所有顶点就全都在栈里了。注意，在这个过程中当且仅当一个顶点的所有邻接顶点入栈后，才到当前顶点入栈，这就保证它们能满足拓扑排序的次序要求。所以最后栈里的内容，从栈顶到栈底，就是一个拓扑排序序列，我们不断出栈并打印它们即可。\n因为这个算法只是简单的调用了下DFS，并借助栈做为辅助，所以其复杂度和DFS一样是O(V+E)。\n代码实现 C++ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94  #include\u003ciostream\u003e#include \u003clist\u003e#include \u003cstack\u003eusing namespace std; // Class to represent a graph class Graph { int V; // No. of vertices'  // Pointer to an array containing adjacency listsList  list\u003cint\u003e *adj; // A function used by topologicalSort  void topologicalSortUtil(int v, bool visited[], stack\u003cint\u003e \u0026Stack); public: Graph(int V); // Constructor  // function to add an edge to graph  void addEdge(int v, int w); // prints a Topological Sort of the complete graph  void topologicalSort(); }; Graph::Graph(int V) { this-\u003eV = V; adj = new list\u003cint\u003e[V]; } void Graph::addEdge(int v, int w) { adj[v].push_back(w); // Add w to v’s list. } // A recursive function used by topologicalSort void Graph::topologicalSortUtil(int v, bool visited[], stack\u003cint\u003e \u0026Stack) { // Mark the current node as visited.  visited[v] = true; // Recur for all the vertices adjacent to this vertex  list\u003cint\u003e::iterator i; for (i = adj[v].begin(); i != adj[v].end(); ++i) if (!visited[*i]) topologicalSortUtil(*i, visited, Stack); // Push current vertex to stack which stores result  Stack.push(v); } // The function to do Topological Sort. It uses recursive // topologicalSortUtil() void Graph::topologicalSort() { stack\u003cint\u003e Stack; // Mark all the vertices as not visited  bool *visited = new bool[V]; for (int i = 0; i \u003c V; i++) visited[i] = false; // Call the recursive helper function to store Topological  // Sort starting from all vertices one by one  for (int i = 0; i \u003c V; i++) if (visited[i] == false) topologicalSortUtil(i, visited, Stack); // Print contents of stack  while (Stack.empty() == false) { cout \u003c\u003c Stack.top() \u003c\u003c \" \"; Stack.pop(); } } int main() { // Create a graph given in the above diagram  Graph g(6); g.addEdge(5, 2); g.addEdge(5, 0); g.addEdge(4, 0); g.addEdge(4, 1); g.addEdge(2, 3); g.addEdge(3, 1); cout \u003c\u003c \"Following is a Topological Sort of the given graph n\"; g.topologicalSort(); return 0; }   Java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83  import java.io.*; import java.util.*; // This class represents a directed graph using adjacency // list representation class Graph { private int V; // No. of vertices  private LinkedList\u003cInteger\u003e adj[]; // Adjacency List  //Constructor  Graph(int v) { V = v; adj = new LinkedList[v]; for (int i=0; i\u003cv; ++i) adj[i] = new LinkedList(); } // Function to add an edge into the graph  void addEdge(int v,int w) { adj[v].add(w); } // A recursive function used by topologicalSort  void topologicalSortUtil(int v, boolean visited[], Stack stack) { // Mark the current node as visited.  visited[v] = true; Integer i; // Recur for all the vertices adjacent to this  // vertex  Iterator\u003cInteger\u003e it = adj[v].iterator(); while (it.hasNext()) { i = it.next(); if (!visited[i]) topologicalSortUtil(i, visited, stack); } // Push current vertex to stack which stores result  stack.push(new Integer(v)); } // The function to do Topological Sort. It uses  // recursive topologicalSortUtil()  void topologicalSort() { Stack stack = new Stack(); // Mark all the vertices as not visited  boolean visited[] = new boolean[V]; for (int i = 0; i \u003c V; i++) visited[i] = false; // Call the recursive helper function to store  // Topological Sort starting from all vertices  // one by one  for (int i = 0; i \u003c V; i++) if (visited[i] == false) topologicalSortUtil(i, visited, stack); // Print contents of stack  while (stack.empty()==false) System.out.print(stack.pop() + \" \"); } public static void main(String args[]) { // Create a graph given in the above diagram  Graph g = new Graph(6); g.addEdge(5, 2); g.addEdge(5, 0); g.addEdge(4, 0); g.addEdge(4, 1); g.addEdge(2, 3); g.addEdge(3, 1); System.out.println(\"Following is a Topological \" + \"sort of the given graph\"); g.topologicalSort(); } }   ","description":"","tags":["graph","topological-sort"],"title":"求图的拓扑排序","uri":"/blog/posts/algorithm/%E5%9B%BE%E7%9A%84%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F/"},{"categories":["Algorithm"],"content":"问题描述 实现一个函数，判断一棵二叉树是否为二叉搜索树。\n算法思路  二叉搜索树的中序遍历序列是有序的，所以只需求出中序遍历结果，再依次判断该序列是否有序即可。 上述方法需要额外线程空间保存遍历结果，在此可以省去该空间开销，只需一个变量保存访问当前节点时上一节点的值即可。 基于left \u003c current \u003c right的特性，可以递归用大小值比较进行判断  代码实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149  /* 题目描述 请实现一个函数，检查一棵二叉树是否为二叉搜索树。 给定树的根结点指针TreeNode* root，请返回一个bool，代表该树是否为二叉搜索树。 */ #include \u003ciostream\u003e #include \u003ccstdlib\u003e #include \u003cvector\u003e #include \u003cqueue\u003e  using namespace std; /*二叉树节点数据结构*/ struct TreeNode { int val; struct TreeNode *left; struct TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) { } }; const int flag = INT_MAX; TreeNode *generateTree(vector\u003cint\u003e \u0026nums) { if (nums.empty()) return NULL; TreeNode *root = new TreeNode(nums[0]); queue\u003cTreeNode *\u003e que; que.push(root); //求出所给元素个数，对应二叉查找树节点个数  int size = nums.size(); for (int i = 1; i \u003c size; i += 2) { //处理队首节点的左右子树  TreeNode *tmp = que.front(); TreeNode *left = NULL, *right = NULL; //定义非空左子树  if (nums[i] != flag) { left = new TreeNode(nums[i]); que.push(left); } //定义非空右子树  if (i + 1 \u003c size \u0026\u0026 nums[i + 1] != flag) { right = new TreeNode(nums[i + 1]); que.push(right); } tmp-\u003eleft = left; tmp-\u003eright = right; //弹出当前处理的节点  que.pop(); } return root; } class Checker { public: /*方法一，将中序遍历结果保存到数组 T(n)=O(n) S(n)=O(n)*/ void inOrder(TreeNode *root,vector\u003cint\u003e \u0026v) { if (root == NULL) return; inOrder(root-\u003eleft, v); v.push_back(root-\u003eval); inOrder(root-\u003eright, v); } bool checkBST1(TreeNode* root) { vector\u003cint\u003e ret; inOrder(root, ret); for (auto i = ret.begin()+1; i != ret.end(); ++i) { if (*i \u003c *(i - 1)) return false; } return true; } /*方法二、省掉线性空间，保存遍历的最后一个节点*/ int lastVal = INT_MIN; bool checkBST2(TreeNode* root) { // write code here  if (!root) return true; /*递归检查左子树*/ if (!checkBST2(root-\u003eleft)) return false; /*比较当前节点，并更新已遍历节点最后的值*/ if (root-\u003eval \u003c= lastVal) return false; lastVal = root-\u003eval; /*递归检查右子树*/ if (!checkBST2(root-\u003eright)) return false; return true; } /*方法三，最大最小值法*/ bool checkBST3(TreeNode* root) { // write code here  if (!root) return true; return checkBST3(root, INT_MAX, INT_MIN); } bool checkBST3(TreeNode *root, int maxVal, int minVal) { if (!root) return true; if (root-\u003eval \u003c minVal || root-\u003eval \u003e= maxVal) return false; if (!checkBST3(root-\u003eleft, root-\u003eval, minVal) || !checkBST3(root-\u003eright, maxVal, root-\u003eval)) return false; return true; } }; int main() { vector\u003cint\u003e v = { 7, 6, flag, 4, flag, 2, 5, 8, 3, flag, flag, flag, flag, flag, flag }; TreeNode *root = generateTree(v); Checker c; bool ret = c.checkBST1(root); cout \u003c\u003c ret \u003c\u003c endl; ret = c.checkBST2(root); cout \u003c\u003c ret \u003c\u003c endl; ret = c.checkBST3(root); cout \u003c\u003c ret \u003c\u003c endl; system(\"pause\"); return 0; }   ","description":"","tags":["algorithm","tree"],"title":"【剑指offer】判断二叉搜索树（BST）","uri":"/blog/posts/algorithm/%E5%88%A4%E6%96%AD%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/"},{"categories":["Algorithm"],"content":"《算法》 Chap-1 笔记 算法：适合用计算机实现的解决问题的方法\n数据结构：便于算法操作的组织数据的方法。\n基础编程模型：实现算法用到的语言特性，软件库和操作系统特性的总称\n数据抽象：\n抽象数据类型（ADT）\n模块化编程\n应用程序编程接口（API）\n","description":"","tags":null,"title":"过往皆为序章","uri":"/blog/posts/algorithm/algorithm-chap1-notes/"}]
